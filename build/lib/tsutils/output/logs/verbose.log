[2022-05-13 13:52:19,035] ERROR: hello
[2022-05-13 13:53:38,431] ERROR: hello
[2022-05-13 13:54:55,486] ERROR: ()
[2022-05-17 14:51:53,477] ERROR: ('No requests were made to https://asdf.asdfjdjjkkk/',)
[2022-05-17 14:57:10,128] ERROR: ('No requests were made to https://asdf.asdfjdjjkkk/',)
[2022-05-17 14:57:46,940] ERROR: No requests were made to https://asdf.asdfjdjjkkk/
[2022-05-17 15:01:08,199] ERROR: 
[2022-05-17 15:01:26,103] ERROR: No requests were made to https://asdf.asdfjdjjkkk/
[2022-05-17 15:01:26,109] ERROR: ... skipping
[2022-05-17 15:02:37,416] ERROR: No requests were made to https://asdf.asdfjdjjkkk/
[2022-05-17 15:02:37,421] ERROR: https://asdf.asdfjdjjkkk/... skipping
[2022-05-18 14:58:49,415] ERROR: 503 raised while requesting https://onlinelibrary.wiley.com/doi/10.1111/petr.14281
[2022-05-18 15:18:03,628] ERROR: No requests made to (https://asdfs.bbboadfa/)
[2022-05-18 15:18:03,640] ERROR: https://asdfs.bbboadfa/... skipping
[2022-05-18 15:18:32,192] ERROR: No requests made to (https://asdfsasdgajbjkooooo.com/)
[2022-05-18 15:18:32,197] ERROR: https://asdfsasdgajbjkooooo.com/... skipping
[2022-05-18 15:19:00,592] ERROR: No requests made to (https://asdfsasdgajbjkooooo.com/)
[2022-05-18 15:19:00,620] ERROR: https://asdfsasdgajbjkooooo.com/... skipping
[2022-05-18 15:20:03,169] ERROR: No requests made to (https://asdfsasdgajbjkooooo.com/)
[2022-05-18 15:20:21,301] ERROR: https://asdfsasdgajbjkooooo.com/... skipping
[2022-05-20 11:41:05,710] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/mapper.py", line 71, in _handle_task
    return func(*args)
TypeError: get() missing 1 required positional argument: 'url'
[2022-05-20 11:41:31,178] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/mapper.py", line 71, in _handle_task
    return func(*args)
TypeError: get() missing 1 required positional argument: 'url'
[2022-05-23 11:26:31,270] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 112, in _handle_task
    return func(*args, **kwargs)
TypeError: get() missing 1 required positional argument: 'url'
[2022-05-23 11:29:34,806] DEBUG: Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.
[2022-05-23 12:00:54,375] ERROR: 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 12:00:54,377] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 102, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 61, in scrape_url
    resp = self._scraper.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 12:58:26,507] ERROR: 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 12:58:26,507] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 61, in scrape_url
    resp = self._scraper.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 13:02:50,279] ERROR: 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 13:02:50,279] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 61, in scrape_url
    resp = self._scraper.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 13:52:28,986] ERROR: 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 13:52:28,986] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 61, in scrape_url
    resp = self._scraper.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:03:57,050] ERROR: 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:03:57,051] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 61, in scrape_url
    resp = self._scraper.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:05:01,636] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 61, in scrape_url
    resp = self._scraper.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 43, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 83, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 122, in _do_parallel_execution
    return self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 140, in _parse_completing_threads
    self._terminate_threads(not_done)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 140, in _parse_completing_threads
    self._terminate_threads(not_done)
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-23 14:05:14,802] ERROR: 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:05:14,803] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:05:14,803] ERROR: 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:05:14,816] ERROR: 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:05:14,822] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:05:14,822] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:05:15,203] ERROR: 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:05:15,204] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:37,801] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 61, in scrape_url
    resp = self._scraper.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 43, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 83, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 122, in _do_parallel_execution
    return self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 138, in _parse_completing_threads
    continue
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 138, in _parse_completing_threads
    continue
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-23 14:08:42,965] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:42,966] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:43,563] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/university-Books/s?k=%22university+of%22&rh=n%3A283155
[2022-05-23 14:08:43,563] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:43,634] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/university-Books/s?k=%22university+of%22&rh=n%3A283155
[2022-05-23 14:08:43,635] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:43,821] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/university-Books/s?k=%22university+of%22&rh=n%3A283155
[2022-05-23 14:08:43,821] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:43,989] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:43,990] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:43,992] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:43,994] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:43,994] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:43,994] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:44,169] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:44,169] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:44,347] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:44,347] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:44,510] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:44,510] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:44,512] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:44,512] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:44,516] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:44,516] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:44,685] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:44,686] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:44,694] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:44,698] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:44,699] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:44,699] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:45,001] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:45,002] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:45,168] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:45,168] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:45,174] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:45,176] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:45,840] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/law-Books/s?k=%22law%22&rh=n%3A283155
[2022-05-23 14:08:45,840] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:46,166] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/law-Books/s?k=%22law%22&rh=n%3A283155
[2022-05-23 14:08:46,166] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:46,570] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:46,571] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:46,734] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:46,734] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:46,848] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/digital-Books/s?k=%22digital%22&rh=n%3A283155
[2022-05-23 14:08:46,848] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:47,058] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/digital-Books/s?k=%22digital%22&rh=n%3A283155
[2022-05-23 14:08:47,058] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:47,220] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:47,221] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:47,377] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:47,378] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:47,381] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:08:47,381] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:08:47,939] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/policy-Books/s?k=%22policy%22&rh=n%3A283155
[2022-05-23 14:08:47,939] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:09:49,575] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:09:49,576] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:09:49,577] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:09:49,578] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:09:49,739] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:09:49,739] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:09:50,164] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/university-Books/s?k=%22university+of%22&rh=n%3A283155
[2022-05-23 14:09:50,165] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:08,905] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:10:08,906] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:08,906] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:10:08,907] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:09,645] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/university-Books/s?k=%22university+of%22&rh=n%3A283155
[2022-05-23 14:10:09,646] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:09,913] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/university-Books/s?k=%22university+of%22&rh=n%3A283155
[2022-05-23 14:10:09,913] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:09,914] INFO: Processing #1/7
[2022-05-23 14:10:10,087] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:10:10,087] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:10:10,088] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:10,087] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:10,258] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:10:10,258] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:11,078] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/economic-Books/s?k=%22economic%22&rh=n%3A283155
[2022-05-23 14:10:11,078] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:11,079] INFO: Processing #2/7
[2022-05-23 14:10:11,249] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:10:11,249] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:11,487] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:10:11,487] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:11,967] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/history-Books/s?k=%22history%22&rh=n%3A283155
[2022-05-23 14:10:11,967] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:13,073] INFO: Processing #3/7
[2022-05-23 14:10:13,239] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:10:13,239] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:13,244] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:10:13,244] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:14,046] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/technology-Books/s?k=%22technology%22&rh=n%3A283155
[2022-05-23 14:10:14,047] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:15,160] INFO: Processing #4/7
[2022-05-23 14:10:15,334] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:10:15,334] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:15,341] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:10:15,343] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:15,503] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:10:15,504] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:16,685] INFO: Processing #5/7
[2022-05-23 14:10:16,856] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:10:16,856] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:16,866] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:10:16,868] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:17,393] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/digital-Books/s?k=%22digital%22&rh=n%3A283155
[2022-05-23 14:10:17,393] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:17,593] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/digital-Books/s?k=%22digital%22&rh=n%3A283155
[2022-05-23 14:10:17,593] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:17,594] INFO: Processing #6/7
[2022-05-23 14:10:18,042] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:10:18,042] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:10:18,042] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:18,043] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:18,314] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/policy-Books/s?k=%22policy%22&rh=n%3A283155
[2022-05-23 14:10:18,314] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:18,440] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:10:18,440] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:10:18,440] INFO: Processing #7/7
[2022-05-23 14:12:06,822] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:12:06,823] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:12:06,823] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:12:06,824] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:12:06,991] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:12:06,991] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:12:07,057] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:12:07,057] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:12:21,206] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:12:21,207] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:12:21,218] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:12:21,218] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:12:21,377] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:12:21,377] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:12:21,606] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/university-Books/s?k=%22university+of%22&rh=n%3A283155
[2022-05-23 14:12:21,606] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:13:08,882] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 62, in scrape_url
    if resp is None:
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 62, in scrape_url
    if resp is None:
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-23 14:13:08,883] INFO: Processing #1/7
[2022-05-23 14:13:12,154] DEBUG: lets go
[2022-05-23 14:13:50,226] DEBUG: lets go
[2022-05-23 14:14:51,438] DEBUG: hello
[2022-05-23 14:15:05,013] DEBUG: hello
[2022-05-23 14:16:31,474] DEBUG: lets go
[2022-05-23 14:17:04,827] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:17:04,827] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:17:04,977] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:17:04,977] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:17:05,544] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/university-Books/s?k=%22university+of%22&rh=n%3A283155
[2022-05-23 14:17:05,544] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:17:05,720] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/university-Books/s?k=%22university+of%22&rh=n%3A283155
[2022-05-23 14:17:05,720] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:17:57,229] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 62, in scrape_url
    if resp is None:
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 62, in scrape_url
    if resp is None:
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-23 14:17:57,230] INFO: Processing #1/7
[2022-05-23 14:18:03,965] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:18:03,971] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:18:04,163] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:18:04,193] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:19:02,629] INFO: Processing #1/7
[2022-05-23 14:19:10,041] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:19:10,041] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:19:10,043] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:19:10,044] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:19:10,597] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/university-Books/s?k=%22university+of%22&rh=n%3A283155
[2022-05-23 14:19:10,597] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:19:40,039] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 62, in scrape_url
    if resp is None:
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 62, in scrape_url
    if resp is None:
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-23 14:19:40,040] INFO: Processing #1/7
[2022-05-23 14:20:04,924] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:20:07,538] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:20:10,077] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:20:12,713] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:20:12,713] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 61, in scrape_url
    resp = self._scraper.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:20:12,714] INFO: Processing #1/7
[2022-05-23 14:47:46,939] INFO: Processing #1/7
[2022-05-23 14:47:53,513] INFO: Processing #2/7
[2022-05-23 14:48:00,921] INFO: Processing #3/7
[2022-05-23 14:48:07,297] INFO: Processing #4/7
[2022-05-23 14:48:14,139] INFO: Processing #5/7
[2022-05-23 14:48:20,278] INFO: Processing #6/7
[2022-05-23 14:48:26,117] INFO: Processing #7/7
[2022-05-23 14:57:56,172] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:56,172] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:56,174] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:56,173] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:56,187] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:56,188] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:56,335] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:56,336] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:56,336] INFO: Processing #1/7
[2022-05-23 14:57:56,508] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:56,509] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:56,514] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:56,514] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:56,516] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:56,519] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:56,896] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:56,896] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:56,897] INFO: Processing #2/7
[2022-05-23 14:57:57,067] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:57,069] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:57,069] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:57,069] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:57,215] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:57,215] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:57,527] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:57,528] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:57,528] INFO: Processing #3/7
[2022-05-23 14:57:57,691] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:57,691] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:57,702] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:57,703] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:57,705] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:57,705] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:57,853] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:57,853] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:57,854] INFO: Processing #4/7
[2022-05-23 14:57:58,016] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:58,016] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:58,023] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:58,024] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:58,030] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:58,030] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:58,174] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:58,174] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:58,175] INFO: Processing #5/7
[2022-05-23 14:57:58,341] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:58,342] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:58,342] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:58,343] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:58,353] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:58,354] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:58,653] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:58,653] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:58,654] INFO: Processing #6/7
[2022-05-23 14:57:58,821] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:58,821] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:58,822] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:58,834] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:58,970] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:58,970] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:58,988] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 14:57:58,989] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 14:57:58,990] INFO: Processing #7/7
[2022-05-23 15:22:10,457] INFO: Processing #1/7
[2022-05-23 15:25:39,945] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 62, in scrape_url
    if resp is None:
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 62, in scrape_url
    if resp is None:
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-23 15:25:39,950] INFO: Processing #2/7
[2022-05-23 15:36:38,703] INFO: Processing #1/7
[2022-05-23 15:37:07,248] INFO: Processing #1/7
[2022-05-23 15:38:07,097] ERROR: No requests could be made to https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:38:11,367] ERROR: No requests could be made to https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:38:18,722] INFO: Processing #1/7
[2022-05-23 15:44:06,507] INFO: Processing #1/7
[2022-05-23 15:44:09,899] INFO: Processing #2/7
[2022-05-23 15:44:12,924] INFO: Processing #3/7
[2022-05-23 15:44:15,842] INFO: Processing #4/7
[2022-05-23 15:44:18,556] INFO: Processing #5/7
[2022-05-23 15:44:21,444] INFO: Processing #6/7
[2022-05-23 15:44:24,184] INFO: Processing #7/7
[2022-05-23 15:44:51,668] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:51,669] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:51,814] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:51,814] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:51,889] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:51,890] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:51,980] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:51,980] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:51,980] INFO: Processing #1/7
[2022-05-23 15:44:52,149] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:52,150] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:52,158] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:52,159] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:52,298] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:52,299] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:52,596] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:52,597] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:52,597] INFO: Processing #2/7
[2022-05-23 15:44:53,004] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:53,004] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:53,017] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:53,017] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:53,320] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:53,321] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:53,783] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:53,783] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:53,784] INFO: Processing #3/7
[2022-05-23 15:44:54,280] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:54,280] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:54,283] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:54,285] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:54,283] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:54,294] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:54,476] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:54,476] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:54,476] INFO: Processing #4/7
[2022-05-23 15:44:54,658] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:54,658] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:54,804] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:54,804] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:54,839] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:54,840] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:54,881] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:54,882] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:54,882] INFO: Processing #5/7
[2022-05-23 15:44:55,053] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:55,054] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:55,055] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:55,056] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:55,202] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:55,202] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:55,227] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:55,227] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:55,227] INFO: Processing #6/7
[2022-05-23 15:44:55,409] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:55,409] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:55,418] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:55,419] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:55,634] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:55,635] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:55,790] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 15:44:55,791] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 15:44:55,791] INFO: Processing #7/7
[2022-05-23 15:45:00,551] INFO: Processing #1/7
[2022-05-23 15:45:01,056] INFO: Processing #2/7
[2022-05-23 15:45:01,543] INFO: Processing #3/7
[2022-05-23 15:45:01,914] INFO: Processing #4/7
[2022-05-23 15:45:02,303] INFO: Processing #5/7
[2022-05-23 15:45:02,911] INFO: Processing #6/7
[2022-05-23 15:45:03,471] INFO: Processing #7/7
[2022-05-23 15:54:35,627] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (X11; CrOS x86_64 14469.41.0) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/99.0.4844.57 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,628] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (X11; CrOS x86_64 14469.41.0) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/99.0.4844.57 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,628] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (X11; CrOS x86_64 14469.41.0) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/99.0.4844.57 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,638] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (X11; CrOS x86_64 14469.41.0) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/99.0.4844.57 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,639] INFO: Processing #1/7
[2022-05-23 15:54:35,650] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (X11; CrOS x86_64 14469.41.0) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/99.0.4844.57 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,656] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (X11; CrOS x86_64 14469.41.0) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/99.0.4844.57 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,657] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/100.0.4896.75 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,682] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/100.0.4896.75 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,687] INFO: Processing #2/7
[2022-05-23 15:54:35,697] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/100.0.4896.75 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,704] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/100.0.4896.75 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,705] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/100.0.4896.75 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,710] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/100.0.4896.75 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,717] INFO: Processing #3/7
[2022-05-23 15:54:35,728] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:98.0) Gecko/20100101 Firefox/98.0']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,730] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:98.0) Gecko/20100101 Firefox/98.0']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,741] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:98.0) Gecko/20100101 Firefox/98.0']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,748] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:98.0) Gecko/20100101 Firefox/98.0']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,750] INFO: Processing #4/7
[2022-05-23 15:54:35,755] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:98.0) Gecko/20100101 Firefox/98.0']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,780] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/92.0.4515.159 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,782] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:98.0) Gecko/20100101 Firefox/98.0']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,789] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/92.0.4515.159 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,789] INFO: Processing #5/7
[2022-05-23 15:54:35,795] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/92.0.4515.159 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,809] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/92.0.4515.159 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,810] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/92.0.4515.159 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,813] INFO: Processing #6/7
[2022-05-23 15:54:35,823] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML', ' like Gecko) Version/15.2 Safari/605.1.15']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,824] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/92.0.4515.159 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,830] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML', ' like Gecko) Version/15.2 Safari/605.1.15']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,835] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML', ' like Gecko) Version/15.2 Safari/605.1.15']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:54:35,837] INFO: Processing #7/7
[2022-05-23 15:56:09,389] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (X11; CrOS x86_64 14469.41.0) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/99.0.4844.57 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,390] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (X11; CrOS x86_64 14469.41.0) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/99.0.4844.57 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,390] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (X11; CrOS x86_64 14469.41.0) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/99.0.4844.57 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,399] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (X11; CrOS x86_64 14469.41.0) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/99.0.4844.57 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,402] INFO: Processing #1/7
[2022-05-23 15:56:09,410] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (X11; CrOS x86_64 14469.41.0) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/99.0.4844.57 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,422] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (X11; CrOS x86_64 14469.41.0) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/99.0.4844.57 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,424] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/100.0.4896.75 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,425] INFO: Processing #2/7
[2022-05-23 15:56:09,439] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/100.0.4896.75 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,446] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/100.0.4896.75 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,450] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/100.0.4896.75 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,459] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/100.0.4896.75 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,459] INFO: Processing #3/7
[2022-05-23 15:56:09,466] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/100.0.4896.75 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,476] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:98.0) Gecko/20100101 Firefox/98.0']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,478] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:98.0) Gecko/20100101 Firefox/98.0']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,484] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:98.0) Gecko/20100101 Firefox/98.0']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,487] INFO: Processing #4/7
[2022-05-23 15:56:09,501] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:98.0) Gecko/20100101 Firefox/98.0']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,507] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:98.0) Gecko/20100101 Firefox/98.0']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,508] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:98.0) Gecko/20100101 Firefox/98.0']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,514] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/92.0.4515.159 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,518] INFO: Processing #5/7
[2022-05-23 15:56:09,536] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/92.0.4515.159 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,538] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/92.0.4515.159 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,539] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/92.0.4515.159 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,547] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/92.0.4515.159 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,552] INFO: Processing #6/7
[2022-05-23 15:56:09,560] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML', ' like Gecko) Chrome/92.0.4515.159 Safari/537.36']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,572] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML', ' like Gecko) Version/15.2 Safari/605.1.15']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,579] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML', ' like Gecko) Version/15.2 Safari/605.1.15']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,584] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1024, in check_header_validity
    if not pat.match(value):
TypeError: expected string or bytes-like object

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 319, in prepare
    self.prepare_headers(headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 453, in prepare_headers
    check_header_validity(header)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/utils.py", line 1027, in check_header_validity
    raise InvalidHeader("Value for header {%s: %s} must be of type str or "
requests.exceptions.InvalidHeader: Value for header {User-Agent: ['Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML', ' like Gecko) Version/15.2 Safari/605.1.15']} must be of type str or bytes, not <class 'list'>
[2022-05-23 15:56:09,592] INFO: Processing #7/7
[2022-05-23 16:00:30,682] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    try:  # SSLErrors are sometimes raised when using CloudScraper
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    try:  # SSLErrors are sometimes raised when using CloudScraper
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-23 16:00:30,682] INFO: Processing #1/7
[2022-05-23 16:00:30,886] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 16:00:30,886] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 16:00:30,887] INFO: Processing #2/7
[2022-05-23 16:00:31,075] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 16:00:31,075] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 16:00:31,075] INFO: Processing #3/7
[2022-05-23 16:00:31,375] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 16:00:31,375] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 16:00:31,375] INFO: Processing #4/7
[2022-05-23 16:00:31,573] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 16:00:31,573] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 16:00:31,573] INFO: Processing #5/7
[2022-05-23 16:00:31,986] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 16:00:31,986] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 16:00:31,987] INFO: Processing #6/7
[2022-05-23 16:00:32,170] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-23 16:00:32,171] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-23 16:00:32,171] INFO: Processing #7/7
[2022-05-23 16:00:50,045] INFO: Processing #1/7
[2022-05-23 16:00:55,316] INFO: Processing #2/7
[2022-05-23 16:01:01,506] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 74, in get
    kwargs = self._get_kwargs(next(self._hosts), kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 74, in get
    kwargs = self._get_kwargs(next(self._hosts), kwargs)
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-23 16:01:01,508] INFO: Processing #3/7
[2022-05-23 16:01:02,571] INFO: Processing #4/7
[2022-05-23 16:06:26,917] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 62, in scrape_url
    if resp is None:
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 62, in scrape_url
    if resp is None:
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-23 16:06:26,917] INFO: Processing #1/7
[2022-05-23 16:06:50,885] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 71, in scrape_url
    elems = resp.dom.xpath(conf["xpath"])
  File "src/lxml/etree.pyx", line 1597, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 305, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 225, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid expression
[2022-05-23 16:06:50,886] INFO: Processing #1/7
[2022-05-23 16:09:00,473] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 72, in scrape_url
    if not elems:
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 72, in scrape_url
    if not elems:
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-23 16:09:00,474] INFO: Processing #1/7
[2022-05-23 16:10:28,103] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 83, in scrape_url
    return out
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 83, in scrape_url
    return out
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-23 16:10:28,104] INFO: Processing #1/7
[2022-05-23 17:12:49,112] INFO: Processing search page #0/7
[2022-05-23 17:12:57,068] INFO: Processing sub page #9/['75']
[2022-05-23 17:13:41,261] INFO: Processing search page #1/7
[2022-05-23 17:13:50,445] INFO: Processing sub page #10/75
[2022-05-23 17:14:01,359] INFO: Processing sub page #20/75
[2022-05-23 17:14:12,570] INFO: Processing sub page #30/75
[2022-05-24 14:17:07,593] INFO: hello
[2022-05-24 14:47:14,558] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-24 14:47:14,558] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-24 14:52:01,604] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-24 14:52:01,604] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs), True
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-24 14:52:02,010] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-24 14:52:02,011] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs), True
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-24 14:52:02,188] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-24 14:52:02,188] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs), True
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-24 14:52:02,363] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-24 14:52:02,364] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs), True
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-24 14:54:26,295] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-24 14:54:26,295] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs), True
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-24 14:54:27,509] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-24 14:54:27,509] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs), True
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-24 14:54:32,936] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-24 14:54:32,937] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs), True
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-24 14:54:35,506] DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-24 14:54:35,506] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs), True
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 40, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise RequestFailedError(resp)
tsutils.scrape.exceptions.RequestFailedError: <Response [503]>
[2022-05-24 15:00:53,995] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 555, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 412, in send
    conn = self.get_connection(request.url, proxies)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 304, in get_connection
    proxy = prepend_scheme_if_needed(proxy, 'http')
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/utils.py", line 906, in prepend_scheme_if_needed
    scheme, netloc, path, params, query, fragment = urlparse(url, new_scheme)
  File "/usr/local/lib/python3.8/urllib/parse.py", line 375, in urlparse
    url, scheme, _coerce_result = _coerce_args(url, scheme)
  File "/usr/local/lib/python3.8/urllib/parse.py", line 124, in _coerce_args
    raise TypeError("Cannot mix str and non-str arguments")
TypeError: Cannot mix str and non-str arguments
[2022-05-24 15:00:54,012] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 555, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 412, in send
    conn = self.get_connection(request.url, proxies)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 304, in get_connection
    proxy = prepend_scheme_if_needed(proxy, 'http')
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/utils.py", line 906, in prepend_scheme_if_needed
    scheme, netloc, path, params, query, fragment = urlparse(url, new_scheme)
  File "/usr/local/lib/python3.8/urllib/parse.py", line 375, in urlparse
    url, scheme, _coerce_result = _coerce_args(url, scheme)
  File "/usr/local/lib/python3.8/urllib/parse.py", line 124, in _coerce_args
    raise TypeError("Cannot mix str and non-str arguments")
TypeError: Cannot mix str and non-str arguments
[2022-05-24 15:00:54,027] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 555, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 412, in send
    conn = self.get_connection(request.url, proxies)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 304, in get_connection
    proxy = prepend_scheme_if_needed(proxy, 'http')
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/utils.py", line 906, in prepend_scheme_if_needed
    scheme, netloc, path, params, query, fragment = urlparse(url, new_scheme)
  File "/usr/local/lib/python3.8/urllib/parse.py", line 375, in urlparse
    url, scheme, _coerce_result = _coerce_args(url, scheme)
  File "/usr/local/lib/python3.8/urllib/parse.py", line 124, in _coerce_args
    raise TypeError("Cannot mix str and non-str arguments")
TypeError: Cannot mix str and non-str arguments
[2022-05-24 15:00:54,042] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 76, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 555, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 412, in send
    conn = self.get_connection(request.url, proxies)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 304, in get_connection
    proxy = prepend_scheme_if_needed(proxy, 'http')
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/utils.py", line 906, in prepend_scheme_if_needed
    scheme, netloc, path, params, query, fragment = urlparse(url, new_scheme)
  File "/usr/local/lib/python3.8/urllib/parse.py", line 375, in urlparse
    url, scheme, _coerce_result = _coerce_args(url, scheme)
  File "/usr/local/lib/python3.8/urllib/parse.py", line 124, in _coerce_args
    raise TypeError("Cannot mix str and non-str arguments")
TypeError: Cannot mix str and non-str arguments
[2022-05-24 15:02:32,577] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 555, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 412, in send
    conn = self.get_connection(request.url, proxies)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 304, in get_connection
    proxy = prepend_scheme_if_needed(proxy, 'http')
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/utils.py", line 906, in prepend_scheme_if_needed
    scheme, netloc, path, params, query, fragment = urlparse(url, new_scheme)
  File "/usr/local/lib/python3.8/urllib/parse.py", line 375, in urlparse
    url, scheme, _coerce_result = _coerce_args(url, scheme)
  File "/usr/local/lib/python3.8/urllib/parse.py", line 124, in _coerce_args
    raise TypeError("Cannot mix str and non-str arguments")
TypeError: Cannot mix str and non-str arguments
[2022-05-24 15:02:33,581] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 555, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 412, in send
    conn = self.get_connection(request.url, proxies)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 304, in get_connection
    proxy = prepend_scheme_if_needed(proxy, 'http')
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/utils.py", line 906, in prepend_scheme_if_needed
    scheme, netloc, path, params, query, fragment = urlparse(url, new_scheme)
  File "/usr/local/lib/python3.8/urllib/parse.py", line 375, in urlparse
    url, scheme, _coerce_result = _coerce_args(url, scheme)
  File "/usr/local/lib/python3.8/urllib/parse.py", line 124, in _coerce_args
    raise TypeError("Cannot mix str and non-str arguments")
TypeError: Cannot mix str and non-str arguments
[2022-05-24 15:02:34,241] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 555, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 412, in send
    conn = self.get_connection(request.url, proxies)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 304, in get_connection
    proxy = prepend_scheme_if_needed(proxy, 'http')
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/utils.py", line 906, in prepend_scheme_if_needed
    scheme, netloc, path, params, query, fragment = urlparse(url, new_scheme)
  File "/usr/local/lib/python3.8/urllib/parse.py", line 375, in urlparse
    url, scheme, _coerce_result = _coerce_args(url, scheme)
  File "/usr/local/lib/python3.8/urllib/parse.py", line 124, in _coerce_args
    raise TypeError("Cannot mix str and non-str arguments")
TypeError: Cannot mix str and non-str arguments
[2022-05-24 15:02:35,219] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 555, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 412, in send
    conn = self.get_connection(request.url, proxies)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 304, in get_connection
    proxy = prepend_scheme_if_needed(proxy, 'http')
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/utils.py", line 906, in prepend_scheme_if_needed
    scheme, netloc, path, params, query, fragment = urlparse(url, new_scheme)
  File "/usr/local/lib/python3.8/urllib/parse.py", line 375, in urlparse
    url, scheme, _coerce_result = _coerce_args(url, scheme)
  File "/usr/local/lib/python3.8/urllib/parse.py", line 124, in _coerce_args
    raise TypeError("Cannot mix str and non-str arguments")
TypeError: Cannot mix str and non-str arguments
[2022-05-24 15:09:01,725] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/urllib3/connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/urllib3/connectionpool.py", line 994, in _prepare_proxy
    conn.connect()
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/urllib3/connection.py", line 369, in connect
    self._tunnel()
  File "/usr/local/lib/python3.8/http/client.py", line 901, in _tunnel
    (version, code, message) = response._read_status()
  File "/usr/local/lib/python3.8/http/client.py", line 277, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 39, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 77, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 555, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 510, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out')))
[2022-05-26 16:11:59,899] ERROR: No source is configured for https://google.com
[2022-05-26 16:12:41,765] ERROR: No source is configured for https://google.com
[2022-05-26 16:12:41,765] INFO: Scraping https://google.com failed
[2022-05-26 16:19:58,476] INFO: Scraping https://google.com failed
[2022-05-26 16:23:15,007] INFO: Scraping https://google.com failed
[2022-05-26 16:44:40,864] ERROR: //div could not be resolved into a string... skipping
[2022-05-26 16:45:15,014] ERROR: //div could not be resolved into a string... skipping
[2022-05-26 16:45:15,014] INFO: Skipping
[2022-05-27 09:20:24,508] ERROR: No source is configured for https://google.com... skipping
[2022-05-27 09:20:24,510] INFO: Scraping https://google.com failed
[2022-05-27 09:22:23,241] ERROR: No source is configured for https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b... skipping
[2022-05-27 09:22:23,242] INFO: Scraping https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b failed
[2022-05-27 09:28:28,390] INFO: Processing #1/2
[2022-05-27 09:28:29,699] INFO: Processing #2/2
[2022-05-27 09:29:32,472] INFO: Processing #1/2
[2022-05-27 09:29:33,898] INFO: Processing #2/2
[2022-05-27 09:30:23,253] INFO: Processing #1/2
[2022-05-27 09:30:24,428] INFO: Processing #2/2
[2022-05-27 09:41:44,763] INFO: Processing #1/7
[2022-05-27 09:41:44,890] INFO: Processing #2/7
[2022-05-27 09:41:44,980] INFO: Processing #3/7
[2022-05-27 09:41:46,033] INFO: Processing #4/7
[2022-05-27 09:41:46,135] INFO: Processing #5/7
[2022-05-27 09:41:46,300] INFO: Processing #6/7
[2022-05-27 09:41:47,219] INFO: Processing #7/7
[2022-05-27 09:50:16,491] ERROR: Driver instances cannot be run in parallel CRITICAL - QUITTING
[2022-05-27 09:50:37,821] ERROR: Driver instances cannot be run in parallel... CRITICAL - QUITTING
[2022-05-27 09:51:27,006] INFO: Processing #5/7
[2022-05-27 10:09:30,563] ERROR: Proxy file at adsfvv.gkk not found. Ignoring
[2022-05-27 11:27:24,411] INFO: Processing #2/2
[2022-05-27 11:36:06,133] ERROR: No source is configured for https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b... skipping
[2022-05-27 11:36:06,134] INFO: Scraping https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b failed
[2022-05-27 11:36:06,134] ERROR: No source is configured for https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b... skipping
[2022-05-27 11:36:06,134] INFO: Scraping https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b failed
[2022-05-27 11:36:06,134] INFO: Processing #2/2
[2022-05-27 11:38:43,738] INFO: Processing #2/2
[2022-05-27 12:11:27,459] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/10.1111/petr.14281
[2022-05-27 12:11:29,897] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/10.1111/petr.14281
[2022-05-27 12:11:32,311] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/10.1111/petr.14281
[2022-05-27 12:11:35,045] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/10.1111/petr.14281
[2022-05-27 14:22:52,292] ERROR: No source is configured for h... skipping
[2022-05-27 14:22:52,293] INFO: Scraping h failed
[2022-05-27 14:22:52,294] ERROR: No source is configured for t... skipping
[2022-05-27 14:22:52,294] INFO: Scraping t failed
[2022-05-27 14:22:52,295] INFO: Processing #2/206
[2022-05-27 14:22:52,295] ERROR: No source is configured for t... skipping
[2022-05-27 14:22:52,296] INFO: Scraping t failed
[2022-05-27 14:22:52,297] ERROR: No source is configured for p... skipping
[2022-05-27 14:22:52,297] INFO: Scraping p failed
[2022-05-27 14:22:52,298] INFO: Processing #4/206
[2022-05-27 14:22:52,298] ERROR: No source is configured for s... skipping
[2022-05-27 14:22:52,299] INFO: Scraping s failed
[2022-05-27 14:22:52,299] ERROR: No source is configured for :... skipping
[2022-05-27 14:22:52,300] INFO: Scraping : failed
[2022-05-27 14:22:52,300] INFO: Processing #6/206
[2022-05-27 14:22:52,301] ERROR: No source is configured for /... skipping
[2022-05-27 14:22:52,302] INFO: Scraping / failed
[2022-05-27 14:22:52,302] ERROR: No source is configured for /... skipping
[2022-05-27 14:22:52,303] INFO: Scraping / failed
[2022-05-27 14:22:52,303] INFO: Processing #8/206
[2022-05-27 14:22:52,304] ERROR: No source is configured for w... skipping
[2022-05-27 14:22:52,305] INFO: Scraping w failed
[2022-05-27 14:22:52,305] ERROR: No source is configured for w... skipping
[2022-05-27 14:22:52,306] INFO: Scraping w failed
[2022-05-27 14:22:52,306] INFO: Processing #10/206
[2022-05-27 14:22:52,307] ERROR: No source is configured for w... skipping
[2022-05-27 14:22:52,307] INFO: Scraping w failed
[2022-05-27 14:22:52,308] ERROR: No source is configured for .... skipping
[2022-05-27 14:22:52,308] INFO: Scraping . failed
[2022-05-27 14:22:52,310] INFO: Processing #12/206
[2022-05-27 14:22:52,310] ERROR: No source is configured for a... skipping
[2022-05-27 14:22:52,311] INFO: Scraping a failed
[2022-05-27 14:22:52,312] ERROR: No source is configured for m... skipping
[2022-05-27 14:22:52,312] INFO: Scraping m failed
[2022-05-27 14:22:52,313] INFO: Processing #14/206
[2022-05-27 14:22:52,313] ERROR: No source is configured for a... skipping
[2022-05-27 14:22:52,314] INFO: Scraping a failed
[2022-05-27 14:22:52,314] ERROR: No source is configured for z... skipping
[2022-05-27 14:22:52,315] INFO: Scraping z failed
[2022-05-27 14:22:52,315] INFO: Processing #16/206
[2022-05-27 14:22:52,316] ERROR: No source is configured for o... skipping
[2022-05-27 14:22:52,317] INFO: Scraping o failed
[2022-05-27 14:22:52,317] ERROR: No source is configured for n... skipping
[2022-05-27 14:22:52,318] INFO: Scraping n failed
[2022-05-27 14:22:52,319] INFO: Processing #18/206
[2022-05-27 14:22:52,320] ERROR: No source is configured for .... skipping
[2022-05-27 14:22:52,320] INFO: Scraping . failed
[2022-05-27 14:22:52,321] ERROR: No source is configured for c... skipping
[2022-05-27 14:22:52,322] INFO: Scraping c failed
[2022-05-27 14:22:52,322] INFO: Processing #20/206
[2022-05-27 14:22:52,323] ERROR: No source is configured for o... skipping
[2022-05-27 14:22:52,323] INFO: Scraping o failed
[2022-05-27 14:22:52,324] ERROR: No source is configured for m... skipping
[2022-05-27 14:22:52,325] INFO: Scraping m failed
[2022-05-27 14:22:52,325] INFO: Processing #22/206
[2022-05-27 14:22:52,326] ERROR: No source is configured for /... skipping
[2022-05-27 14:22:52,326] INFO: Scraping / failed
[2022-05-27 14:22:52,327] ERROR: No source is configured for s... skipping
[2022-05-27 14:22:52,327] INFO: Scraping s failed
[2022-05-27 14:22:52,328] INFO: Processing #24/206
[2022-05-27 14:22:52,328] ERROR: No source is configured for ?... skipping
[2022-05-27 14:22:52,329] INFO: Scraping ? failed
[2022-05-27 14:22:52,330] ERROR: No source is configured for k... skipping
[2022-05-27 14:22:52,330] INFO: Scraping k failed
[2022-05-27 14:22:52,331] INFO: Processing #26/206
[2022-05-27 14:22:52,331] ERROR: No source is configured for =... skipping
[2022-05-27 14:22:52,332] INFO: Scraping = failed
[2022-05-27 14:22:52,332] ERROR: No source is configured for %... skipping
[2022-05-27 14:22:52,333] INFO: Scraping % failed
[2022-05-27 14:22:52,333] INFO: Processing #28/206
[2022-05-27 14:22:52,334] ERROR: No source is configured for 2... skipping
[2022-05-27 14:22:52,335] INFO: Scraping 2 failed
[2022-05-27 14:22:52,336] ERROR: No source is configured for 2... skipping
[2022-05-27 14:22:52,337] INFO: Scraping 2 failed
[2022-05-27 14:22:52,337] INFO: Processing #30/206
[2022-05-27 14:22:52,338] ERROR: No source is configured for u... skipping
[2022-05-27 14:22:52,338] INFO: Scraping u failed
[2022-05-27 14:22:52,339] ERROR: No source is configured for n... skipping
[2022-05-27 14:22:52,340] INFO: Scraping n failed
[2022-05-27 14:22:52,340] INFO: Processing #32/206
[2022-05-27 14:22:52,341] ERROR: No source is configured for i... skipping
[2022-05-27 14:22:52,341] INFO: Scraping i failed
[2022-05-27 14:22:52,342] ERROR: No source is configured for v... skipping
[2022-05-27 14:22:52,342] INFO: Scraping v failed
[2022-05-27 14:22:52,343] INFO: Processing #34/206
[2022-05-27 14:22:52,343] ERROR: No source is configured for e... skipping
[2022-05-27 14:22:52,344] INFO: Scraping e failed
[2022-05-27 14:22:52,344] ERROR: No source is configured for r... skipping
[2022-05-27 14:22:52,345] INFO: Scraping r failed
[2022-05-27 14:22:52,345] INFO: Processing #36/206
[2022-05-27 14:22:52,346] ERROR: No source is configured for s... skipping
[2022-05-27 14:22:52,347] INFO: Scraping s failed
[2022-05-27 14:22:52,347] ERROR: No source is configured for i... skipping
[2022-05-27 14:22:52,348] INFO: Scraping i failed
[2022-05-27 14:22:52,348] INFO: Processing #38/206
[2022-05-27 14:22:52,349] ERROR: No source is configured for t... skipping
[2022-05-27 14:22:52,349] INFO: Scraping t failed
[2022-05-27 14:22:52,350] ERROR: No source is configured for y... skipping
[2022-05-27 14:22:52,350] INFO: Scraping y failed
[2022-05-27 14:22:52,351] INFO: Processing #40/206
[2022-05-27 14:22:52,351] ERROR: No source is configured for +... skipping
[2022-05-27 14:22:52,352] INFO: Scraping + failed
[2022-05-27 14:22:52,353] ERROR: No source is configured for o... skipping
[2022-05-27 14:22:52,353] INFO: Scraping o failed
[2022-05-27 14:22:52,354] INFO: Processing #42/206
[2022-05-27 14:22:52,354] ERROR: No source is configured for f... skipping
[2022-05-27 14:22:52,355] INFO: Scraping f failed
[2022-05-27 14:22:52,355] ERROR: No source is configured for %... skipping
[2022-05-27 14:22:52,356] INFO: Scraping % failed
[2022-05-27 14:22:52,356] INFO: Processing #44/206
[2022-05-27 14:22:52,357] ERROR: No source is configured for 2... skipping
[2022-05-27 14:22:52,357] INFO: Scraping 2 failed
[2022-05-27 14:22:52,358] ERROR: No source is configured for 2... skipping
[2022-05-27 14:22:52,359] INFO: Scraping 2 failed
[2022-05-27 14:22:52,359] INFO: Processing #46/206
[2022-05-27 14:22:52,360] ERROR: No source is configured for &... skipping
[2022-05-27 14:22:52,360] INFO: Scraping & failed
[2022-05-27 14:22:52,361] ERROR: No source is configured for i... skipping
[2022-05-27 14:22:52,361] INFO: Scraping i failed
[2022-05-27 14:22:52,362] INFO: Processing #48/206
[2022-05-27 14:22:52,362] ERROR: No source is configured for =... skipping
[2022-05-27 14:22:52,363] INFO: Scraping = failed
[2022-05-27 14:22:52,364] ERROR: No source is configured for s... skipping
[2022-05-27 14:22:52,364] INFO: Scraping s failed
[2022-05-27 14:22:52,365] INFO: Processing #50/206
[2022-05-27 14:22:52,365] ERROR: No source is configured for t... skipping
[2022-05-27 14:22:52,366] INFO: Scraping t failed
[2022-05-27 14:22:52,366] ERROR: No source is configured for r... skipping
[2022-05-27 14:22:52,367] INFO: Scraping r failed
[2022-05-27 14:22:52,368] INFO: Processing #52/206
[2022-05-27 14:22:52,368] ERROR: No source is configured for i... skipping
[2022-05-27 14:22:52,369] INFO: Scraping i failed
[2022-05-27 14:22:52,369] ERROR: No source is configured for p... skipping
[2022-05-27 14:22:52,370] INFO: Scraping p failed
[2022-05-27 14:22:52,370] INFO: Processing #54/206
[2022-05-27 14:22:52,371] ERROR: No source is configured for b... skipping
[2022-05-27 14:22:52,371] INFO: Scraping b failed
[2022-05-27 14:22:52,372] ERROR: No source is configured for o... skipping
[2022-05-27 14:22:52,373] INFO: Scraping o failed
[2022-05-27 14:22:52,373] INFO: Processing #56/206
[2022-05-27 14:22:52,374] ERROR: No source is configured for o... skipping
[2022-05-27 14:22:52,374] INFO: Scraping o failed
[2022-05-27 14:22:52,375] ERROR: No source is configured for k... skipping
[2022-05-27 14:22:52,375] INFO: Scraping k failed
[2022-05-27 14:22:52,376] INFO: Processing #58/206
[2022-05-27 14:22:52,376] ERROR: No source is configured for s... skipping
[2022-05-27 14:22:52,377] INFO: Scraping s failed
[2022-05-27 14:22:52,377] ERROR: No source is configured for &... skipping
[2022-05-27 14:22:52,378] INFO: Scraping & failed
[2022-05-27 14:22:52,378] INFO: Processing #60/206
[2022-05-27 14:22:52,379] ERROR: No source is configured for s... skipping
[2022-05-27 14:22:52,380] INFO: Scraping s failed
[2022-05-27 14:22:52,380] ERROR: No source is configured for =... skipping
[2022-05-27 14:22:52,381] INFO: Scraping = failed
[2022-05-27 14:22:52,381] INFO: Processing #62/206
[2022-05-27 14:22:52,382] ERROR: No source is configured for d... skipping
[2022-05-27 14:22:52,382] INFO: Scraping d failed
[2022-05-27 14:22:52,383] ERROR: No source is configured for a... skipping
[2022-05-27 14:22:52,384] INFO: Scraping a failed
[2022-05-27 14:22:52,384] INFO: Processing #64/206
[2022-05-27 14:22:52,385] ERROR: No source is configured for t... skipping
[2022-05-27 14:22:52,386] INFO: Scraping t failed
[2022-05-27 14:22:52,387] ERROR: No source is configured for e... skipping
[2022-05-27 14:22:52,387] INFO: Scraping e failed
[2022-05-27 14:22:52,388] INFO: Processing #66/206
[2022-05-27 14:22:52,388] ERROR: No source is configured for r... skipping
[2022-05-27 14:22:52,389] INFO: Scraping r failed
[2022-05-27 14:22:52,390] ERROR: No source is configured for a... skipping
[2022-05-27 14:22:52,390] INFO: Scraping a failed
[2022-05-27 14:22:52,391] INFO: Processing #68/206
[2022-05-27 14:22:52,391] ERROR: No source is configured for n... skipping
[2022-05-27 14:22:52,392] INFO: Scraping n failed
[2022-05-27 14:22:52,392] ERROR: No source is configured for k... skipping
[2022-05-27 14:22:52,393] INFO: Scraping k failed
[2022-05-27 14:22:52,394] INFO: Processing #70/206
[2022-05-27 14:22:52,394] ERROR: No source is configured for &... skipping
[2022-05-27 14:22:52,395] INFO: Scraping & failed
[2022-05-27 14:22:52,395] ERROR: No source is configured for A... skipping
[2022-05-27 14:22:52,396] INFO: Scraping A failed
[2022-05-27 14:22:52,396] INFO: Processing #72/206
[2022-05-27 14:22:52,397] ERROR: No source is configured for d... skipping
[2022-05-27 14:22:52,397] INFO: Scraping d failed
[2022-05-27 14:22:52,398] ERROR: No source is configured for v... skipping
[2022-05-27 14:22:52,399] INFO: Scraping v failed
[2022-05-27 14:22:52,399] INFO: Processing #74/206
[2022-05-27 14:22:52,400] ERROR: No source is configured for -... skipping
[2022-05-27 14:22:52,400] INFO: Scraping - failed
[2022-05-27 14:22:52,401] ERROR: No source is configured for S... skipping
[2022-05-27 14:22:52,402] INFO: Scraping S failed
[2022-05-27 14:22:52,403] INFO: Processing #76/206
[2022-05-27 14:22:52,403] ERROR: No source is configured for r... skipping
[2022-05-27 14:22:52,404] INFO: Scraping r failed
[2022-05-27 14:22:52,405] ERROR: No source is configured for c... skipping
[2022-05-27 14:22:52,406] INFO: Scraping c failed
[2022-05-27 14:22:52,406] INFO: Processing #78/206
[2022-05-27 14:22:52,407] ERROR: No source is configured for h... skipping
[2022-05-27 14:22:52,407] INFO: Scraping h failed
[2022-05-27 14:22:52,409] ERROR: No source is configured for -... skipping
[2022-05-27 14:22:52,410] INFO: Scraping - failed
[2022-05-27 14:22:52,410] INFO: Processing #80/206
[2022-05-27 14:22:52,411] ERROR: No source is configured for B... skipping
[2022-05-27 14:22:52,411] INFO: Scraping B failed
[2022-05-27 14:22:52,412] ERROR: No source is configured for o... skipping
[2022-05-27 14:22:52,412] INFO: Scraping o failed
[2022-05-27 14:22:52,413] INFO: Processing #82/206
[2022-05-27 14:22:52,413] ERROR: No source is configured for o... skipping
[2022-05-27 14:22:52,414] INFO: Scraping o failed
[2022-05-27 14:22:52,414] ERROR: No source is configured for k... skipping
[2022-05-27 14:22:52,415] INFO: Scraping k failed
[2022-05-27 14:22:52,415] INFO: Processing #84/206
[2022-05-27 14:22:52,416] ERROR: No source is configured for s... skipping
[2022-05-27 14:22:52,417] INFO: Scraping s failed
[2022-05-27 14:22:52,417] ERROR: No source is configured for -... skipping
[2022-05-27 14:22:52,418] INFO: Scraping - failed
[2022-05-27 14:22:52,419] INFO: Processing #86/206
[2022-05-27 14:22:52,419] ERROR: No source is configured for S... skipping
[2022-05-27 14:22:52,420] INFO: Scraping S failed
[2022-05-27 14:22:52,421] ERROR: No source is configured for u... skipping
[2022-05-27 14:22:52,422] INFO: Scraping u failed
[2022-05-27 14:22:52,422] INFO: Processing #88/206
[2022-05-27 14:22:52,423] ERROR: No source is configured for b... skipping
[2022-05-27 14:22:52,423] INFO: Scraping b failed
[2022-05-27 14:22:52,424] ERROR: No source is configured for m... skipping
[2022-05-27 14:22:52,424] INFO: Scraping m failed
[2022-05-27 14:22:52,425] INFO: Processing #90/206
[2022-05-27 14:22:52,426] ERROR: No source is configured for i... skipping
[2022-05-27 14:22:52,426] INFO: Scraping i failed
[2022-05-27 14:22:52,427] ERROR: No source is configured for t... skipping
[2022-05-27 14:22:52,427] INFO: Scraping t failed
[2022-05-27 14:22:52,428] INFO: Processing #92/206
[2022-05-27 14:22:52,428] ERROR: No source is configured for .... skipping
[2022-05-27 14:22:52,429] INFO: Scraping . failed
[2022-05-27 14:22:52,429] ERROR: No source is configured for x... skipping
[2022-05-27 14:22:52,430] INFO: Scraping x failed
[2022-05-27 14:22:52,430] INFO: Processing #94/206
[2022-05-27 14:22:52,431] ERROR: No source is configured for =... skipping
[2022-05-27 14:22:52,431] INFO: Scraping = failed
[2022-05-27 14:22:52,432] ERROR: No source is configured for 2... skipping
[2022-05-27 14:22:52,433] INFO: Scraping 2 failed
[2022-05-27 14:22:52,433] INFO: Processing #96/206
[2022-05-27 14:22:52,434] ERROR: No source is configured for 6... skipping
[2022-05-27 14:22:52,435] INFO: Scraping 6 failed
[2022-05-27 14:22:52,435] ERROR: No source is configured for &... skipping
[2022-05-27 14:22:52,436] INFO: Scraping & failed
[2022-05-27 14:22:52,437] INFO: Processing #98/206
[2022-05-27 14:22:52,437] ERROR: No source is configured for A... skipping
[2022-05-27 14:22:52,438] INFO: Scraping A failed
[2022-05-27 14:22:52,439] ERROR: No source is configured for d... skipping
[2022-05-27 14:22:52,439] INFO: Scraping d failed
[2022-05-27 14:22:52,440] INFO: Processing #100/206
[2022-05-27 14:22:52,440] ERROR: No source is configured for v... skipping
[2022-05-27 14:22:52,441] INFO: Scraping v failed
[2022-05-27 14:22:52,442] ERROR: No source is configured for -... skipping
[2022-05-27 14:22:52,449] INFO: Scraping - failed
[2022-05-27 14:22:52,450] INFO: Processing #102/206
[2022-05-27 14:22:52,450] ERROR: No source is configured for S... skipping
[2022-05-27 14:22:52,451] INFO: Scraping S failed
[2022-05-27 14:22:52,452] ERROR: No source is configured for r... skipping
[2022-05-27 14:22:52,453] INFO: Scraping r failed
[2022-05-27 14:22:52,453] INFO: Processing #104/206
[2022-05-27 14:22:52,454] ERROR: No source is configured for c... skipping
[2022-05-27 14:22:52,455] INFO: Scraping c failed
[2022-05-27 14:22:52,455] ERROR: No source is configured for h... skipping
[2022-05-27 14:22:52,456] INFO: Scraping h failed
[2022-05-27 14:22:52,457] INFO: Processing #106/206
[2022-05-27 14:22:52,457] ERROR: No source is configured for -... skipping
[2022-05-27 14:22:52,458] INFO: Scraping - failed
[2022-05-27 14:22:52,458] ERROR: No source is configured for B... skipping
[2022-05-27 14:22:52,459] INFO: Scraping B failed
[2022-05-27 14:22:52,459] INFO: Processing #108/206
[2022-05-27 14:22:52,460] ERROR: No source is configured for o... skipping
[2022-05-27 14:22:52,461] INFO: Scraping o failed
[2022-05-27 14:22:52,461] ERROR: No source is configured for o... skipping
[2022-05-27 14:22:52,462] INFO: Scraping o failed
[2022-05-27 14:22:52,462] INFO: Processing #110/206
[2022-05-27 14:22:52,463] ERROR: No source is configured for k... skipping
[2022-05-27 14:22:52,463] INFO: Scraping k failed
[2022-05-27 14:22:52,464] ERROR: No source is configured for s... skipping
[2022-05-27 14:22:52,464] INFO: Scraping s failed
[2022-05-27 14:22:52,465] INFO: Processing #112/206
[2022-05-27 14:22:52,465] ERROR: No source is configured for -... skipping
[2022-05-27 14:22:52,466] INFO: Scraping - failed
[2022-05-27 14:22:52,467] ERROR: No source is configured for S... skipping
[2022-05-27 14:22:52,468] INFO: Scraping S failed
[2022-05-27 14:22:52,468] INFO: Processing #114/206
[2022-05-27 14:22:52,469] ERROR: No source is configured for u... skipping
[2022-05-27 14:22:52,470] INFO: Scraping u failed
[2022-05-27 14:22:52,470] ERROR: No source is configured for b... skipping
[2022-05-27 14:22:52,471] INFO: Scraping b failed
[2022-05-27 14:22:52,472] INFO: Processing #116/206
[2022-05-27 14:22:52,472] ERROR: No source is configured for m... skipping
[2022-05-27 14:22:52,473] INFO: Scraping m failed
[2022-05-27 14:22:52,473] ERROR: No source is configured for i... skipping
[2022-05-27 14:22:52,474] INFO: Scraping i failed
[2022-05-27 14:22:52,474] INFO: Processing #118/206
[2022-05-27 14:22:52,475] ERROR: No source is configured for t... skipping
[2022-05-27 14:22:52,475] INFO: Scraping t failed
[2022-05-27 14:22:52,476] ERROR: No source is configured for .... skipping
[2022-05-27 14:22:52,477] INFO: Scraping . failed
[2022-05-27 14:22:52,477] INFO: Processing #120/206
[2022-05-27 14:22:52,478] ERROR: No source is configured for y... skipping
[2022-05-27 14:22:52,478] INFO: Scraping y failed
[2022-05-27 14:22:52,479] ERROR: No source is configured for =... skipping
[2022-05-27 14:22:52,479] INFO: Scraping = failed
[2022-05-27 14:22:52,480] INFO: Processing #122/206
[2022-05-27 14:22:52,480] ERROR: No source is configured for 2... skipping
[2022-05-27 14:22:52,481] INFO: Scraping 2 failed
[2022-05-27 14:22:52,481] ERROR: No source is configured for 0... skipping
[2022-05-27 14:22:52,482] INFO: Scraping 0 failed
[2022-05-27 14:22:52,483] INFO: Processing #124/206
[2022-05-27 14:22:52,483] ERROR: No source is configured for &... skipping
[2022-05-27 14:22:52,484] INFO: Scraping & failed
[2022-05-27 14:22:52,484] ERROR: No source is configured for f... skipping
[2022-05-27 14:22:52,485] INFO: Scraping f failed
[2022-05-27 14:22:52,485] INFO: Processing #126/206
[2022-05-27 14:22:52,486] ERROR: No source is configured for i... skipping
[2022-05-27 14:22:52,486] INFO: Scraping i failed
[2022-05-27 14:22:52,487] ERROR: No source is configured for e... skipping
[2022-05-27 14:22:52,488] INFO: Scraping e failed
[2022-05-27 14:22:52,488] INFO: Processing #128/206
[2022-05-27 14:22:52,489] ERROR: No source is configured for l... skipping
[2022-05-27 14:22:52,489] INFO: Scraping l failed
[2022-05-27 14:22:52,490] ERROR: No source is configured for d... skipping
[2022-05-27 14:22:52,491] INFO: Scraping d failed
[2022-05-27 14:22:52,491] INFO: Processing #130/206
[2022-05-27 14:22:52,492] ERROR: No source is configured for -... skipping
[2022-05-27 14:22:52,492] INFO: Scraping - failed
[2022-05-27 14:22:52,493] ERROR: No source is configured for d... skipping
[2022-05-27 14:22:52,493] INFO: Scraping d failed
[2022-05-27 14:22:52,494] INFO: Processing #132/206
[2022-05-27 14:22:52,494] ERROR: No source is configured for a... skipping
[2022-05-27 14:22:52,495] INFO: Scraping a failed
[2022-05-27 14:22:52,496] ERROR: No source is configured for t... skipping
[2022-05-27 14:22:52,496] INFO: Scraping t failed
[2022-05-27 14:22:52,497] INFO: Processing #134/206
[2022-05-27 14:22:52,497] ERROR: No source is configured for e... skipping
[2022-05-27 14:22:52,498] INFO: Scraping e failed
[2022-05-27 14:22:52,498] ERROR: No source is configured for m... skipping
[2022-05-27 14:22:52,499] INFO: Scraping m failed
[2022-05-27 14:22:52,500] INFO: Processing #136/206
[2022-05-27 14:22:52,500] ERROR: No source is configured for o... skipping
[2022-05-27 14:22:52,501] INFO: Scraping o failed
[2022-05-27 14:22:52,503] ERROR: No source is configured for d... skipping
[2022-05-27 14:22:52,504] INFO: Scraping d failed
[2022-05-27 14:22:52,505] INFO: Processing #138/206
[2022-05-27 14:22:52,505] ERROR: No source is configured for =... skipping
[2022-05-27 14:22:52,506] INFO: Scraping = failed
[2022-05-27 14:22:52,507] ERROR: No source is configured for 5... skipping
[2022-05-27 14:22:52,507] INFO: Scraping 5 failed
[2022-05-27 14:22:52,508] INFO: Processing #140/206
[2022-05-27 14:22:52,508] ERROR: No source is configured for &... skipping
[2022-05-27 14:22:52,509] INFO: Scraping & failed
[2022-05-27 14:22:52,510] ERROR: No source is configured for f... skipping
[2022-05-27 14:22:52,510] INFO: Scraping f failed
[2022-05-27 14:22:52,511] INFO: Processing #142/206
[2022-05-27 14:22:52,511] ERROR: No source is configured for i... skipping
[2022-05-27 14:22:52,512] INFO: Scraping i failed
[2022-05-27 14:22:52,512] ERROR: No source is configured for e... skipping
[2022-05-27 14:22:52,513] INFO: Scraping e failed
[2022-05-27 14:22:52,514] INFO: Processing #144/206
[2022-05-27 14:22:52,514] ERROR: No source is configured for l... skipping
[2022-05-27 14:22:52,515] INFO: Scraping l failed
[2022-05-27 14:22:52,515] ERROR: No source is configured for d... skipping
[2022-05-27 14:22:52,516] INFO: Scraping d failed
[2022-05-27 14:22:52,516] INFO: Processing #146/206
[2022-05-27 14:22:52,517] ERROR: No source is configured for -... skipping
[2022-05-27 14:22:52,518] INFO: Scraping - failed
[2022-05-27 14:22:52,519] ERROR: No source is configured for d... skipping
[2022-05-27 14:22:52,520] INFO: Scraping d failed
[2022-05-27 14:22:52,521] INFO: Processing #148/206
[2022-05-27 14:22:52,521] ERROR: No source is configured for a... skipping
[2022-05-27 14:22:52,522] INFO: Scraping a failed
[2022-05-27 14:22:52,522] ERROR: No source is configured for t... skipping
[2022-05-27 14:22:52,523] INFO: Scraping t failed
[2022-05-27 14:22:52,523] INFO: Processing #150/206
[2022-05-27 14:22:52,524] ERROR: No source is configured for e... skipping
[2022-05-27 14:22:52,525] INFO: Scraping e failed
[2022-05-27 14:22:52,525] ERROR: No source is configured for o... skipping
[2022-05-27 14:22:52,526] INFO: Scraping o failed
[2022-05-27 14:22:52,526] INFO: Processing #152/206
[2022-05-27 14:22:52,527] ERROR: No source is configured for p... skipping
[2022-05-27 14:22:52,527] INFO: Scraping p failed
[2022-05-27 14:22:52,528] ERROR: No source is configured for =... skipping
[2022-05-27 14:22:52,529] INFO: Scraping = failed
[2022-05-27 14:22:52,529] INFO: Processing #154/206
[2022-05-27 14:22:52,530] ERROR: No source is configured for D... skipping
[2022-05-27 14:22:52,530] INFO: Scraping D failed
[2022-05-27 14:22:52,531] ERROR: No source is configured for u... skipping
[2022-05-27 14:22:52,531] INFO: Scraping u failed
[2022-05-27 14:22:52,532] INFO: Processing #156/206
[2022-05-27 14:22:52,532] ERROR: No source is configured for r... skipping
[2022-05-27 14:22:52,533] INFO: Scraping r failed
[2022-05-27 14:22:52,534] ERROR: No source is configured for i... skipping
[2022-05-27 14:22:52,535] INFO: Scraping i failed
[2022-05-27 14:22:52,535] INFO: Processing #158/206
[2022-05-27 14:22:52,536] ERROR: No source is configured for n... skipping
[2022-05-27 14:22:52,537] INFO: Scraping n failed
[2022-05-27 14:22:52,538] ERROR: No source is configured for g... skipping
[2022-05-27 14:22:52,538] INFO: Scraping g failed
[2022-05-27 14:22:52,539] INFO: Processing #160/206
[2022-05-27 14:22:52,539] ERROR: No source is configured for &... skipping
[2022-05-27 14:22:52,540] INFO: Scraping & failed
[2022-05-27 14:22:52,541] ERROR: No source is configured for f... skipping
[2022-05-27 14:22:52,541] INFO: Scraping f failed
[2022-05-27 14:22:52,542] INFO: Processing #162/206
[2022-05-27 14:22:52,542] ERROR: No source is configured for i... skipping
[2022-05-27 14:22:52,543] INFO: Scraping i failed
[2022-05-27 14:22:52,543] ERROR: No source is configured for e... skipping
[2022-05-27 14:22:52,544] INFO: Scraping e failed
[2022-05-27 14:22:52,544] INFO: Processing #164/206
[2022-05-27 14:22:52,545] ERROR: No source is configured for l... skipping
[2022-05-27 14:22:52,545] INFO: Scraping l failed
[2022-05-27 14:22:52,546] ERROR: No source is configured for d... skipping
[2022-05-27 14:22:52,547] INFO: Scraping d failed
[2022-05-27 14:22:52,547] INFO: Processing #166/206
[2022-05-27 14:22:52,548] ERROR: No source is configured for -... skipping
[2022-05-27 14:22:52,548] INFO: Scraping - failed
[2022-05-27 14:22:52,549] ERROR: No source is configured for d... skipping
[2022-05-27 14:22:52,549] INFO: Scraping d failed
[2022-05-27 14:22:52,550] INFO: Processing #168/206
[2022-05-27 14:22:52,551] ERROR: No source is configured for a... skipping
[2022-05-27 14:22:52,552] INFO: Scraping a failed
[2022-05-27 14:22:52,552] ERROR: No source is configured for t... skipping
[2022-05-27 14:22:52,553] INFO: Scraping t failed
[2022-05-27 14:22:52,554] INFO: Processing #170/206
[2022-05-27 14:22:52,554] ERROR: No source is configured for e... skipping
[2022-05-27 14:22:52,555] INFO: Scraping e failed
[2022-05-27 14:22:52,556] ERROR: No source is configured for y... skipping
[2022-05-27 14:22:52,556] INFO: Scraping y failed
[2022-05-27 14:22:52,557] INFO: Processing #172/206
[2022-05-27 14:22:52,557] ERROR: No source is configured for e... skipping
[2022-05-27 14:22:52,558] INFO: Scraping e failed
[2022-05-27 14:22:52,558] ERROR: No source is configured for a... skipping
[2022-05-27 14:22:52,559] INFO: Scraping a failed
[2022-05-27 14:22:52,560] INFO: Processing #174/206
[2022-05-27 14:22:52,560] ERROR: No source is configured for r... skipping
[2022-05-27 14:22:52,561] INFO: Scraping r failed
[2022-05-27 14:22:52,561] ERROR: No source is configured for =... skipping
[2022-05-27 14:22:52,562] INFO: Scraping = failed
[2022-05-27 14:22:52,562] INFO: Processing #176/206
[2022-05-27 14:22:52,563] ERROR: No source is configured for 2... skipping
[2022-05-27 14:22:52,563] INFO: Scraping 2 failed
[2022-05-27 14:22:52,564] ERROR: No source is configured for 0... skipping
[2022-05-27 14:22:52,564] INFO: Scraping 0 failed
[2022-05-27 14:22:52,565] INFO: Processing #178/206
[2022-05-27 14:22:52,565] ERROR: No source is configured for 2... skipping
[2022-05-27 14:22:52,566] INFO: Scraping 2 failed
[2022-05-27 14:22:52,567] ERROR: No source is configured for 2... skipping
[2022-05-27 14:22:52,568] INFO: Scraping 2 failed
[2022-05-27 14:22:52,568] INFO: Processing #180/206
[2022-05-27 14:22:52,569] ERROR: No source is configured for &... skipping
[2022-05-27 14:22:52,570] INFO: Scraping & failed
[2022-05-27 14:22:52,570] ERROR: No source is configured for u... skipping
[2022-05-27 14:22:52,571] INFO: Scraping u failed
[2022-05-27 14:22:52,572] INFO: Processing #182/206
[2022-05-27 14:22:52,572] ERROR: No source is configured for n... skipping
[2022-05-27 14:22:52,573] INFO: Scraping n failed
[2022-05-27 14:22:52,574] ERROR: No source is configured for f... skipping
[2022-05-27 14:22:52,574] INFO: Scraping f failed
[2022-05-27 14:22:52,575] INFO: Processing #184/206
[2022-05-27 14:22:52,575] ERROR: No source is configured for i... skipping
[2022-05-27 14:22:52,576] INFO: Scraping i failed
[2022-05-27 14:22:52,576] ERROR: No source is configured for l... skipping
[2022-05-27 14:22:52,577] INFO: Scraping l failed
[2022-05-27 14:22:52,577] INFO: Processing #186/206
[2022-05-27 14:22:52,578] ERROR: No source is configured for t... skipping
[2022-05-27 14:22:52,578] INFO: Scraping t failed
[2022-05-27 14:22:52,579] ERROR: No source is configured for e... skipping
[2022-05-27 14:22:52,580] INFO: Scraping e failed
[2022-05-27 14:22:52,580] INFO: Processing #188/206
[2022-05-27 14:22:52,581] ERROR: No source is configured for r... skipping
[2022-05-27 14:22:52,581] INFO: Scraping r failed
[2022-05-27 14:22:52,582] ERROR: No source is configured for e... skipping
[2022-05-27 14:22:52,582] INFO: Scraping e failed
[2022-05-27 14:22:52,583] INFO: Processing #190/206
[2022-05-27 14:22:52,583] ERROR: No source is configured for d... skipping
[2022-05-27 14:22:52,584] INFO: Scraping d failed
[2022-05-27 14:22:52,585] ERROR: No source is configured for =... skipping
[2022-05-27 14:22:52,586] INFO: Scraping = failed
[2022-05-27 14:22:52,587] INFO: Processing #192/206
[2022-05-27 14:22:52,587] ERROR: No source is configured for 1... skipping
[2022-05-27 14:22:52,588] INFO: Scraping 1 failed
[2022-05-27 14:22:52,589] ERROR: No source is configured for &... skipping
[2022-05-27 14:22:52,589] INFO: Scraping & failed
[2022-05-27 14:22:52,590] INFO: Processing #194/206
[2022-05-27 14:22:52,590] ERROR: No source is configured for r... skipping
[2022-05-27 14:22:52,591] INFO: Scraping r failed
[2022-05-27 14:22:52,591] ERROR: No source is configured for e... skipping
[2022-05-27 14:22:52,592] INFO: Scraping e failed
[2022-05-27 14:22:52,593] INFO: Processing #196/206
[2022-05-27 14:22:52,593] ERROR: No source is configured for f... skipping
[2022-05-27 14:22:52,594] INFO: Scraping f failed
[2022-05-27 14:22:52,594] ERROR: No source is configured for =... skipping
[2022-05-27 14:22:52,595] INFO: Scraping = failed
[2022-05-27 14:22:52,595] INFO: Processing #198/206
[2022-05-27 14:22:52,596] ERROR: No source is configured for s... skipping
[2022-05-27 14:22:52,596] INFO: Scraping s failed
[2022-05-27 14:22:52,597] ERROR: No source is configured for r... skipping
[2022-05-27 14:22:52,598] INFO: Scraping r failed
[2022-05-27 14:22:52,598] INFO: Processing #200/206
[2022-05-27 14:22:52,599] ERROR: No source is configured for _... skipping
[2022-05-27 14:22:52,599] INFO: Scraping _ failed
[2022-05-27 14:22:52,600] ERROR: No source is configured for a... skipping
[2022-05-27 14:22:52,601] INFO: Scraping a failed
[2022-05-27 14:22:52,602] INFO: Processing #202/206
[2022-05-27 14:22:52,602] ERROR: No source is configured for d... skipping
[2022-05-27 14:22:52,603] INFO: Scraping d failed
[2022-05-27 14:22:52,604] ERROR: No source is configured for v... skipping
[2022-05-27 14:22:52,605] INFO: Scraping v failed
[2022-05-27 14:22:52,605] INFO: Processing #204/206
[2022-05-27 14:22:52,606] ERROR: No source is configured for _... skipping
[2022-05-27 14:22:52,606] INFO: Scraping _ failed
[2022-05-27 14:22:52,607] ERROR: No source is configured for b... skipping
[2022-05-27 14:22:52,607] INFO: Scraping b failed
[2022-05-27 14:22:52,608] INFO: Processing #206/206
[2022-05-27 14:29:34,977] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 111, in _handle_task
    return func(*args, **kwargs), None
TypeError: scrape_url() takes from 2 to 3 positional arguments but 207 were given
[2022-05-27 16:20:20,395] ERROR: No source is configured for h... skipping
[2022-05-27 16:20:20,395] INFO: Scraping h failed
[2022-05-27 16:20:20,396] ERROR: No source is configured for t... skipping
[2022-05-27 16:20:20,396] INFO: Scraping t failed
[2022-05-27 16:20:20,396] INFO: Processing #2/62
[2022-05-27 16:20:20,396] ERROR: No source is configured for t... skipping
[2022-05-27 16:20:20,396] INFO: Scraping t failed
[2022-05-27 16:20:20,396] ERROR: No source is configured for p... skipping
[2022-05-27 16:20:20,397] INFO: Scraping p failed
[2022-05-27 16:20:20,397] INFO: Processing #4/62
[2022-05-27 16:20:20,397] ERROR: No source is configured for :... skipping
[2022-05-27 16:20:20,397] INFO: Scraping : failed
[2022-05-27 16:20:20,397] ERROR: No source is configured for /... skipping
[2022-05-27 16:20:20,397] INFO: Scraping / failed
[2022-05-27 16:20:20,398] INFO: Processing #6/62
[2022-05-27 16:20:20,398] ERROR: No source is configured for /... skipping
[2022-05-27 16:20:20,398] INFO: Scraping / failed
[2022-05-27 16:20:20,398] ERROR: No source is configured for a... skipping
[2022-05-27 16:20:20,398] INFO: Scraping a failed
[2022-05-27 16:20:20,398] INFO: Processing #8/62
[2022-05-27 16:20:20,398] ERROR: No source is configured for p... skipping
[2022-05-27 16:20:20,399] INFO: Scraping p failed
[2022-05-27 16:20:20,399] ERROR: No source is configured for i... skipping
[2022-05-27 16:20:20,399] INFO: Scraping i failed
[2022-05-27 16:20:20,399] INFO: Processing #10/62
[2022-05-27 16:20:20,399] ERROR: No source is configured for .... skipping
[2022-05-27 16:20:20,399] INFO: Scraping . failed
[2022-05-27 16:20:20,400] ERROR: No source is configured for c... skipping
[2022-05-27 16:20:20,400] INFO: Scraping c failed
[2022-05-27 16:20:20,400] INFO: Processing #12/62
[2022-05-27 16:20:20,400] ERROR: No source is configured for r... skipping
[2022-05-27 16:20:20,400] INFO: Scraping r failed
[2022-05-27 16:20:20,400] ERROR: No source is configured for o... skipping
[2022-05-27 16:20:20,401] INFO: Scraping o failed
[2022-05-27 16:20:20,401] INFO: Processing #14/62
[2022-05-27 16:20:20,401] ERROR: No source is configured for s... skipping
[2022-05-27 16:20:20,401] INFO: Scraping s failed
[2022-05-27 16:20:20,401] ERROR: No source is configured for s... skipping
[2022-05-27 16:20:20,401] INFO: Scraping s failed
[2022-05-27 16:20:20,401] INFO: Processing #16/62
[2022-05-27 16:20:20,402] ERROR: No source is configured for r... skipping
[2022-05-27 16:20:20,402] INFO: Scraping r failed
[2022-05-27 16:20:20,402] ERROR: No source is configured for e... skipping
[2022-05-27 16:20:20,402] INFO: Scraping e failed
[2022-05-27 16:20:20,403] INFO: Processing #18/62
[2022-05-27 16:20:20,403] ERROR: No source is configured for f... skipping
[2022-05-27 16:20:20,403] INFO: Scraping f failed
[2022-05-27 16:20:20,403] ERROR: No source is configured for .... skipping
[2022-05-27 16:20:20,403] INFO: Scraping . failed
[2022-05-27 16:20:20,403] INFO: Processing #20/62
[2022-05-27 16:20:20,403] ERROR: No source is configured for o... skipping
[2022-05-27 16:20:20,404] INFO: Scraping o failed
[2022-05-27 16:20:20,404] ERROR: No source is configured for r... skipping
[2022-05-27 16:20:20,404] INFO: Scraping r failed
[2022-05-27 16:20:20,404] INFO: Processing #22/62
[2022-05-27 16:20:20,404] ERROR: No source is configured for g... skipping
[2022-05-27 16:20:20,404] INFO: Scraping g failed
[2022-05-27 16:20:20,405] ERROR: No source is configured for /... skipping
[2022-05-27 16:20:20,405] INFO: Scraping / failed
[2022-05-27 16:20:20,405] INFO: Processing #24/62
[2022-05-27 16:20:20,405] ERROR: No source is configured for w... skipping
[2022-05-27 16:20:20,405] INFO: Scraping w failed
[2022-05-27 16:20:20,405] ERROR: No source is configured for o... skipping
[2022-05-27 16:20:20,406] INFO: Scraping o failed
[2022-05-27 16:20:20,406] INFO: Processing #26/62
[2022-05-27 16:20:20,406] ERROR: No source is configured for r... skipping
[2022-05-27 16:20:20,406] INFO: Scraping r failed
[2022-05-27 16:20:20,406] ERROR: No source is configured for k... skipping
[2022-05-27 16:20:20,406] INFO: Scraping k failed
[2022-05-27 16:20:20,406] INFO: Processing #28/62
[2022-05-27 16:20:20,407] ERROR: No source is configured for s... skipping
[2022-05-27 16:20:20,407] INFO: Scraping s failed
[2022-05-27 16:20:20,407] ERROR: No source is configured for /... skipping
[2022-05-27 16:20:20,407] INFO: Scraping / failed
[2022-05-27 16:20:20,407] INFO: Processing #30/62
[2022-05-27 16:20:20,407] ERROR: No source is configured for 1... skipping
[2022-05-27 16:20:20,408] INFO: Scraping 1 failed
[2022-05-27 16:20:20,408] ERROR: No source is configured for 0... skipping
[2022-05-27 16:20:20,408] INFO: Scraping 0 failed
[2022-05-27 16:20:20,408] INFO: Processing #32/62
[2022-05-27 16:20:20,408] ERROR: No source is configured for .... skipping
[2022-05-27 16:20:20,408] INFO: Scraping . failed
[2022-05-27 16:20:20,409] ERROR: No source is configured for 1... skipping
[2022-05-27 16:20:20,409] INFO: Scraping 1 failed
[2022-05-27 16:20:20,409] INFO: Processing #34/62
[2022-05-27 16:20:20,409] ERROR: No source is configured for 5... skipping
[2022-05-27 16:20:20,409] INFO: Scraping 5 failed
[2022-05-27 16:20:20,409] ERROR: No source is configured for 9... skipping
[2022-05-27 16:20:20,409] INFO: Scraping 9 failed
[2022-05-27 16:20:20,410] INFO: Processing #36/62
[2022-05-27 16:20:20,410] ERROR: No source is configured for 0... skipping
[2022-05-27 16:20:20,410] INFO: Scraping 0 failed
[2022-05-27 16:20:20,410] ERROR: No source is configured for /... skipping
[2022-05-27 16:20:20,410] INFO: Scraping / failed
[2022-05-27 16:20:20,410] INFO: Processing #38/62
[2022-05-27 16:20:20,411] ERROR: No source is configured for 1... skipping
[2022-05-27 16:20:20,411] INFO: Scraping 1 failed
[2022-05-27 16:20:20,411] ERROR: No source is configured for 9... skipping
[2022-05-27 16:20:20,411] INFO: Scraping 9 failed
[2022-05-27 16:20:20,411] INFO: Processing #40/62
[2022-05-27 16:20:20,411] ERROR: No source is configured for 8... skipping
[2022-05-27 16:20:20,412] INFO: Scraping 8 failed
[2022-05-27 16:20:20,412] ERROR: No source is configured for 2... skipping
[2022-05-27 16:20:20,412] INFO: Scraping 2 failed
[2022-05-27 16:20:20,412] INFO: Processing #42/62
[2022-05-27 16:20:20,412] ERROR: No source is configured for -... skipping
[2022-05-27 16:20:20,412] INFO: Scraping - failed
[2022-05-27 16:20:20,413] ERROR: No source is configured for 3... skipping
[2022-05-27 16:20:20,413] INFO: Scraping 3 failed
[2022-05-27 16:20:20,413] INFO: Processing #44/62
[2022-05-27 16:20:20,413] ERROR: No source is configured for 5... skipping
[2022-05-27 16:20:20,413] INFO: Scraping 5 failed
[2022-05-27 16:20:20,413] ERROR: No source is configured for 3... skipping
[2022-05-27 16:20:20,414] INFO: Scraping 3 failed
[2022-05-27 16:20:20,414] INFO: Processing #46/62
[2022-05-27 16:20:20,414] ERROR: No source is configured for 3... skipping
[2022-05-27 16:20:20,414] INFO: Scraping 3 failed
[2022-05-27 16:20:20,414] ERROR: No source is configured for .... skipping
[2022-05-27 16:20:20,414] INFO: Scraping . failed
[2022-05-27 16:20:20,414] INFO: Processing #48/62
[2022-05-27 16:20:20,415] ERROR: No source is configured for 2... skipping
[2022-05-27 16:20:20,415] INFO: Scraping 2 failed
[2022-05-27 16:20:20,415] ERROR: No source is configured for 0... skipping
[2022-05-27 16:20:20,415] INFO: Scraping 0 failed
[2022-05-27 16:20:20,415] INFO: Processing #50/62
[2022-05-27 16:20:20,415] ERROR: No source is configured for 2... skipping
[2022-05-27 16:20:20,416] INFO: Scraping 2 failed
[2022-05-27 16:20:20,416] ERROR: No source is configured for 2... skipping
[2022-05-27 16:20:20,416] INFO: Scraping 2 failed
[2022-05-27 16:20:20,416] INFO: Processing #52/62
[2022-05-27 16:20:20,416] ERROR: No source is configured for v... skipping
[2022-05-27 16:20:20,416] INFO: Scraping v failed
[2022-05-27 16:20:20,417] ERROR: No source is configured for 3... skipping
[2022-05-27 16:20:20,417] INFO: Scraping 3 failed
[2022-05-27 16:20:20,417] INFO: Processing #54/62
[2022-05-27 16:20:20,417] ERROR: No source is configured for 1... skipping
[2022-05-27 16:20:20,417] INFO: Scraping 1 failed
[2022-05-27 16:20:20,417] ERROR: No source is configured for n... skipping
[2022-05-27 16:20:20,418] INFO: Scraping n failed
[2022-05-27 16:20:20,418] INFO: Processing #56/62
[2022-05-27 16:20:20,418] ERROR: No source is configured for 1... skipping
[2022-05-27 16:20:20,418] INFO: Scraping 1 failed
[2022-05-27 16:20:20,418] ERROR: No source is configured for a... skipping
[2022-05-27 16:20:20,418] INFO: Scraping a failed
[2022-05-27 16:20:20,418] INFO: Processing #58/62
[2022-05-27 16:20:20,419] ERROR: No source is configured for r... skipping
[2022-05-27 16:20:20,419] INFO: Scraping r failed
[2022-05-27 16:20:20,419] ERROR: No source is configured for t... skipping
[2022-05-27 16:20:20,419] INFO: Scraping t failed
[2022-05-27 16:20:20,419] INFO: Processing #60/62
[2022-05-27 16:20:20,419] ERROR: No source is configured for 0... skipping
[2022-05-27 16:20:20,420] INFO: Scraping 0 failed
[2022-05-27 16:20:20,420] ERROR: No source is configured for 8... skipping
[2022-05-27 16:20:20,420] INFO: Scraping 8 failed
[2022-05-27 16:20:20,420] INFO: Processing #62/62
[2022-05-27 16:20:39,652] ERROR: No source is configured for http://api.crossref.org/works/10.1590/1982-3533.2022v31n1art08... skipping
[2022-05-27 16:20:39,652] INFO: Scraping http://api.crossref.org/works/10.1590/1982-3533.2022v31n1art08 failed
[2022-05-27 16:27:11,646] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 111, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 77, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 104, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 104, in get
    resp = self.sess.get(url, **kwargs)
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-27 16:45:02,208] INFO: Processing #2/3
[2022-05-27 16:49:40,273] INFO: Processing #2/3
[2022-05-27 16:54:01,138] INFO: Processing #2/3
[2022-05-30 09:33:42,527] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 111, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 77, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 104, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
TypeError: request() got an unexpected keyword argument 'doi'
[2022-05-30 09:38:32,239] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 111, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 77, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 104, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 515, in request
    prep = self.prepare_request(req)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 443, in prepare_request
    p.prepare(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 318, in prepare
    self.prepare_url(url, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/models.py", line 392, in prepare_url
    raise MissingSchema(error)
requests.exceptions.MissingSchema: Invalid URL 'api.crossref.org/works/10.1590/1982-3533.2022v31n1art08': No scheme supplied. Perhaps you meant http://api.crossref.org/works/10.1590/1982-3533.2022v31n1art08?
[2022-05-30 09:45:08,858] INFO: Processing #2/3
[2022-05-30 09:45:08,859] ERROR: No source is configured for http://api.crossref.org/works/10.1590/1982-3533.2022v31n1art08... skipping
[2022-05-30 09:45:08,859] INFO: Scraping http://api.crossref.org/works/10.1590/1982-3533.2022v31n1art08 failed
[2022-05-30 09:46:37,266] ERROR: No source is configured for https://api.crossref.org/works/10.1590/1982-3533.2022v31n1art08... skipping
[2022-05-30 09:46:37,267] INFO: Scraping https://api.crossref.org/works/10.1590/1982-3533.2022v31n1art08 failed
[2022-05-30 09:49:00,523] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 111, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 63, in scrape_url
    source = self._identify_request_source(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 73, in _identify_request_source
    if not source.match_url(url):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 50, in match_url
    if re.findall(prefix + patt, url, re.I):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 50, in match_url
    if re.findall(prefix + patt, url, re.I):
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-30 10:19:30,990] ERROR: No source is configured for external_url... skipping
[2022-05-30 10:19:30,990] INFO: Scraping external_url failed
[2022-05-30 10:19:33,388] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/thirdparty/mitmproxy/addons/core.py", line 60, in configure
    server_spec.parse_with_mode(mode)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/thirdparty/mitmproxy/net/server_spec.py", line 80, in parse_with_mode
    return mode, parse(server_spec)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/thirdparty/mitmproxy/net/server_spec.py", line 47, in parse
    raise ValueError("Invalid server scheme: {}".format(scheme))
ValueError: Invalid server scheme: None

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 111, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 66, in scrape_url
    return source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 62, in scrape_url
    return self._extract_data(self.scraper.get(url, **kwargs), ad_fields)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 77, in scraper
    self._scraper = self._scraper_cls.get_or_create(
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 76, in get_or_create
    _instances.append(cls(**settings))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 64, in __init__
    self._chrome = Chrome.load(**self._settings, host=next(self._hosts))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 42, in load
    return WiredChrome(**settings)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 140, in __init__
    self._configure_host(self._settings["host"])
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 163, in _configure_host
    self.proxy = host.proxy_dict
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/webdriver.py", line 116, in proxy
    options.update(**utils.build_proxy_args(utils.get_upstream_proxy({'proxy': proxy_conf})))
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/thirdparty/mitmproxy/optmanager.py", line 223, in update
    u = self.update_known(**kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/thirdparty/mitmproxy/optmanager.py", line 215, in update_known
    self.changed.send(self, updated=updated)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/blinker/base.py", line 266, in send
    return [(receiver, receiver(sender, **kwargs))
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/blinker/base.py", line 266, in <listcomp>
    return [(receiver, receiver(sender, **kwargs))
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/thirdparty/mitmproxy/addonmanager.py", line 119, in _configure_all
    self.trigger("configure", updated)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/thirdparty/mitmproxy/addonmanager.py", line 256, in trigger
    self.invoke_addon(i, name, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/thirdparty/mitmproxy/addonmanager.py", line 237, in invoke_addon
    func(*args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/thirdparty/mitmproxy/addons/core.py", line 62, in configure
    raise exceptions.OptionsError(str(e)) from e
seleniumwire.thirdparty.mitmproxy.exceptions.OptionsError: Invalid server scheme: None
[2022-05-30 10:19:33,392] INFO: Processing #2/2
[2022-05-30 10:27:16,468] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 111, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 66, in scrape_url
    return source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 62, in scrape_url
    return self._extract_data(self.scraper.get(url, **kwargs), ad_fields)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 77, in scraper
    self._scraper = self._scraper_cls.get_or_create(
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 76, in get_or_create
    _instances.append(cls(**settings))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 64, in __init__
    self._chrome = Chrome.load(**self._settings, host=next(self._hosts))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/hosts.py", line 31, in __next__
    return next(self._cycle)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/hosts.py", line 35, in _compile_hosts
    yield Host._load(proxy, user_agent)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/hosts.py", line 55, in _load
    return Host(proxy, user_agent)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/hosts.py", line 61, in __init__
    self.proxy_dict_prefixed = self._build_proxy_dict(prefixes=True)
TypeError: _build_proxy_dict() got an unexpected keyword argument 'prefixes'
[2022-05-30 10:27:30,305] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711
[2022-05-30 10:27:30,306] INFO: Rotating host
[2022-05-30 10:27:30,306] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise CaptchaHitError(resp.url)
tsutils.scrape.exceptions.CaptchaHitError: https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 111, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 66, in scrape_url
    return source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 62, in scrape_url
    return self._extract_data(self.scraper.get(url, **kwargs), ad_fields)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    self._rotate_host()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 144, in _rotate_host
    self._chrome.configure_host(next(self._hosts))
AttributeError: 'WiredChrome' object has no attribute 'configure_host'
[2022-05-30 10:28:24,063] INFO: Rotating host
[2022-05-30 10:28:33,724] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/10.1111/imig.13019
[2022-05-30 10:28:33,724] INFO: Rotating host
[2022-05-30 10:28:40,392] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/10.1111/imig.13019
[2022-05-30 10:28:40,393] INFO: Rotating host
[2022-05-30 10:28:48,761] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/10.1111/imig.13019
[2022-05-30 10:28:48,762] INFO: Rotating host
[2022-05-30 10:28:51,867] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/10.1111/imig.13019
[2022-05-30 10:28:51,867] INFO: Rotating host
[2022-05-30 10:28:51,872] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise CaptchaHitError(resp.url)
tsutils.scrape.exceptions.CaptchaHitError: https://onlinelibrary.wiley.com/doi/10.1111/imig.13019

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 111, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 66, in scrape_url
    return source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 62, in scrape_url
    return self._extract_data(self.scraper.get(url, **kwargs), ad_fields)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    self._rotate_host()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 144, in _rotate_host
    self._chrome._configure_host(next(self._hosts))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 163, in _configure_host
    self.proxy = host.proxy_dict_prefixed
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/webdriver.py", line 116, in proxy
    options.update(**utils.build_proxy_args(utils.get_upstream_proxy({'proxy': proxy_conf})))
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/thirdparty/mitmproxy/optmanager.py", line 223, in update
    u = self.update_known(**kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/thirdparty/mitmproxy/optmanager.py", line 215, in update_known
    self.changed.send(self, updated=updated)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/blinker/base.py", line 266, in send
    return [(receiver, receiver(sender, **kwargs))
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/blinker/base.py", line 266, in <listcomp>
    return [(receiver, receiver(sender, **kwargs))
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/thirdparty/mitmproxy/server/config.py", line 90, in configure
    _, spec = server_spec.parse_with_mode(options.mode)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/thirdparty/mitmproxy/net/server_spec.py", line 80, in parse_with_mode
    return mode, parse(server_spec)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/thirdparty/mitmproxy/net/server_spec.py", line 42, in parse
    raise ValueError("Invalid server specification: {}".format(server_spec))
ValueError: Invalid server specification: https://
[2022-05-30 10:28:51,874] INFO: Processing #2/2
[2022-05-30 10:33:10,066] INFO: Rotating host
[2022-05-30 10:33:42,002] INFO: Rotating host
[2022-05-30 10:33:48,180] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/10.1111/imig.13019
[2022-05-30 10:33:48,180] INFO: Rotating host
[2022-05-30 10:34:54,839] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/10.1111/imig.13019
[2022-05-30 10:34:54,841] INFO: Rotating host
[2022-05-30 10:35:04,231] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/10.1111/imig.13019
[2022-05-30 10:35:04,232] INFO: Rotating host
[2022-05-30 10:37:01,867] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/10.1111/imig.13019
[2022-05-30 10:37:01,868] INFO: Rotating host
[2022-05-30 10:37:21,643] INFO: Processing #2/2
[2022-05-30 10:39:23,605] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 111, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 66, in scrape_url
    return source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 62, in scrape_url
    return self._extract_data(self.scraper.get(url, **kwargs), ad_fields)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 77, in scraper
    self._scraper = self._scraper_cls.get_or_create(
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 76, in get_or_create
    _instances.append(cls(**settings))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 63, in __init__
    super().__init__(**settings)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 51, in __init__
    self._hosts = Hosts(self._settings["proxy_file"])
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/hosts.py", line 27, in __init__
    self._load_proxies(proxy_file),
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/hosts.py", line 40, in _load_proxies
    return load_csv(proxy_file, flat=True)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/hosts.py", line 40, in _load_proxies
    return load_csv(proxy_file, flat=True)
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-30 10:42:09,685] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 53, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 89, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 442, in get
    self.execute(Command.GET, {'url': url})
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 430, in execute
    self.error_handler.check_response(response)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py", line 247, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message: timeout: Timed out receiving message from renderer: 10.836
  (Session info: headless chrome=101.0.4951.64)
Stacktrace:
#0 0x561b636b60c3 <unknown>
#1 0x561b63418d68 <unknown>
#2 0x561b63404058 <unknown>
#3 0x561b63402d82 <unknown>
#4 0x561b634032dc <unknown>
#5 0x561b634112bf <unknown>
#6 0x561b63411e22 <unknown>
#7 0x561b6341fe43 <unknown>
#8 0x561b6342316a <unknown>
#9 0x561b63403614 <unknown>
#10 0x561b6341fb84 <unknown>
#11 0x561b6347ec2d <unknown>
#12 0x561b6346b693 <unknown>
#13 0x561b6344175c <unknown>
#14 0x561b63442895 <unknown>
#15 0x561b636f6cf6 <unknown>
#16 0x561b636fa22c <unknown>
#17 0x561b636e294e <unknown>
#18 0x561b636faca4 <unknown>
#19 0x561b636d7802 <unknown>
#20 0x561b637144c8 <unknown>
#21 0x561b63714623 <unknown>
#22 0x561b6372ddd3 <unknown>
#23 0x7f1ed850d609 <unknown>


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 111, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 66, in scrape_url
    return source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 62, in scrape_url
    return self._extract_data(self.scraper.get(url, **kwargs), ad_fields)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 71, in _handle_error
    if 'tsutils' not in exc.__module__:
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 71, in _handle_error
    if 'tsutils' not in exc.__module__:
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-30 10:43:08,521] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 111, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 66, in scrape_url
    return source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 62, in scrape_url
    return self._extract_data(self.scraper.get(url, **kwargs), ad_fields)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 77, in scraper
    self._scraper = self._scraper_cls.get_or_create(
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 76, in get_or_create
    _instances.append(cls(**settings))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 64, in __init__
    self._chrome = Chrome.load(**self._settings, host=next(self._hosts))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 41, in load
    return StealthChrome(**settings)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 71, in __init__
    self._init_driver()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 111, in _init_driver
    chrome_cls.__init__(self, **self._configure_init_kwargs())
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 401, in __init__
    super(Chrome, self).__init__(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/chrome/webdriver.py", line 70, in __init__
    super(WebDriver, self).__init__(DesiredCapabilities.CHROME['browserName'], "goog",
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/chromium/webdriver.py", line 92, in __init__
    RemoteWebDriver.__init__(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 275, in __init__
    self.start_session(capabilities, browser_profile)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 589, in start_session
    super(selenium.webdriver.chrome.webdriver.WebDriver, self).start_session(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 365, in start_session
    response = self.execute(Command.NEW_SESSION, parameters)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 430, in execute
    self.error_handler.check_response(response)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py", line 247, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.WebDriverException: Message: unknown error: cannot connect to chrome at 127.0.0.1:34643
from session not created: This version of ChromeDriver only supports Chrome version 102
Current browser version is 101.0.4951.64
Stacktrace:
#0 0x56110fc05f33 <unknown>
#1 0x56110f950118 <unknown>
#2 0x56110f9771c5 <unknown>
#3 0x56110f96ea06 <unknown>
#4 0x56110f9a9d3a <unknown>
#5 0x56110f9a3e63 <unknown>
#6 0x56110f97982a <unknown>
#7 0x56110f97a985 <unknown>
#8 0x56110fc4a4cd <unknown>
#9 0x56110fc4e5ec <unknown>
#10 0x56110fc3471e <unknown>
#11 0x56110fc4f238 <unknown>
#12 0x56110fc29870 <unknown>
#13 0x56110fc6b608 <unknown>
#14 0x56110fc6b788 <unknown>
#15 0x56110fc85f1d <unknown>
#16 0x7fb9f9537947 <unknown>

[2022-05-30 10:46:31,258] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/full/10.1111/dech.12711
[2022-05-30 10:46:31,258] INFO: Rotating host
[2022-05-30 10:46:31,259] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 65, in _parse_response
    raise CaptchaHitError(resp.url)
tsutils.scrape.exceptions.CaptchaHitError: https://onlinelibrary.wiley.com/doi/full/10.1111/dech.12711

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 111, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 66, in scrape_url
    return source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 62, in scrape_url
    return self._extract_data(self.scraper.get(url, **kwargs), ad_fields)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 77, in _handle_error
    self._rotate_host()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 144, in _rotate_host
    self._chrome._configure_host(next(self._hosts))
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 433, in __getattribute__
    return super().__getattribute__(item)
AttributeError: 'StealthChrome' object has no attribute '_configure_host'
[2022-05-30 10:48:07,731] INFO: timeout: Timed out receiving message from renderer: 12.202
  (Session info: headless chrome=102.0.5005.49)
[2022-05-30 10:48:07,732] INFO: Rotating host
[2022-05-30 10:48:23,025] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/full/10.1111/dech.12711
[2022-05-30 10:48:23,026] INFO: Rotating host
[2022-05-30 10:48:28,979] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/10.1111/imig.13019
[2022-05-30 10:48:28,980] INFO: Rotating host
[2022-05-30 10:48:35,980] INFO: Processing #2/2
[2022-05-30 10:49:11,093] ERROR: timeout: Timed out receiving message from renderer: -0.002
  (Session info: chrome=102.0.5005.49)
[2022-05-30 10:49:11,094] INFO: Rotating host
[2022-05-30 10:50:27,183] ERROR: timeout: Timed out receiving message from renderer: 6.593
  (Session info: chrome=102.0.5005.49)
[2022-05-30 10:50:27,183] INFO: Rotating host
[2022-05-30 10:56:04,545] ERROR: timeout: Timed out receiving message from renderer: 9.712
  (Session info: chrome=102.0.5005.49)
[2022-05-30 10:56:04,557] INFO: Rotating host
[2022-05-30 10:56:11,373] INFO: CAPTCHA HIT - please solve. Hit any key when done
[2022-05-30 10:56:22,183] INFO: Processing #2/2
[2022-05-30 10:57:15,826] INFO: CAPTCHA HIT - please solve. Hit any key when done
[2022-05-30 10:58:08,085] INFO: Loading....
[2022-05-30 10:58:09,187] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711
[2022-05-30 10:58:09,188] INFO: Rotating host
[2022-05-30 10:58:17,282] INFO: CAPTCHA HIT - please solve. Hit any key when done
[2022-05-30 10:58:19,110] INFO: Loading....
[2022-05-30 10:58:20,441] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/full/10.1111/dech.12711
[2022-05-30 10:58:20,442] INFO: Rotating host
[2022-05-30 11:04:21,773] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/10.1111/petr.14281
[2022-05-30 11:04:21,774] INFO: Rotating host
[2022-05-30 11:04:25,576] ERROR: Captcha hit on https://onlinelibrary.wiley.com/doi/10.1111/petr.14281
[2022-05-30 11:04:25,577] INFO: Rotating host
[2022-05-30 11:06:50,657] ERROR: timeout: Timed out receiving message from renderer: 12.166
  (Session info: headless chrome=102.0.5005.49)
[2022-05-30 11:06:50,658] INFO: Rotating host
[2022-05-30 11:28:54,522] DEBUG: Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/10.1111/petr.14281
[2022-05-30 11:28:54,523] INFO: Rotating host
[2022-05-30 11:29:12,053] ERROR: timeout: Timed out receiving message from renderer: 13.504
  (Session info: headless chrome=102.0.5005.49)
[2022-05-30 11:29:12,054] INFO: Rotating host
[2022-05-30 11:29:17,687] DEBUG: Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/10.1111/petr.14281
[2022-05-30 11:29:17,687] INFO: Rotating host
[2022-05-30 11:29:25,693] DEBUG: Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/10.1111/petr.14281
[2022-05-30 11:29:25,694] INFO: Rotating host
[2022-05-30 11:31:17,368] DEBUG: Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/10.1111/petr.14281
[2022-05-30 11:31:17,368] INFO: Rotating host
[2022-05-30 11:31:26,443] DEBUG: Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/10.1111/petr.14281
[2022-05-30 11:31:26,443] INFO: Rotating host
[2022-05-30 11:31:31,799] DEBUG: Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/10.1111/petr.14281
[2022-05-30 11:31:31,799] INFO: Rotating host
[2022-05-30 11:31:48,253] ERROR: unknown error: net::ERR_TUNNEL_CONNECTION_FAILED
  (Session info: headless chrome=102.0.5005.49)
[2022-05-30 11:31:48,253] INFO: Rotating host
[2022-05-30 11:48:54,987] ERROR: Driver instances cannot be run in parallel... CRITICAL - QUITTING
[2022-05-30 11:49:23,293] INFO: Processing #2/2
[2022-05-30 11:50:41,017] INFO: Processing #2/2
[2022-05-30 14:03:11,062] ERROR: unknown error: net::ERR_TUNNEL_CONNECTION_FAILED
  (Session info: headless chrome=102.0.5005.49)
[2022-05-30 14:03:11,063] INFO: Rotating host
[2022-05-30 14:32:31,604] ERROR: unknown error: net::ERR_TUNNEL_CONNECTION_FAILED
  (Session info: headless chrome=102.0.5005.49)
[2022-05-30 14:32:31,605] INFO: Rotating host
[2022-05-30 14:32:32,687] ERROR: unknown error: net::ERR_TUNNEL_CONNECTION_FAILED
  (Session info: headless chrome=102.0.5005.49)
[2022-05-30 14:32:32,687] INFO: Rotating host
[2022-05-30 14:32:33,767] ERROR: unknown error: net::ERR_TUNNEL_CONNECTION_FAILED
  (Session info: headless chrome=102.0.5005.49)
[2022-05-30 14:32:33,767] INFO: Rotating host
[2022-05-30 14:51:02,853] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 112, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 66, in scrape_url
    return source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 62, in scrape_url
    return self._extract_data(self.scraper.get(url, **kwargs), ad_fields)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 77, in scraper
    self._scraper = self._scraper_cls.get_or_create(
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 76, in get_or_create
    if len(_instances) == 0:
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 64, in __init__
    super().__init__(**settings)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 54, in __init__
    super().__init__(self, **self._configure_init_kwargs())
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 54, in __init__
    super().__init__(self, **self._configure_init_kwargs())
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-30 15:09:01,523] DEBUG: Error raised while processing item
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 111, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 66, in scrape_url
    return source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 62, in scrape_url
    return self._extract_data(self.scraper.get(url, **kwargs), ad_fields)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 71, in _extract_data
    out[field.name] = field.extract(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/field.py", line 27, in extract
    results = self._process_sub_conf(sub_conf, data)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/field.py", line 74, in _process_sub_conf
    for val in vals:
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/field.py", line 74, in _process_sub_conf
    for val in vals:
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-30 15:35:57,706] DEBUG: hello
[2022-05-30 15:36:36,637] DEBUG: hello
[2022-05-30 15:38:53,136] DEBUG: hello
[2022-05-30 17:22:25,378] ERROR: No source is configured for https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b... skipping
[2022-05-30 17:22:25,379] INFO: Scraping https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b failed
[2022-05-30 17:22:25,379] ERROR: No source is configured for https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books[]d-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b... skipping
[2022-05-30 17:22:25,379] INFO: Scraping https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books[]d-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b failed
[2022-05-30 17:22:25,380] ERROR: No source is configured for https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b... skipping
[2022-05-30 17:22:25,380] INFO: Scraping https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b failed
[2022-05-30 17:22:25,380] ERROR: No source is configured for https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b... skipping
[2022-05-30 17:22:25,380] INFO: Scraping https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b failed
[2022-05-30 17:22:25,381] ERROR: No source is configured for https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b... skipping
[2022-05-30 17:22:25,381] INFO: Scraping https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b failed
[2022-05-30 17:22:25,381] ERROR: No source is configured for https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b... skipping
[2022-05-30 17:22:25,381] INFO: Scraping https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b failed
[2022-05-30 17:22:25,382] ERROR: No source is configured for https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b... skipping
[2022-05-30 17:22:25,382] INFO: Scraping https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b failed
[2022-05-30 17:22:25,382] ERROR: No source is configured for https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b... skipping
[2022-05-30 17:22:25,382] INFO: Scraping https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b failed
[2022-05-30 17:22:25,383] ERROR: No source is configured for https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b... skipping
[2022-05-30 17:22:25,383] INFO: Scraping https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b failed
[2022-05-30 17:33:46,205] DEBUG: hello
[2022-05-31 09:34:13,662] INFO: Processing #2/2
[2022-05-31 10:19:14,430] INFO: Processing #2/2
[2022-05-31 10:45:46,620] ERROR: No further items available - stopping execution
[2022-05-31 10:47:04,302] DEBUG: hello
[2022-05-31 10:47:05,260] ERROR: No further items available - stopping execution
[2022-05-31 10:48:05,075] ERROR: No further items available - stopping execution
[2022-05-31 10:48:16,378] INFO: Processing #2/2
[2022-05-31 10:50:13,756] ERROR: No further items available - stopping execution
[2022-05-31 10:50:14,615] INFO: Processing #2/2
[2022-05-31 10:52:33,590] ERROR: No further items available - stopping execution
[2022-05-31 10:53:26,399] DEBUG: hello
[2022-05-31 10:54:54,122] ERROR: No further items available - stopping execution
[2022-05-31 10:56:00,927] ERROR: No further items available - stopping execution
[2022-05-31 10:57:25,604] INFO:  raised while processing item
[2022-05-31 10:57:25,605] DEBUG: See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 119, in _handle_task
    out = func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 69, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 49, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 90, in execute
    return self._do_sequential_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _do_sequential_execution
    res, exc = self._handle_task(func, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 129, in _handle_task
    return out, exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 129, in _handle_task
    return out, exc
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-31 10:57:26,405] INFO: Processing #2/2
[2022-05-31 10:57:55,995] INFO:  raised while processing item
[2022-05-31 10:57:55,995] DEBUG: See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 119, in _handle_task
    out = func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 69, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 49, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 90, in execute
    return self._do_sequential_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _do_sequential_execution
    res, exc = self._handle_task(func, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 129, in _handle_task
    return out, exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 129, in _handle_task
    return out, exc
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-31 10:57:56,954] INFO: Processing #2/2
[2022-05-31 10:58:21,779] INFO:  raised while processing item
[2022-05-31 10:58:21,780] DEBUG: See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 119, in _handle_task
    out = func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    return self._execute_callback(self.Result(values, resp))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    return self._execute_callback(self.Result(values, resp))
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-31 10:58:22,756] INFO: Processing #2/2
[2022-05-31 10:59:07,230] ERROR: No further items available - stopping execution
[2022-05-31 11:00:25,260] ERROR: No further items available - stopping execution
[2022-05-31 11:14:22,248] ERROR: No further items available - stopping execution
[2022-05-31 11:14:22,249] INFO: 'tuple' object has no attribute 'values' raised while processing item
[2022-05-31 11:14:22,249] DEBUG: See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return self._parse_completed_task(func(*args, **kwargs))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 70, in scrape_url
    res = res.values
AttributeError: 'tuple' object has no attribute 'values'
[2022-05-31 12:21:48,206] ERROR: No further items available - stopping execution
[2022-05-31 12:21:51,039] INFO: Processing #2/2
[2022-05-31 12:22:31,193] ERROR: No further items available - stopping execution
[2022-05-31 12:23:17,810] INFO:  raised while processing item
[2022-05-31 12:23:17,810] DEBUG: See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 69, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 49, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 83, in execute
    if self._stop_execution(out):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 83, in execute
    if self._stop_execution(out):
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-31 12:23:17,811] INFO: Processing #2/2
[2022-05-31 12:24:13,834] ERROR: No further items available - stopping execution
[2022-05-31 12:25:55,266] INFO:  raised while processing item
[2022-05-31 12:25:55,266] DEBUG: See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 69, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 49, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    out, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 117, in _parse_completing_threads
    if self.stop_early:
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 117, in _parse_completing_threads
    if self.stop_early:
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-31 12:25:55,267] INFO: Processing #2/2
[2022-05-31 12:26:04,703] ERROR: No further items available - stopping execution
[2022-05-31 12:26:07,166] INFO: Processing #2/2
[2022-05-31 12:26:59,192] ERROR: No further items available - stopping execution
[2022-05-31 12:27:11,781] INFO:  raised while processing item
[2022-05-31 12:27:11,781] DEBUG: See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 71, in scrape_url
    return res
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 71, in scrape_url
    return res
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-31 12:27:13,790] INFO: Processing #2/2
[2022-05-31 12:27:45,345] ERROR: No further items available - stopping execution
[2022-05-31 12:27:47,920] INFO: Processing #2/2
[2022-05-31 12:28:15,637] ERROR: No further items available - stopping execution
[2022-05-31 12:28:24,891] INFO: Processing #2/2
[2022-05-31 12:31:54,847] INFO:  raised while processing item
[2022-05-31 12:31:54,847] DEBUG: See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 103, in _handle_task
    print('called')
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 69, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 49, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    out, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _parse_completing_threads
    done, futures = wait(futures, return_when=FIRST_COMPLETED)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _parse_completing_threads
    done, futures = wait(futures, return_when=FIRST_COMPLETED)
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-31 12:31:56,708] INFO: Processing #2/2
[2022-05-31 12:33:03,337] INFO:  raised while processing item
[2022-05-31 12:33:03,337] DEBUG: See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 69, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 49, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    out, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 117, in _parse_completing_threads
    if self.stop_early:
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 117, in _parse_completing_threads
    if self.stop_early:
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-31 12:33:05,152] INFO: Processing #2/2
[2022-05-31 12:34:20,078] INFO:  raised while processing item
[2022-05-31 12:34:20,078] DEBUG: See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 104, in _handle_task
    return func(*args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 69, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 49, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    out, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 117, in _parse_completing_threads
    input(len(done))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 117, in _parse_completing_threads
    input(len(done))
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-31 12:34:24,222] INFO: Processing #2/2
[2022-05-31 12:34:55,315] INFO: Processing #2/2
[2022-05-31 12:37:15,359] INFO: Processing #2/2
[2022-05-31 12:37:30,960] INFO: Processing #2/2
[2022-05-31 12:38:18,449] INFO: Processing #2/2
[2022-05-31 12:39:02,578] INFO: Processing #2/2
[2022-05-31 12:39:15,059] INFO: Processing #2/2
[2022-05-31 12:53:31,704] ERROR: No further items available - stopping execution
[2022-05-31 12:53:33,330] INFO: Processing #2/2
[2022-05-31 12:53:54,001] ERROR: No further items available - stopping execution
[2022-05-31 12:56:49,058] ERROR: No further items available - stopping execution
[2022-05-31 12:56:50,783] INFO: Processing #2/2
[2022-05-31 12:57:55,212] INFO:  raised while processing item
[2022-05-31 12:57:55,213] DEBUG: See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-31 12:57:56,029] INFO: Processing #2/2
[2022-05-31 12:58:34,798] INFO:  raised while processing item
[2022-05-31 12:58:34,798] DEBUG: See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-05-31 12:58:35,717] INFO: Processing #2/2
[2022-05-31 13:02:45,539] ERROR: No further items available - stopping execution
[2022-05-31 13:02:47,230] INFO: Processing #2/2
[2022-05-31 13:03:11,396] ERROR: No further items available - stopping execution
[2022-05-31 14:35:01,689] INFO: Processing #2/2
[2022-05-31 14:38:46,417] INFO: Processing #2/2
[2022-05-31 14:38:53,287] INFO: Processing #2/2
[2022-05-31 14:40:19,719] INFO: Processing #2/2
[2022-05-31 14:46:32,416] INFO: Processing #2/2
[2022-05-31 14:48:57,781] INFO: Processing #2/2
[2022-05-31 14:50:10,353] INFO: Processing #2/2
[2022-05-31 14:50:42,798] INFO: Processing #2/2
[2022-05-31 14:51:02,256] ERROR: No further items available - stopping execution
[2022-05-31 14:51:17,646] ERROR: No further items available - stopping execution
[2022-05-31 16:14:34,310] ERROR: No source is configured for https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books[]d-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b... skipping
[2022-05-31 16:14:34,310] INFO: Scraping https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books[]d-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b failed
[2022-05-31 16:20:21,672] ERROR: No further results available - stopping execution
[2022-05-31 16:20:23,783] ERROR: No further results available - stopping execution
[2022-05-31 16:20:25,836] INFO: 'BdbQuit' object has no attribute 'msg' raised while processing item
[2022-05-31 16:20:25,837] DEBUG: See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 107, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 555, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/urllib3/connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
  File "/usr/local/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/usr/local/lib/python3.8/http/client.py", line 277, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/local/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
  File "/usr/local/lib/python3.8/pdb.py", line 194, in sigint_handler
    self.set_trace(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 321, in set_trace
    def set_trace(self, frame=None):
  File "/usr/local/lib/python3.8/bdb.py", line 90, in trace_dispatch
    return self.dispatch_call(frame, arg)
  File "/usr/local/lib/python3.8/bdb.py", line 135, in dispatch_call
    if self.quitting: raise BdbQuit
bdb.BdbQuit

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    logger.error(exc.msg)
AttributeError: 'BdbQuit' object has no attribute 'msg'
[2022-05-31 16:20:25,841] INFO: 'BdbQuit' object has no attribute 'msg' raised while processing item
[2022-05-31 16:20:25,841] DEBUG: See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 107, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 555, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 542, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/sessions.py", line 655, in send
    r = adapter.send(request, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/adapters.py", line 439, in send
    resp = conn.urlopen(
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/urllib3/connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
  File "/usr/local/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/usr/local/lib/python3.8/http/client.py", line 277, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/local/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
  File "/usr/local/lib/python3.8/pdb.py", line 194, in sigint_handler
    self.set_trace(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 321, in set_trace
    def set_trace(self, frame=None):
  File "/usr/local/lib/python3.8/bdb.py", line 90, in trace_dispatch
    return self.dispatch_call(frame, arg)
  File "/usr/local/lib/python3.8/bdb.py", line 135, in dispatch_call
    if self.quitting: raise BdbQuit
bdb.BdbQuit

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 80, in execute
    return self._do_sequential_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 93, in _do_sequential_execution
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    logger.error(exc.msg)
AttributeError: 'BdbQuit' object has no attribute 'msg'
[2022-05-31 16:21:11,447] ERROR: No further results available - stopping execution
[2022-05-31 16:21:13,549] ERROR: No further results available - stopping execution
[2022-05-31 16:21:14,992] INFO: Processing #4/19
[2022-05-31 16:21:15,785] INFO: Processing #8/19
[2022-05-31 16:21:16,561] INFO: Processing #12/19
[2022-05-31 16:21:17,939] INFO: Processing #16/19
[2022-05-31 16:21:22,298] INFO: Processing #4/74
[2022-05-31 16:21:23,507] INFO: Processing #8/74
[2022-05-31 16:21:24,850] INFO: Processing #12/74
[2022-05-31 16:21:27,178] INFO: Processing #16/74
[2022-05-31 16:21:28,443] INFO: Processing #20/74
[2022-05-31 16:21:30,138] INFO: Processing #24/74
[2022-05-31 16:21:32,191] INFO: Processing #28/74
[2022-05-31 16:21:33,520] INFO: Processing #32/74
[2022-05-31 16:21:35,639] INFO: Processing #36/74
[2022-05-31 16:21:37,146] INFO: Processing #40/74
[2022-05-31 16:21:38,856] INFO: Processing #44/74
[2022-05-31 16:21:40,843] INFO: Processing #48/74
[2022-05-31 16:21:42,298] INFO: Processing #52/74
[2022-05-31 16:21:43,908] INFO: Processing #56/74
[2022-05-31 16:21:45,996] INFO: Processing #60/74
[2022-05-31 16:21:47,380] INFO: Processing #64/74
[2022-05-31 16:21:49,466] INFO: Processing #68/74
[2022-05-31 16:21:51,070] INFO: Processing #72/74
[2022-05-31 16:21:55,796] INFO: Processing #4/74
[2022-05-31 16:21:57,423] INFO: Processing #8/74
[2022-05-31 16:21:58,911] INFO: Processing #12/74
[2022-05-31 16:22:00,973] INFO: Processing #16/74
[2022-05-31 16:22:02,908] INFO: Processing #20/74
[2022-05-31 16:22:04,319] INFO: Processing #24/74
[2022-05-31 16:22:06,743] INFO: Processing #28/74
[2022-05-31 16:22:08,426] INFO: Processing #32/74
[2022-05-31 16:22:10,182] INFO: Processing #36/74
[2022-05-31 16:22:12,070] INFO: Processing #40/74
[2022-05-31 16:22:13,948] INFO: Processing #44/74
[2022-05-31 16:22:15,698] INFO: Processing #48/74
[2022-05-31 16:22:18,332] INFO: Processing #52/74
[2022-05-31 16:22:20,435] INFO: Processing #56/74
[2022-05-31 16:22:22,129] INFO: Processing #60/74
[2022-05-31 16:22:23,970] INFO: Processing #64/74
[2022-05-31 16:22:26,131] INFO: Processing #68/74
[2022-05-31 16:22:27,750] INFO: Processing #72/74
[2022-05-31 16:22:34,259] INFO: Processing #4/74
[2022-05-31 16:22:36,109] INFO: Processing #8/74
[2022-05-31 16:22:38,374] INFO: Processing #12/74
[2022-05-31 16:22:38,420] INFO: Rotating host
[2022-05-31 16:22:38,420] INFO: 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised while processing item
[2022-05-31 16:22:38,421] INFO: 'NoneType' object is not iterable raised while processing item
[2022-05-31 16:22:40,435] INFO: Processing #16/74
[2022-05-31 16:22:42,698] INFO: Processing #20/74
[2022-05-31 16:22:45,665] INFO: Processing #24/74
[2022-05-31 16:22:47,638] INFO: Processing #28/74
[2022-05-31 16:22:49,567] INFO: Processing #32/74
[2022-05-31 16:22:52,491] INFO: Processing #36/74
[2022-05-31 16:22:54,903] INFO: Processing #40/74
[2022-05-31 16:22:57,145] INFO: Processing #44/74
[2022-05-31 16:22:59,931] INFO: Processing #48/74
[2022-05-31 16:23:01,783] INFO: Processing #52/74
[2022-05-31 16:23:03,708] INFO: Processing #56/74
[2022-05-31 16:23:07,073] INFO: Processing #60/74
[2022-05-31 16:23:08,989] INFO: Processing #64/74
[2022-05-31 16:23:12,052] INFO: Processing #68/74
[2022-05-31 16:23:14,881] INFO: Processing #72/74
[2022-05-31 16:23:19,227] INFO: Processing #4/74
[2022-05-31 16:23:20,584] INFO: Processing #8/74
[2022-05-31 16:23:22,250] INFO: Processing #12/74
[2022-05-31 16:23:24,181] INFO: Processing #16/74
[2022-05-31 16:23:25,641] INFO: Processing #20/74
[2022-05-31 16:23:26,794] INFO: Processing #24/74
[2022-05-31 16:23:29,104] INFO: Processing #28/74
[2022-05-31 16:23:30,993] INFO: Processing #32/74
[2022-05-31 16:23:33,209] INFO: Processing #36/74
[2022-05-31 16:23:34,633] INFO: Processing #40/74
[2022-05-31 16:23:36,665] INFO: Processing #44/74
[2022-05-31 16:23:38,151] INFO: Processing #48/74
[2022-05-31 16:23:39,767] INFO: Processing #52/74
[2022-05-31 16:23:41,778] INFO: Processing #56/74
[2022-05-31 16:23:43,974] INFO: Processing #60/74
[2022-05-31 16:23:46,211] INFO: Processing #64/74
[2022-05-31 16:23:47,714] INFO: Processing #68/74
[2022-05-31 16:23:49,681] INFO: Processing #72/74
[2022-05-31 16:23:54,044] INFO: Processing #4/74
[2022-05-31 16:23:55,861] INFO: Processing #8/74
[2022-05-31 16:23:57,624] INFO: Processing #12/74
[2022-05-31 16:23:59,507] INFO: Processing #16/74
[2022-05-31 16:24:01,381] INFO: Processing #20/74
[2022-05-31 16:24:03,398] INFO: Processing #24/74
[2022-05-31 16:24:05,206] INFO: Processing #28/74
[2022-05-31 16:24:06,888] INFO: Processing #32/74
[2022-05-31 16:24:09,108] INFO: Processing #36/74
[2022-05-31 16:24:10,726] INFO: Processing #40/74
[2022-05-31 16:24:12,658] INFO: Processing #44/74
[2022-05-31 16:24:14,381] INFO: Processing #48/74
[2022-05-31 16:24:15,688] INFO: Processing #52/74
[2022-05-31 16:24:17,625] INFO: Processing #56/74
[2022-05-31 16:24:18,992] INFO: Processing #60/74
[2022-05-31 16:24:20,212] INFO: Processing #64/74
[2022-05-31 16:24:22,029] INFO: Processing #68/74
[2022-05-31 16:24:23,508] INFO: Processing #72/74
[2022-05-31 16:24:27,492] INFO: Processing #4/74
[2022-05-31 16:24:28,816] INFO: Processing #8/74
[2022-05-31 16:24:30,222] INFO: Processing #12/74
[2022-05-31 16:24:32,070] INFO: Processing #16/74
[2022-05-31 16:24:33,315] INFO: Processing #20/74
[2022-05-31 16:24:34,907] INFO: Processing #24/74
[2022-05-31 16:24:36,254] INFO: Processing #28/74
[2022-05-31 16:24:38,210] INFO: Processing #32/74
[2022-05-31 16:24:39,566] INFO: Processing #36/74
[2022-05-31 16:24:41,023] INFO: Processing #40/74
[2022-05-31 16:24:42,429] INFO: Processing #44/74
[2022-05-31 16:24:44,336] INFO: Processing #48/74
[2022-05-31 16:24:45,662] INFO: Processing #52/74
[2022-05-31 16:24:45,998] INFO: Rotating host
[2022-05-31 16:24:45,998] INFO: 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=55&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised while processing item
[2022-05-31 16:24:45,999] INFO: 'NoneType' object is not iterable raised while processing item
[2022-05-31 16:24:46,953] INFO: Processing #56/74
[2022-05-31 16:24:48,190] INFO: Processing #60/74
[2022-05-31 16:24:49,796] INFO: Processing #64/74
[2022-05-31 16:24:51,012] INFO: Processing #68/74
[2022-05-31 16:24:52,666] INFO: Processing #72/74
[2022-05-31 16:24:56,854] INFO: Processing #4/74
[2022-05-31 16:24:58,614] INFO: Processing #8/74
[2022-05-31 16:25:00,006] INFO: Processing #12/74
[2022-05-31 16:25:01,828] INFO: Processing #16/74
[2022-05-31 16:25:04,098] INFO: Processing #20/74
[2022-05-31 16:25:05,270] INFO: Processing #24/74
[2022-05-31 16:25:06,821] INFO: Processing #28/74
[2022-05-31 16:25:08,448] INFO: Processing #32/74
[2022-05-31 16:25:09,910] INFO: Processing #36/74
[2022-05-31 16:25:11,205] INFO: Processing #40/74
[2022-05-31 16:25:13,265] INFO: Processing #44/74
[2022-05-31 16:25:14,467] INFO: Processing #48/74
[2022-05-31 16:25:16,549] INFO: Processing #52/74
[2022-05-31 16:25:17,779] INFO: Processing #56/74
[2022-05-31 16:25:18,848] INFO: Processing #60/74
[2022-05-31 16:25:20,879] INFO: Processing #64/74
[2022-05-31 16:25:22,368] INFO: Processing #68/74
[2022-05-31 16:25:24,239] INFO: Processing #72/74
[2022-05-31 16:32:22,634] DEBUG:     Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:32:22,635] INFO:     Rotating host
[2022-05-31 16:32:22,635] INFO:     503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised while processing item
[2022-05-31 16:32:22,636] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 79, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 67, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:32:22,809] DEBUG:     Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:32:22,809] INFO:     Rotating host
[2022-05-31 16:32:22,810] INFO:     503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised while processing item
[2022-05-31 16:32:22,810] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 79, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 67, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:32:23,969] ERROR:     No further results available - stopping execution
[2022-05-31 16:32:27,179] INFO:     Processing #4/19
[2022-05-31 16:32:30,201] INFO:     Processing #8/19
[2022-05-31 16:32:33,770] INFO:     Processing #12/19
[2022-05-31 16:32:36,839] INFO:     Processing #16/19
[2022-05-31 16:34:55,301] DEBUG:     Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:34:55,301] INFO:     Rotating host
[2022-05-31 16:34:55,302] INFO:     503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised while processing item
[2022-05-31 16:34:55,302] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 79, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 67, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:34:55,469] DEBUG:     Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:34:55,469] INFO:     Rotating host
[2022-05-31 16:34:55,470] INFO:     503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised while processing item
[2022-05-31 16:34:55,470] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 79, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 67, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:34:55,857] DEBUG:     Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:34:55,858] INFO:     Rotating host
[2022-05-31 16:34:55,858] INFO:     503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised while processing item
[2022-05-31 16:34:55,858] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 79, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 67, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:34:56,256] DEBUG:     Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:34:56,256] INFO:     Rotating host
[2022-05-31 16:34:56,256] INFO:     503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised while processing item
[2022-05-31 16:34:56,257] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 79, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 67, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:40:29,005] INFO:     'TypeError' object has no attribute '__module__' raised while processing item
[2022-05-31 16:40:29,005] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 36, in _compile_hosts
    random.shuffle(combinations)
  File "/usr/local/lib/python3.8/random.py", line 304, in shuffle
    for i in reversed(range(1, len(x))):
TypeError: object of type 'itertools.product' has no len()

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'TypeError' object has no attribute '__module__'
[2022-05-31 16:40:29,009] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:40:29,009] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:40:29,011] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:40:29,012] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:40:29,013] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:40:29,014] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:40:29,016] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:40:29,016] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:40:29,018] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:40:29,019] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:40:29,020] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:40:29,021] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:40:29,023] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:40:29,023] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:40:29,025] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:40:29,025] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:40:29,027] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:40:29,028] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:41:06,082] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:41:06,083] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:41:06,085] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:41:06,086] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:41:06,088] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:41:06,088] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:41:06,090] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:41:06,090] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:41:06,092] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:41:06,092] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:41:06,094] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:41:06,095] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:41:06,096] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:41:06,097] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:41:06,098] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:41:06,099] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:41:06,101] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:41:06,101] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:41:06,103] INFO:     'StopIteration' object has no attribute '__module__' raised while processing item
[2022-05-31 16:41:06,103] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 105, in get
    kwargs = self._get_kwargs(self.host, kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 93, in host
    self._host = next(self._hosts)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/hosts.py", line 32, in __next__
    return next(self._cycle)
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 72, in _handle_error
    if 'tsutils' not in exc.__module__:
AttributeError: 'StopIteration' object has no attribute '__module__'
[2022-05-31 16:41:24,855] DEBUG:     Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:41:24,856] INFO:     Rotating host
[2022-05-31 16:41:24,857] INFO:     503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised while processing item
[2022-05-31 16:41:24,857] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 80, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 68, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:41:25,034] DEBUG:     Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:41:25,035] INFO:     Rotating host
[2022-05-31 16:41:25,035] INFO:     503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised while processing item
[2022-05-31 16:41:25,036] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 80, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 68, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:41:26,155] ERROR:     No further results available - stopping execution
[2022-05-31 16:41:29,134] INFO:     Processing #4/19
[2022-05-31 16:41:32,560] INFO:     Processing #8/19
[2022-05-31 16:42:31,917] INFO:     'BdbQuit' object has no attribute 'msg' raised while processing item
[2022-05-31 16:42:31,917] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 110, in get
    return Response._from_requester(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/response.py", line 82, in _from_requester
    return cls._configure_from_state(response.__getstate__())
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/models.py", line 656, in __getstate__
    self.content
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/models.py", line 831, in content
    self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/models.py", line 753, in generate
    for chunk in self.raw.stream(chunk_size, decode_content=True):
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/urllib3/response.py", line 575, in stream
    for line in self.read_chunked(amt, decode_content=decode_content):
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/urllib3/response.py", line 770, in read_chunked
    chunk = self._handle_chunk(amt)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/urllib3/response.py", line 724, in _handle_chunk
    self._fp._safe_read(2)  # Toss the CRLF at the end of the chunk.
  File "/usr/local/lib/python3.8/http/client.py", line 613, in _safe_read
    data = self.fp.read(amt)
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/local/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
  File "/usr/local/lib/python3.8/pdb.py", line 194, in sigint_handler
    self.set_trace(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 321, in set_trace
    def set_trace(self, frame=None):
  File "/usr/local/lib/python3.8/bdb.py", line 90, in trace_dispatch
    return self.dispatch_call(frame, arg)
  File "/usr/local/lib/python3.8/bdb.py", line 135, in dispatch_call
    if self.quitting: raise BdbQuit
bdb.BdbQuit

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 73, in _handle_error
    input(self._settings["request_retries"])
AttributeError: 'BdbQuit' object has no attribute 'msg'
[2022-05-31 16:42:31,920] INFO:     'BdbQuit' object has no attribute 'msg' raised while processing item
[2022-05-31 16:42:31,920] DEBUG:     See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 41, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 110, in get
    return Response._from_requester(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/response.py", line 82, in _from_requester
    return cls._configure_from_state(response.__getstate__())
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/models.py", line 656, in __getstate__
    self.content
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/models.py", line 831, in content
    self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/requests/models.py", line 753, in generate
    for chunk in self.raw.stream(chunk_size, decode_content=True):
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/urllib3/response.py", line 575, in stream
    for line in self.read_chunked(amt, decode_content=decode_content):
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/urllib3/response.py", line 770, in read_chunked
    chunk = self._handle_chunk(amt)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/urllib3/response.py", line 724, in _handle_chunk
    self._fp._safe_read(2)  # Toss the CRLF at the end of the chunk.
  File "/usr/local/lib/python3.8/http/client.py", line 613, in _safe_read
    data = self.fp.read(amt)
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/local/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
  File "/usr/local/lib/python3.8/pdb.py", line 194, in sigint_handler
    self.set_trace(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 321, in set_trace
    def set_trace(self, frame=None):
  File "/usr/local/lib/python3.8/bdb.py", line 90, in trace_dispatch
    return self.dispatch_call(frame, arg)
  File "/usr/local/lib/python3.8/bdb.py", line 135, in dispatch_call
    if self.quitting: raise BdbQuit
bdb.BdbQuit

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 80, in execute
    return self._do_sequential_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 93, in _do_sequential_execution
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 73, in _handle_error
    input(self._settings["request_retries"])
AttributeError: 'BdbQuit' object has no attribute 'msg'
[2022-05-31 16:42:33,462] INFO:     Processing #12/19
[2022-05-31 16:42:41,403]     DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:44:04,077]     INFO: can't re-enter readline raised while processing item
[2022-05-31 16:44:04,077]     DEBUG: See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 68, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 73, in _handle_error
    logger.error(exc.msg)
  File "/usr/local/lib/python3.8/pdb.py", line 194, in sigint_handler
    self.set_trace(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 321, in set_trace
    def set_trace(self, frame=None):
  File "/usr/local/lib/python3.8/bdb.py", line 90, in trace_dispatch
    return self.dispatch_call(frame, arg)
  File "/usr/local/lib/python3.8/bdb.py", line 134, in dispatch_call
    self.user_call(frame, arg)
  File "/usr/local/lib/python3.8/pdb.py", line 252, in user_call
    self.interaction(frame, None)
  File "/usr/local/lib/python3.8/pdb.py", line 357, in interaction
    self._cmdloop()
  File "/usr/local/lib/python3.8/pdb.py", line 322, in _cmdloop
    self.cmdloop()
  File "/usr/local/lib/python3.8/cmd.py", line 126, in cmdloop
    line = input(self.prompt)
RuntimeError: can't re-enter readline
[2022-05-31 16:44:04,267]     DEBUG: Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:44:43,898]     ERROR: No further results available - stopping execution
[2022-05-31 16:44:45,937]     ERROR: No further results available - stopping execution
[2022-05-31 16:44:47,370]     INFO: Processing #4/10
[2022-05-31 16:44:48,212]     INFO: Processing #8/10
[2022-05-31 16:44:52,630]     INFO: Processing #4/10
[2022-05-31 16:44:53,879]     INFO: Processing #8/10
[2022-05-31 16:44:59,156]     INFO: Processing #4/10
[2022-05-31 16:45:00,630]     INFO: Processing #8/10
[2022-05-31 16:45:06,683]     INFO: Processing #4/10
[2022-05-31 16:45:08,409]     INFO: Processing #8/10
[2022-05-31 16:45:13,710]     INFO: Processing #4/10
[2022-05-31 16:45:15,049]     INFO: Processing #8/10
[2022-05-31 16:45:19,605]     INFO: Processing #4/10
[2022-05-31 16:45:21,050]     INFO: Processing #8/10
[2022-05-31 16:45:25,097]     INFO: Processing #4/10
[2022-05-31 16:45:26,347]     INFO: Processing #8/10
[2022-05-31 16:45:30,227]     INFO: Processing #4/10
[2022-05-31 16:45:31,625]     INFO: Processing #8/10
[2022-05-31 16:47:36,230]     ERROR No further results available - stopping execution
[2022-05-31 16:47:38,473]     ERROR No further results available - stopping execution
[2022-05-31 16:47:39,948]     INFO Processing #4/19
[2022-05-31 16:47:41,398]     INFO Processing #8/19
[2022-05-31 16:47:42,386]     INFO Processing #12/19
[2022-05-31 16:47:43,346]     INFO Processing #16/19
[2022-05-31 16:47:47,854]     INFO Processing #4/74
[2022-05-31 16:47:49,271]     INFO Processing #8/74
[2022-05-31 16:47:51,086]     INFO Processing #12/74
[2022-05-31 16:47:53,025]     INFO Processing #16/74
[2022-05-31 16:47:54,772]     INFO Processing #20/74
[2022-05-31 16:47:56,001]     INFO Processing #24/74
[2022-05-31 16:47:58,500]     INFO Processing #28/74
[2022-05-31 16:48:00,033]     INFO Processing #32/74
[2022-05-31 16:48:01,523]     INFO Processing #36/74
[2022-05-31 16:48:03,823]     INFO Processing #40/74
[2022-05-31 16:48:05,358]     INFO Processing #44/74
[2022-05-31 16:48:07,036]     INFO Processing #48/74
[2022-05-31 16:48:08,707]     INFO Processing #52/74
[2022-05-31 16:48:10,552]     INFO Processing #56/74
[2022-05-31 16:48:12,153]     INFO Processing #60/74
[2022-05-31 16:48:13,993]     INFO Processing #64/74
[2022-05-31 16:48:15,686]     INFO Processing #68/74
[2022-05-31 16:48:17,487]     INFO Processing #72/74
[2022-05-31 16:48:22,023]     INFO Processing #4/74
[2022-05-31 16:48:23,525]     INFO Processing #8/74
[2022-05-31 16:48:25,800]     INFO Processing #12/74
[2022-05-31 16:48:27,230]     INFO Processing #16/74
[2022-05-31 16:48:29,090]     INFO Processing #20/74
[2022-05-31 16:48:30,858]     INFO Processing #24/74
[2022-05-31 16:48:32,519]     INFO Processing #28/74
[2022-05-31 16:48:35,507]     INFO Processing #32/74
[2022-05-31 16:48:37,029]     INFO Processing #36/74
[2022-05-31 16:48:38,345]     INFO Processing #40/74
[2022-05-31 16:48:40,741]     INFO Processing #44/74
[2022-05-31 16:48:42,231]     INFO Processing #48/74
[2022-05-31 16:48:43,771]     INFO Processing #52/74
[2022-05-31 16:48:46,243]     INFO Processing #56/74
[2022-05-31 16:48:47,626]     INFO Processing #60/74
[2022-05-31 16:48:49,087]     INFO Processing #64/74
[2022-05-31 16:48:51,269]     INFO Processing #68/74
[2022-05-31 16:48:52,776]     INFO Processing #72/74
[2022-05-31 16:48:59,285]     INFO Processing #4/74
[2022-05-31 16:49:00,948]     INFO Processing #8/74
[2022-05-31 16:49:02,837]     INFO Processing #12/74
[2022-05-31 16:49:05,718]     INFO Processing #16/74
[2022-05-31 16:49:07,528]     INFO Processing #20/74
[2022-05-31 16:49:09,934]     INFO Processing #24/74
[2022-05-31 16:49:12,201]     INFO Processing #28/74
[2022-05-31 16:49:14,510]     INFO Processing #32/74
[2022-05-31 16:49:17,128]     INFO Processing #36/74
[2022-05-31 16:49:19,293]     INFO Processing #40/74
[2022-05-31 16:49:21,708]     INFO Processing #44/74
[2022-05-31 16:49:23,967]     INFO Processing #48/74
[2022-05-31 16:49:25,838]     INFO Processing #52/74
[2022-05-31 16:49:28,404]     INFO Processing #56/74
[2022-05-31 16:49:30,416]     INFO Processing #60/74
[2022-05-31 16:49:31,389]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:49:31,389]     INFO Rotating host
[2022-05-31 16:49:33,056]     INFO Processing #64/74
[2022-05-31 16:49:33,233]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=68&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:49:33,233]     INFO Rotating host
[2022-05-31 16:49:39,136]     INFO Processing #68/74
[2022-05-31 16:49:39,304]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:49:39,304]     INFO Rotating host
[2022-05-31 16:49:50,470]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=68&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:49:50,471]     INFO Rotating host
[2022-05-31 16:49:53,321]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:49:53,322]     INFO Rotating host
[2022-05-31 16:49:54,381]     INFO Processing #72/74
[2022-05-31 16:49:56,248]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:49:56,249]     INFO Rotating host
[2022-05-31 16:49:58,052]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:49:58,052]     INFO Rotating host
[2022-05-31 16:50:01,214]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:01,214]     INFO Rotating host
[2022-05-31 16:50:01,221]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:01,222]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:01,222]     INFO Rotating host
[2022-05-31 16:50:01,222]     INFO Rotating host
[2022-05-31 16:50:08,185]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:08,185]     INFO Rotating host
[2022-05-31 16:50:08,841]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:08,842]     INFO Rotating host
[2022-05-31 16:50:10,021]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:10,022]     INFO Rotating host
[2022-05-31 16:50:10,022]     INFO 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised while processing item
[2022-05-31 16:50:10,022]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 80, in _handle_error
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 68, in _parse_response
    return resp
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:10,023]     INFO 'NoneType' object is not iterable raised while processing item
[2022-05-31 16:50:10,023]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _do_parallel_execution
    if self._stop_execution(out):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 140, in _stop_execution
    for res in out:
TypeError: 'NoneType' object is not iterable
[2022-05-31 16:50:10,198]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:10,198]     INFO Rotating host
[2022-05-31 16:50:10,772]     INFO Processing #4/74
[2022-05-31 16:50:11,364]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:11,364]     INFO Rotating host
[2022-05-31 16:50:11,858]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:11,859]     INFO Rotating host
[2022-05-31 16:50:12,534]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:12,535]     INFO Rotating host
[2022-05-31 16:50:12,535]     INFO 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised while processing item
[2022-05-31 16:50:12,535]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 80, in _handle_error
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 68, in _parse_response
    return resp
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:12,536]     INFO 'NoneType' object is not iterable raised while processing item
[2022-05-31 16:50:12,536]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _do_parallel_execution
    if self._stop_execution(out):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 140, in _stop_execution
    for res in out:
TypeError: 'NoneType' object is not iterable
[2022-05-31 16:50:12,697]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:12,697]     INFO Rotating host
[2022-05-31 16:50:13,030]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:13,031]     INFO Rotating host
[2022-05-31 16:50:13,216]     INFO Processing #8/74
[2022-05-31 16:50:13,858]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:13,858]     INFO Rotating host
[2022-05-31 16:50:14,522]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:14,523]     INFO Rotating host
[2022-05-31 16:50:15,266]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:15,266]     INFO Rotating host
[2022-05-31 16:50:15,266]     INFO 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised while processing item
[2022-05-31 16:50:15,267]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 80, in _handle_error
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 68, in _parse_response
    return resp
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:15,268]     INFO 'NoneType' object is not iterable raised while processing item
[2022-05-31 16:50:15,269]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _do_parallel_execution
    if self._stop_execution(out):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 140, in _stop_execution
    for res in out:
TypeError: 'NoneType' object is not iterable
[2022-05-31 16:50:15,338]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:15,338]     INFO Rotating host
[2022-05-31 16:50:15,434]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:15,434]     INFO Rotating host
[2022-05-31 16:50:15,692]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:50:15,692]     INFO Rotating host
[2022-05-31 16:50:17,454]     INFO Processing #12/74
[2022-05-31 16:50:17,454]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,455]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,455]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,455]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,456]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,456]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,456]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,456]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,457]     INFO Processing #16/74
[2022-05-31 16:50:17,457]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,457]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,457]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,457]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,458]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,458]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,458]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,458]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,459]     INFO Processing #20/74
[2022-05-31 16:50:17,459]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,459]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,459]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,460]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,460]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,460]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,460]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,460]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,461]     INFO Processing #24/74
[2022-05-31 16:50:17,461]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,461]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,461]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,462]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,462]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,462]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,462]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,463]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,463]     INFO Processing #28/74
[2022-05-31 16:50:17,463]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,464]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,464]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,464]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,464]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,464]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,465]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,465]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,465]     INFO Processing #32/74
[2022-05-31 16:50:17,465]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,466]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,466]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,466]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,466]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,466]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,467]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,467]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,467]     INFO Processing #36/74
[2022-05-31 16:50:17,467]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,468]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,468]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,468]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,468]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,468]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,469]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,469]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,469]     INFO Processing #40/74
[2022-05-31 16:50:17,470]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,470]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,470]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,470]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,470]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,471]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,471]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,471]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,472]     INFO Processing #44/74
[2022-05-31 16:50:17,472]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,472]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,472]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,472]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,473]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,473]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,473]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,473]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,474]     INFO Processing #48/74
[2022-05-31 16:50:17,474]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,474]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,474]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,474]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,475]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,475]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,475]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,475]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,476]     INFO Processing #52/74
[2022-05-31 16:50:17,476]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,476]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,476]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,476]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,477]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,477]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,477]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,477]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,478]     INFO Processing #56/74
[2022-05-31 16:50:17,478]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,478]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,478]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,478]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,479]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,479]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,480]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,480]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,480]     INFO Processing #60/74
[2022-05-31 16:50:17,480]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,480]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,481]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,481]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,481]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,481]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,482]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,482]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,482]     INFO Processing #64/74
[2022-05-31 16:50:17,482]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,482]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,483]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,483]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,483]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,483]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,484]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,484]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,484]     INFO Processing #68/74
[2022-05-31 16:50:17,484]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,484]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,485]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,485]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,485]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,485]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,486]     INFO cannot schedule new futures after interpreter shutdown raised while processing item
[2022-05-31 16:50:17,486]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 81, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _do_parallel_execution
    futures = self._configure_threads(executor)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 109, in _configure_threads
    f = executor.submit(self._handle_task, func, *args, **kwargs)
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 181, in submit
    raise RuntimeError('cannot schedule new futures after '
RuntimeError: cannot schedule new futures after interpreter shutdown
[2022-05-31 16:50:17,486]     INFO Processing #72/74
[2022-05-31 16:57:30,602]     ERROR No further results available - stopping execution
[2022-05-31 16:57:32,824]     ERROR No further results available - stopping execution
[2022-05-31 16:57:34,801]     INFO Processing #4/19
[2022-05-31 16:57:35,635]     INFO Processing #8/19
[2022-05-31 16:57:36,689]     INFO Processing #12/19
[2022-05-31 16:57:37,955]     INFO Processing #16/19
[2022-05-31 16:57:43,668]     INFO Processing #4/74
[2022-05-31 16:57:45,359]     INFO Processing #8/74
[2022-05-31 16:57:47,132]     INFO Processing #12/74
[2022-05-31 16:57:49,095]     INFO Processing #16/74
[2022-05-31 16:57:50,985]     INFO Processing #20/74
[2022-05-31 16:57:52,467]     INFO Processing #24/74
[2022-05-31 16:57:53,968]     INFO Processing #28/74
[2022-05-31 16:57:56,003]     INFO Processing #32/74
[2022-05-31 16:57:57,646]     INFO Processing #36/74
[2022-05-31 16:57:59,045]     INFO Processing #40/74
[2022-05-31 16:58:01,073]     INFO Processing #44/74
[2022-05-31 16:58:02,863]     INFO Processing #48/74
[2022-05-31 16:58:04,323]     INFO Processing #52/74
[2022-05-31 16:58:06,052]     INFO Processing #56/74
[2022-05-31 16:58:08,197]     INFO Processing #60/74
[2022-05-31 16:58:09,540]     INFO Processing #64/74
[2022-05-31 16:58:11,246]     INFO Processing #68/74
[2022-05-31 16:58:13,721]     INFO Processing #72/74
[2022-05-31 16:58:18,602]     INFO Processing #4/74
[2022-05-31 16:58:19,870]     INFO Processing #8/74
[2022-05-31 16:58:21,488]     INFO Processing #12/74
[2022-05-31 16:58:23,556]     INFO Processing #16/74
[2022-05-31 16:58:25,491]     INFO Processing #20/74
[2022-05-31 16:58:27,019]     INFO Processing #24/74
[2022-05-31 16:58:29,328]     INFO Processing #28/74
[2022-05-31 16:58:30,917]     INFO Processing #32/74
[2022-05-31 16:58:32,566]     INFO Processing #36/74
[2022-05-31 16:58:34,654]     INFO Processing #40/74
[2022-05-31 16:58:36,431]     INFO Processing #44/74
[2022-05-31 16:58:38,366]     INFO Processing #48/74
[2022-05-31 16:58:39,868]     INFO Processing #52/74
[2022-05-31 16:58:41,430]     INFO Processing #56/74
[2022-05-31 16:58:43,667]     INFO Processing #60/74
[2022-05-31 16:58:45,469]     INFO Processing #64/74
[2022-05-31 16:58:47,399]     INFO Processing #68/74
[2022-05-31 16:58:49,381]     INFO Processing #72/74
[2022-05-31 16:58:54,537]     INFO Processing #4/74
[2022-05-31 16:58:56,364]     INFO Processing #8/74
[2022-05-31 16:58:58,017]     INFO Processing #12/74
[2022-05-31 16:59:01,145]     INFO Processing #16/74
[2022-05-31 16:59:04,086]     INFO Processing #20/74
[2022-05-31 16:59:06,106]     INFO Processing #24/74
[2022-05-31 16:59:08,695]     INFO Processing #28/74
[2022-05-31 16:59:10,516]     INFO Processing #32/74
[2022-05-31 16:59:13,152]     INFO Processing #36/74
[2022-05-31 16:59:15,859]     INFO Processing #40/74
[2022-05-31 16:59:17,701]     INFO Processing #44/74
[2022-05-31 16:59:19,592]     INFO Processing #48/74
[2022-05-31 16:59:19,792]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=52&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 16:59:19,793]     INFO Rotating host
[2022-05-31 16:59:22,322]     INFO Processing #52/74
[2022-05-31 16:59:23,933]     INFO Processing #56/74
[2022-05-31 16:59:26,852]     INFO Processing #60/74
[2022-05-31 16:59:28,815]     INFO Processing #64/74
[2022-05-31 16:59:30,666]     INFO Processing #68/74
[2022-05-31 16:59:33,622]     INFO Processing #72/74
[2022-05-31 16:59:37,473]     INFO Processing #4/74
[2022-05-31 16:59:38,773]     INFO Processing #8/74
[2022-05-31 16:59:39,992]     INFO Processing #12/74
[2022-05-31 16:59:42,614]     INFO Processing #16/74
[2022-05-31 16:59:43,774]     INFO Processing #20/74
[2022-05-31 16:59:45,015]     INFO Processing #24/74
[2022-05-31 16:59:47,171]     INFO Processing #28/74
[2022-05-31 16:59:48,386]     INFO Processing #32/74
[2022-05-31 16:59:49,926]     INFO Processing #36/74
[2022-05-31 16:59:51,972]     INFO Processing #40/74
[2022-05-31 16:59:53,880]     INFO Processing #44/74
[2022-05-31 16:59:55,220]     INFO Processing #48/74
[2022-05-31 16:59:57,377]     INFO Processing #52/74
[2022-05-31 16:59:58,867]     INFO Processing #56/74
[2022-05-31 17:00:00,510]     INFO Processing #60/74
[2022-05-31 17:00:02,685]     INFO Processing #64/74
[2022-05-31 17:00:04,473]     INFO Processing #68/74
[2022-05-31 17:00:06,086]     INFO Processing #72/74
[2022-05-31 17:00:11,305]     INFO Processing #4/74
[2022-05-31 17:00:12,614]     INFO Processing #8/74
[2022-05-31 17:00:14,121]     INFO Processing #12/74
[2022-05-31 17:00:16,305]     INFO Processing #16/74
[2022-05-31 17:00:17,861]     INFO Processing #20/74
[2022-05-31 17:00:20,137]     INFO Processing #24/74
[2022-05-31 17:00:21,281]     INFO Processing #28/74
[2022-05-31 17:00:23,212]     INFO Processing #32/74
[2022-05-31 17:00:24,856]     INFO Processing #36/74
[2022-05-31 17:00:26,522]     INFO Processing #40/74
[2022-05-31 17:00:28,633]     INFO Processing #44/74
[2022-05-31 17:00:30,747]     INFO Processing #48/74
[2022-05-31 17:00:32,291]     INFO Processing #52/74
[2022-05-31 17:00:33,676]     INFO Processing #56/74
[2022-05-31 17:00:35,477]     INFO Processing #60/74
[2022-05-31 17:00:36,752]     INFO Processing #64/74
[2022-05-31 17:00:39,191]     INFO Processing #68/74
[2022-05-31 17:00:40,575]     INFO Processing #72/74
[2022-05-31 17:00:44,807]     INFO Processing #4/74
[2022-05-31 17:00:46,093]     INFO Processing #8/74
[2022-05-31 17:00:47,192]     INFO Processing #12/74
[2022-05-31 17:00:49,322]     INFO Processing #16/74
[2022-05-31 17:00:50,708]     INFO Processing #20/74
[2022-05-31 17:00:51,981]     INFO Processing #24/74
[2022-05-31 17:00:53,783]     INFO Processing #28/74
[2022-05-31 17:00:55,538]     INFO Processing #32/74
[2022-05-31 17:00:56,692]     INFO Processing #36/74
[2022-05-31 17:00:58,305]     INFO Processing #40/74
[2022-05-31 17:00:59,933]     INFO Processing #44/74
[2022-05-31 17:01:01,363]     INFO Processing #48/74
[2022-05-31 17:01:02,583]     INFO Processing #52/74
[2022-05-31 17:01:04,367]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 17:01:04,367]     INFO Rotating host
[2022-05-31 17:01:04,542]     INFO Processing #56/74
[2022-05-31 17:01:06,536]     INFO Processing #60/74
[2022-05-31 17:01:08,013]     INFO Processing #64/74
[2022-05-31 17:01:09,544]     INFO Processing #68/74
[2022-05-31 17:01:10,768]     INFO Processing #72/74
[2022-05-31 17:01:15,479]     INFO Processing #4/74
[2022-05-31 17:01:16,615]     INFO Processing #8/74
[2022-05-31 17:01:17,678]     INFO Processing #12/74
[2022-05-31 17:01:19,743]     INFO Processing #16/74
[2022-05-31 17:01:21,253]     INFO Processing #20/74
[2022-05-31 17:01:22,615]     INFO Processing #24/74
[2022-05-31 17:01:24,296]     INFO Processing #28/74
[2022-05-31 17:01:25,571]     INFO Processing #32/74
[2022-05-31 17:01:27,029]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=38&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 17:01:27,030]     INFO Rotating host
[2022-05-31 17:01:27,201]     INFO Processing #36/74
[2022-05-31 17:01:29,344]     INFO Processing #40/74
[2022-05-31 17:01:30,512]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 17:01:30,512]     INFO Rotating host
[2022-05-31 17:01:30,635]     INFO Processing #44/74
[2022-05-31 17:01:31,900]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 17:01:31,900]     INFO Rotating host
[2022-05-31 17:01:32,778]     INFO Processing #48/74
[2022-05-31 17:01:34,086]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=54&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 17:01:34,086]     INFO Rotating host
[2022-05-31 17:01:35,241]     INFO Processing #52/74
[2022-05-31 17:01:36,839]     INFO Processing #56/74
[2022-05-31 17:01:37,512]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 17:01:37,513]     INFO Rotating host
[2022-05-31 17:01:38,371]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=63&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 17:01:38,372]     INFO Rotating host
[2022-05-31 17:01:38,588]     INFO Processing #60/74
[2022-05-31 17:01:40,609]     INFO Processing #64/74
[2022-05-31 17:01:40,685]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=67&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 17:01:40,685]     INFO Rotating host
[2022-05-31 17:01:40,996]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=68&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 17:01:40,996]     INFO Rotating host
[2022-05-31 17:01:43,340]     INFO Processing #68/74
[2022-05-31 17:01:43,452]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=71&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 17:01:43,452]     INFO Rotating host
[2022-05-31 17:01:43,737]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 17:01:43,737]     INFO Rotating host
[2022-05-31 17:01:44,896]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-05-31 17:01:44,896]     INFO Rotating host
[2022-05-31 17:01:46,221]     INFO Processing #72/74
[2022-05-31 16:52:07,254]     ERROR 'BdbQuit' object has no attribute 'msg'
[2022-05-31 16:52:07,255]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 497, in get_wrapped
    return orig_get(*args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 535, in get
    return super().get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 442, in get
    self.execute(Command.GET, {'url': url})
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "<string>", line 3, in raise_from
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "/usr/local/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
  File "/usr/local/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/usr/local/lib/python3.8/http/client.py", line 277, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.8/bdb.py", line 92, in trace_dispatch
    return self.dispatch_return(frame, arg)
  File "/usr/local/lib/python3.8/bdb.py", line 154, in dispatch_return
    if self.quitting: raise BdbQuit
bdb.BdbQuit

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'BdbQuit' object has no attribute 'msg'
[2022-05-31 16:52:07,265]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,273]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61fc4160>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61fc4160>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,289]     INFO Processing #2/30
[2022-05-31 16:52:07,294]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,301]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61feb040>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61feb040>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,305]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,310]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61feb580>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61feb580>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,313]     INFO Processing #4/30
[2022-05-31 16:52:07,317]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,319]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61feba90>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61feba90>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,325]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,327]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61feb6a0>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61feb6a0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,333]     INFO Processing #6/30
[2022-05-31 16:52:07,338]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,341]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61f8a040>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61f8a040>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,364]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,364]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61f96c10>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61f96c10>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,365]     INFO Processing #8/30
[2022-05-31 16:52:07,368]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,369]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61f963a0>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61f963a0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,374]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,375]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61f9abe0>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61f9abe0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,377]     INFO Processing #10/30
[2022-05-31 16:52:07,381]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,384]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61fb0100>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61fb0100>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,402]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,403]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61feb310>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61feb310>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,403]     INFO Processing #12/30
[2022-05-31 16:52:07,436]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,437]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba700bc850>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba700bc850>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,458]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,462]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61feb4c0>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61feb4c0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,465]     INFO Processing #14/30
[2022-05-31 16:52:07,476]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,477]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61fe7970>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61fe7970>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,492]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,495]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61fe7130>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61fe7130>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,496]     INFO Processing #16/30
[2022-05-31 16:52:07,507]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,507]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61fbbca0>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61fbbca0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,510]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,515]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61ff60a0>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61ff60a0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,516]     INFO Processing #18/30
[2022-05-31 16:52:07,518]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,522]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61ff62b0>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61ff62b0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,533]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,533]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61754400>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61754400>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,537]     INFO Processing #20/30
[2022-05-31 16:52:07,539]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,539]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61ff60d0>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61ff60d0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,544]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,545]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61754df0>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61754df0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,557]     INFO Processing #22/30
[2022-05-31 16:52:07,560]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,571]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba617540a0>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba617540a0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,588]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,589]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61fbbb20>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61fbbb20>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,602]     INFO Processing #24/30
[2022-05-31 16:52:07,610]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,613]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61771910>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61771910>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,623]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,624]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba617766a0>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba617766a0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,632]     INFO Processing #26/30
[2022-05-31 16:52:07,635]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,635]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba617545b0>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba617545b0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,642]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,642]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba617761c0>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba617761c0>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,648]     INFO Processing #28/30
[2022-05-31 16:52:07,650]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,650]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61779f10>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61779f10>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,656]     ERROR 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,656]     DEBUG See traceback
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
    raise err
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 205, in connect
    conn = self._new_conn()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7fba61fbbb20>: Failed to establish a new connection: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 42, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 54, in inner
    func(driver, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 90, in get
    self._chrome.get(url)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 456, in get_wrapped
    if self.execute_script("return navigator.webdriver"):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 884, in execute_script
    return self.execute(command, {
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 369, in _request
    response = self._conn.request(method, url, body=body, headers=headers)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 78, in request
    return self.request_encode_body(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/request.py", line 170, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/poolmanager.py", line 376, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 813, in urlopen
    return self.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=53315): Max retries exceeded with url: /session/7f56f8420a8b3d09ac77f994f82921cd/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fba61fbbb20>: Failed to establish a new connection: [Errno 111] Connection refused'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 75, in _handle_error
    logger.error(exc.msg)
AttributeError: 'MaxRetryError' object has no attribute 'msg'
[2022-05-31 16:52:07,661]     INFO Processing #30/30
[2022-05-31 16:52:49,397]     INFO Processing #2/30
[2022-05-31 16:52:55,848]     INFO Processing #4/30
[2022-05-31 16:53:04,205]     INFO Processing #6/30
[2022-05-31 16:53:12,388]     INFO Processing #8/30
[2022-05-31 16:53:21,047]     INFO Processing #10/30
[2022-05-31 16:53:30,685]     INFO Processing #12/30
[2022-05-31 16:53:40,699]     INFO Processing #14/30
[2022-05-31 16:53:51,224]     INFO Processing #16/30
[2022-05-31 16:54:03,817]     INFO Processing #18/30
[2022-05-31 16:54:15,443]     INFO Processing #20/30
[2022-05-31 16:54:28,487]     INFO Processing #22/30
[2022-05-31 16:54:41,931]     INFO Processing #24/30
[2022-05-31 16:54:55,655]     INFO Processing #26/30
[2022-05-31 16:55:10,771]     INFO Processing #28/30
[2022-05-31 16:55:28,862]     INFO Processing #30/30
[2022-06-01 09:54:57,865]     DEBUG oops
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/test.py", line 38, in <module>
    i = 0
  File "/home/gravy/Dropbox/code/syllabus/tsutils/test.py", line 38, in <module>
    i = 0
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-06-01 09:56:24,054]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:25,504]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:25,584]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:26,790]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:26,868]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:26,945]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:27,971]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:28,833]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:28,915]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:28,993]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:29,084]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:29,852]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:30,683]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:30,760]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:32,626]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:32,845]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:33,198]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:33,382]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:34,444]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:35,350]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:35,421]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:37,066]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:37,176]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:38,019]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:38,623]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:40,249]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:45,657]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:45,729]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:47,113]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:47,721]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:47,794]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:49,566]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:51,651]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:53,659]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:53,736]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:55,268]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:55,348]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:56,503]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:56,749]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:59,434]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:56:59,532]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:03,325]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:04,800]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:05,996]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:06,076]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:06,166]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:07,264]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:08,191]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:08,288]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:09,081]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:11,414]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:12,375]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:13,008]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:13,091]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:13,165]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:13,246]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:13,323]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:18,034]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:18,115]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:19,346]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:22,412]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:25,002]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:28,015]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:28,095]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:32,334]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:38,966]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:41,249]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:41,334]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:42,645]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:42,715]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:44,148]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:44,226]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:48,870]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:49,181]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:49,311]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:50,034]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:51,204]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:51,830]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:52,483]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:52,573]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:54,440]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:55,358]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:56,201]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:56,278]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:56,348]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:57,008]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:57,748]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:57:57,825]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:58:01,166]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:58:01,272]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:58:06,261]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:58:07,421]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:58:07,500]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:58:08,928]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:58:11,217]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 09:58:12,219]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 10:01:31,986]     DEBUG oops
Traceback (most recent call last):
  File "test.py", line 52, in <module>
    print(f'Did it {url_data.values["abstract_description"][:50]}')
TypeError: 'builtin_function_or_method' object is not subscriptable
[2022-06-01 10:01:37,589]     DEBUG oops
Traceback (most recent call last):
  File "test.py", line 52, in <module>
    print(f'Did it {url_data.values["abstract_description"][:50]}')
TypeError: 'builtin_function_or_method' object is not subscriptable
[2022-06-01 10:01:41,535]     DEBUG oops
Traceback (most recent call last):
  File "test.py", line 52, in <module>
    print(f'Did it {url_data.values["abstract_description"][:50]}')
TypeError: 'builtin_function_or_method' object is not subscriptable
[2022-06-01 10:02:04,267]     INFO oops
Traceback (most recent call last):
  File "test.py", line 52, in <module>
    print(f'Did it {url_data.values["abstract_description"][:50]}')
TypeError: 'builtin_function_or_method' object is not subscriptable
[2022-06-01 10:02:48,783]     DEBUG Request failed - 403 raised requesting https://onlinelibrary.wiley.com/doi/10.1111/imig.13019
[2022-06-01 10:02:48,784]     INFO Request failed. Rotating host
[2022-06-01 10:02:52,189]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 10:02:52,189]     INFO oops
KeyError: 'abstract_description'
[2022-06-01 10:08:33,024]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 10:08:33,025]     INFO oops
KeyError: 'abstract_description'
[2022-06-01 10:09:28,061]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 10:09:28,063]     DEBUG oops
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.

During handling of the above exception, another exception occurred:

AttributeError: 'CloudflareChallengeError' object has no attribute 'msg'
[2022-06-01 10:10:41,318]     ERROR Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.
[2022-06-01 10:10:41,319]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:10:42,445]     ERROR Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.
[2022-06-01 10:10:42,446]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:10:42,446]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.
[2022-06-01 10:10:42,447]     DEBUG oops
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.
[2022-06-01 10:11:54,019]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:11:55,120]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:11:55,121]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.
[2022-06-01 10:11:55,125]     DEBUG oops
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.
[2022-06-01 10:13:18,467]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:13:19,566]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:13:19,566]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.
[2022-06-01 10:13:19,567]     DEBUG oops
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.
[2022-06-01 10:15:10,190]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:15:13,772]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:15:13,773]     DEBUG Error raised while processing item
cloudscraper.exceptions.CloudflareChallengeError: Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.
[2022-06-01 10:17:55,359]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:17:56,607]     DEBUG Rotating host (HTTPSConnectionPool(host='onlinelibrary.wiley.com', port=443): Max retries exceeded with url: /doi/10.1111/imig.13019 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 10:17:56,607]     DEBUG Error raised while processing item
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='onlinelibrary.wiley.com', port=443): Max retries exceeded with url: /doi/10.1111/imig.13019 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer')))

During handling of the above exception, another exception occurred:

requests.exceptions.ProxyError: HTTPSConnectionPool(host='onlinelibrary.wiley.com', port=443): Max retries exceeded with url: /doi/10.1111/imig.13019 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer')))
[2022-06-01 10:17:56,607]     DEBUG oops
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='onlinelibrary.wiley.com', port=443): Max retries exceeded with url: /doi/10.1111/imig.13019 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer')))

During handling of the above exception, another exception occurred:

requests.exceptions.ProxyError: HTTPSConnectionPool(host='onlinelibrary.wiley.com', port=443): Max retries exceeded with url: /doi/10.1111/imig.13019 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer')))
[2022-06-01 10:19:14,616]     DEBUG Rotating host (HTTPSConnectionPool(host='onlinelibrary.wiley.com', port=443): Max retries exceeded with url: /doi/10.1111/imig.13019 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 10:19:15,863]     DEBUG Rotating host (HTTPSConnectionPool(host='onlinelibrary.wiley.com', port=443): Max retries exceeded with url: /doi/10.1111/imig.13019 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 10:19:15,863]     DEBUG HTTPSConnectionPool(host='onlinelibrary.wiley.com', port=443): Max retries exceeded with url: /doi/10.1111/imig.13019 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised while processing item
[2022-06-01 10:19:15,863]     DEBUG oops
Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 700, in urlopen
    self._prepare_proxy(conn)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 994, in _prepare_proxy
    conn.connect()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connection.py", line 369, in connect
    self._tunnel()
  File "/usr/local/lib/python3.8/http/client.py", line 901, in _tunnel
    (version, code, message) = response._read_status()
  File "/usr/local/lib/python3.8/http/client.py", line 277, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [Errno 104] Connection reset by peer

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/adapters.py", line 440, in send
    resp = conn.urlopen(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='onlinelibrary.wiley.com', port=443): Max retries exceeded with url: /doi/10.1111/imig.13019 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer')))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "test.py", line 54, in <module>
    url_data = rqstr_sess.scrape_url(url, cookies=cookies)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 70, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 80, in execute
    return self._do_sequential_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 93, in _do_sequential_execution
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 116, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 82, in _handle_error
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 44, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 107, in get
    resp = self.sess.get(url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 257, in request
    self.perform_request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/cloudscraper/__init__.py", line 190, in perform_request
    return super(CloudScraper, self).request(method, url, *args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/requests/adapters.py", line 513, in send
    raise ProxyError(e, request=request)
requests.exceptions.ProxyError: HTTPSConnectionPool(host='onlinelibrary.wiley.com', port=443): Max retries exceeded with url: /doi/10.1111/imig.13019 (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer')))
[2022-06-01 10:20:35,304]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:20:37,223]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:20:37,223]     DEBUG Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised while processing item
[2022-06-01 10:20:41,844]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:20:43,761]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:20:43,761]     DEBUG Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised while processing item
[2022-06-01 10:20:49,031]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:20:50,984]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:20:50,984]     DEBUG Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised while processing item
[2022-06-01 10:20:58,271]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:21:00,195]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:21:00,195]     DEBUG Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised while processing item
[2022-06-01 10:21:08,177]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:21:10,194]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:21:10,194]     DEBUG Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised while processing item
[2022-06-01 10:21:58,803]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:21:59,900]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:21:59,901]     DEBUG Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised while processing item
[2022-06-01 10:22:02,868]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:22:03,950]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:22:03,950]     DEBUG Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised while processing item
[2022-06-01 10:22:30,444]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:22:31,526]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:22:31,527]     DEBUG Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised while processing item
[2022-06-01 10:23:40,375]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:23:41,462]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:23:41,463]     DEBUG Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised while processing item
[2022-06-01 10:23:45,140]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:23:46,541]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:23:46,541]     DEBUG Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised while processing item
[2022-06-01 10:23:49,670]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:23:50,751]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:23:50,751]     DEBUG Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised while processing item
[2022-06-01 10:25:40,771]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:25:47,673]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:25:54,710]     DEBUG Rotating host (HTTPSConnectionPool(host='onlinelibrary.wiley.com', port=443): Max retries exceeded with url: /doi/10.1111/imig.13019 (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 10:25:57,043]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:26:01,039]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:26:04,902]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:26:04,902]     DEBUG Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised while processing item
[2022-06-01 10:26:10,170]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:26:14,454]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:29:34,586]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:29:35,680]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:29:35,680]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised and ignored while processing item
[2022-06-01 10:32:49,595]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:32:50,714]     DEBUG Rotating host (Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.)
[2022-06-01 10:34:57,731]     DEBUG Rotating host ()
[2022-06-01 10:34:58,738]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=44425): Max retries exceeded with url: /session/5ebc65e80a4004256f520a26dc54047f/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f33cc1d02b0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 10:37:23,451]     INFO 
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/test.py", line 53, in <module>
    rqstr_sess.sources[0]._scraper._host = driver_sess.sources[0]._scraper._chrome.host
AttributeError: 'bool' object has no attribute '_host'
[2022-06-01 10:39:20,186]     INFO 
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/test.py", line 55, in <module>
    out.append(url_data)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/test.py", line 55, in <module>
    out.append(url_data)
  File "/usr/local/lib/python3.8/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/usr/local/lib/python3.8/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
[2022-06-01 12:33:08,694]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Read timed out. (read timeout=5))
[2022-06-01 12:33:52,463]     ERROR No further results available - stopping execution
[2022-06-01 12:33:52,464]     DEBUG See traceback
NoneType: None
[2022-06-01 12:33:57,497]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 12:34:02,119]     ERROR No further results available - stopping execution
[2022-06-01 12:34:02,120]     DEBUG See traceback
NoneType: None
[2022-06-01 12:34:09,088]     INFO Processing #4/19
[2022-06-01 12:34:15,348]     INFO Processing #8/19
[2022-06-01 12:35:24,539]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 12:35:27,414]     ERROR No further results available - stopping execution
[2022-06-01 12:35:27,414]     DEBUG See traceback
NoneType: None
[2022-06-01 12:35:30,778]     ERROR No further results available - stopping execution
[2022-06-01 12:35:30,778]     DEBUG See traceback
NoneType: None
[2022-06-01 12:35:37,459]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22professor+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 12:35:41,019]     INFO Processing #4/19
[2022-06-01 12:35:45,441]     INFO Processing #8/19
[2022-06-01 12:37:45,665]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 12:37:49,305]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 12:37:49,306]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 12:37:59,131]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 12:38:24,058]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 12:38:24,059]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 12:38:28,990]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 12:38:28,990]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 12:38:32,006]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/Stanford-University-Press-Books/s?k=%22Stanford+University+Press%22&rh=n%3A283155
[2022-06-01 12:38:32,007]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/Stanford-University-Press-Books/s?k=%22Stanford+University+Press%22&rh=n%3A283155)
[2022-06-01 12:38:32,007]     INFO 503 raised requesting https://www.amazon.com/Stanford-University-Press-Books/s?k=%22Stanford+University+Press%22&rh=n%3A283155 raised and ignored while processing item
[2022-06-01 12:38:32,397]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 12:38:32,397]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 12:38:33,537]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/professor-Books/s?k=%22professor+of%22&rh=n%3A283155
[2022-06-01 12:38:33,538]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/professor-Books/s?k=%22professor+of%22&rh=n%3A283155)
[2022-06-01 12:38:33,589]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 12:38:33,589]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 12:38:33,590]     INFO 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 12:39:22,644]     ERROR No further results available - stopping execution
[2022-06-01 12:39:22,645]     DEBUG See traceback
NoneType: None
[2022-06-01 12:39:25,761]     ERROR No further results available - stopping execution
[2022-06-01 12:39:25,762]     DEBUG See traceback
NoneType: None
[2022-06-01 12:39:31,822]     INFO Processing #4/19
[2022-06-01 12:42:02,507]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 12:42:53,065]     ERROR No further results available - stopping execution
[2022-06-01 12:42:53,066]     DEBUG See traceback
NoneType: None
[2022-06-01 12:42:58,462]     DEBUG Rotating host ()
[2022-06-01 12:43:27,416]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 12:47:59,987]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 12:49:03,134]     ERROR No further results available - stopping execution
[2022-06-01 12:49:03,134]     DEBUG See traceback
NoneType: None
[2022-06-01 12:49:06,857]     ERROR No further results available - stopping execution
[2022-06-01 12:49:06,857]     DEBUG See traceback
NoneType: None
[2022-06-01 12:49:10,161]     INFO Processing #2/19
[2022-06-01 12:49:15,292]     INFO Processing #4/19
[2022-06-01 12:49:22,279]     INFO Processing #6/19
[2022-06-01 12:49:25,463]     INFO Processing #8/19
[2022-06-01 12:49:54,352]     ERROR No further results available - stopping execution
[2022-06-01 12:49:54,353]     DEBUG See traceback
NoneType: None
[2022-06-01 12:49:59,970]     ERROR No further results available - stopping execution
[2022-06-01 12:49:59,970]     DEBUG See traceback
NoneType: None
[2022-06-01 12:50:07,651]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 12:50:07,726]     INFO Processing #4/19
[2022-06-01 12:50:09,778]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 12:50:09,778]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 12:50:10,256]     INFO Processing #8/19
[2022-06-01 12:50:10,462]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 12:50:10,464]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 12:50:10,554]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 12:50:10,555]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 12:50:10,743]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 12:50:10,743]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 12:50:10,945]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 12:50:10,945]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 12:50:10,962]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 12:50:10,963]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 12:50:31,007]     ERROR No further results available - stopping execution
[2022-06-01 12:50:31,007]     DEBUG See traceback
NoneType: None
[2022-06-01 12:50:31,664]     DEBUG Rotating host ('Requester' object has no attribute '_solve_captcha')
[2022-06-01 12:50:36,356]     ERROR No further results available - stopping execution
[2022-06-01 12:50:36,357]     DEBUG See traceback
NoneType: None
[2022-06-01 12:50:39,519]     INFO Processing #4/19
[2022-06-01 12:50:41,657]     INFO Processing #8/19
[2022-06-01 12:50:43,597]     INFO Processing #12/19
[2022-06-01 12:50:46,487]     INFO Processing #16/19
[2022-06-01 12:50:46,732]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22professor+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 12:50:53,682]     INFO Processing #4/74
[2022-06-01 12:50:55,313]     INFO Processing #8/74
[2022-06-01 12:50:56,917]     INFO Processing #12/74
[2022-06-01 12:50:59,502]     INFO Processing #16/74
[2022-06-01 12:50:59,566]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 12:51:02,967]     INFO Processing #20/74
[2022-06-01 12:51:05,967]     INFO Processing #24/74
[2022-06-01 12:51:09,428]     INFO Processing #28/74
[2022-06-01 12:51:11,731]     INFO Processing #32/74
[2022-06-01 12:51:14,126]     INFO Processing #36/74
[2022-06-01 12:51:14,376]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=40&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 12:51:17,220]     INFO Processing #40/74
[2022-06-01 12:51:18,841]     INFO Processing #44/74
[2022-06-01 12:51:21,607]     INFO Processing #48/74
[2022-06-01 12:51:23,387]     INFO Processing #52/74
[2022-06-01 12:51:24,975]     INFO Processing #56/74
[2022-06-01 12:51:25,036]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=60&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 12:51:27,689]     INFO Processing #60/74
[2022-06-01 12:51:29,124]     INFO Processing #64/74
[2022-06-01 12:51:31,397]     INFO Processing #68/74
[2022-06-01 12:51:33,567]     INFO Processing #72/74
[2022-06-01 12:51:38,044]     INFO Processing #4/74
[2022-06-01 12:51:39,582]     INFO Processing #8/74
[2022-06-01 12:51:41,055]     INFO Processing #12/74
[2022-06-01 12:51:43,208]     INFO Processing #16/74
[2022-06-01 12:51:44,903]     INFO Processing #20/74
[2022-06-01 12:51:46,603]     INFO Processing #24/74
[2022-06-01 12:51:48,542]     INFO Processing #28/74
[2022-06-01 12:51:50,183]     INFO Processing #32/74
[2022-06-01 12:51:52,773]     INFO Processing #36/74
[2022-06-01 12:51:54,529]     INFO Processing #40/74
[2022-06-01 12:51:56,053]     INFO Processing #44/74
[2022-06-01 12:51:59,459]     INFO Processing #48/74
[2022-06-01 12:52:00,787]     INFO Processing #52/74
[2022-06-01 12:52:02,524]     INFO Processing #56/74
[2022-06-01 12:52:04,680]     INFO Processing #60/74
[2022-06-01 12:52:06,442]     INFO Processing #64/74
[2022-06-01 12:52:07,883]     INFO Processing #68/74
[2022-06-01 12:52:10,009]     INFO Processing #72/74
[2022-06-01 12:52:15,397]     INFO Processing #4/74
[2022-06-01 12:52:17,117]     INFO Processing #8/74
[2022-06-01 12:52:18,621]     INFO Processing #12/74
[2022-06-01 12:52:22,412]     INFO Processing #16/74
[2022-06-01 12:52:24,546]     INFO Processing #20/74
[2022-06-01 12:52:26,336]     INFO Processing #24/74
[2022-06-01 12:52:29,006]     INFO Processing #28/74
[2022-06-01 12:52:30,823]     INFO Processing #32/74
[2022-06-01 12:52:32,856]     INFO Processing #36/74
[2022-06-01 12:52:36,708]     INFO Processing #40/74
[2022-06-01 12:52:38,692]     INFO Processing #44/74
[2022-06-01 12:52:39,599]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 12:52:39,599]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 12:52:40,965]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 12:52:40,965]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 12:52:40,965]     INFO 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 12:52:40,965]     INFO 'tuple' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 12:52:40,966]     INFO Processing #48/74
[2022-06-01 12:52:45,173]     INFO Processing #52/74
[2022-06-01 12:52:48,692]     INFO Processing #56/74
[2022-06-01 12:52:52,331]     INFO Processing #60/74
[2022-06-01 12:52:56,673]     INFO Processing #64/74
[2022-06-01 12:52:59,433]     INFO Processing #68/74
[2022-06-01 12:53:07,349]     INFO Processing #72/74
[2022-06-01 12:53:07,641]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 12:53:14,493]     INFO Processing #4/74
[2022-06-01 12:53:16,374]     INFO Processing #8/74
[2022-06-01 12:53:18,492]     INFO Processing #12/74
[2022-06-01 12:53:22,044]     INFO Processing #16/74
[2022-06-01 12:53:22,370]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 12:53:22,395]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 12:53:24,825]     INFO Processing #20/74
[2022-06-01 12:53:26,750]     INFO Processing #24/74
[2022-06-01 12:53:28,791]     INFO Processing #28/74
[2022-06-01 12:53:31,136]     INFO Processing #32/74
[2022-06-01 12:53:33,351]     INFO Processing #36/74
[2022-06-01 12:53:34,299]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&page=41&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 12:53:34,349]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&page=42&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 12:53:40,199]     INFO Processing #40/74
[2022-06-01 12:53:40,334]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&page=41&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 12:53:40,335]     INFO HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&page=41&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))) raised and ignored while processing item
[2022-06-01 12:53:40,335]     INFO 'tuple' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 12:53:40,352]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&page=43&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 12:53:41,426]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&page=43&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 12:53:41,427]     INFO HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&page=43&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 12:53:41,427]     INFO 'tuple' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 12:53:42,381]     INFO Processing #44/74
[2022-06-01 12:53:46,261]     INFO Processing #48/74
[2022-06-01 12:53:48,774]     INFO Processing #52/74
[2022-06-01 12:53:51,186]     INFO Processing #56/74
[2022-06-01 12:53:54,639]     INFO Processing #60/74
[2022-06-01 12:53:55,381]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 12:53:56,446]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 12:53:56,446]     INFO HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 12:53:56,446]     INFO 'tuple' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 12:53:56,596]     INFO Processing #64/74
[2022-06-01 12:53:59,112]     INFO Processing #68/74
[2022-06-01 12:54:00,755]     INFO Processing #72/74
[2022-06-01 12:54:05,770]     INFO Processing #4/74
[2022-06-01 12:54:07,103]     INFO Processing #8/74
[2022-06-01 12:54:08,741]     INFO Processing #12/74
[2022-06-01 12:54:10,894]     INFO Processing #16/74
[2022-06-01 12:54:12,261]     INFO Processing #20/74
[2022-06-01 12:54:13,801]     INFO Processing #24/74
[2022-06-01 12:54:15,920]     INFO Processing #28/74
[2022-06-01 12:54:17,936]     INFO Processing #32/74
[2022-06-01 12:54:19,522]     INFO Processing #36/74
[2022-06-01 12:54:21,206]     INFO Processing #40/74
[2022-06-01 12:54:23,666]     INFO Processing #44/74
[2022-06-01 12:54:25,093]     INFO Processing #48/74
[2022-06-01 12:54:26,402]     INFO Processing #52/74
[2022-06-01 12:54:28,241]     INFO Processing #56/74
[2022-06-01 12:54:29,821]     INFO Processing #60/74
[2022-06-01 12:54:30,987]     INFO Processing #64/74
[2022-06-01 12:54:32,733]     INFO Processing #68/74
[2022-06-01 12:54:34,294]     INFO Processing #72/74
[2022-06-01 12:54:38,321]     INFO Processing #4/74
[2022-06-01 12:54:39,553]     INFO Processing #8/74
[2022-06-01 12:54:40,906]     INFO Processing #12/74
[2022-06-01 12:54:42,800]     INFO Processing #16/74
[2022-06-01 12:54:43,837]     INFO Processing #20/74
[2022-06-01 12:54:46,103]     INFO Processing #24/74
[2022-06-01 12:54:47,890]     INFO Processing #28/74
[2022-06-01 12:54:49,569]     INFO Processing #32/74
[2022-06-01 12:54:50,957]     INFO Processing #36/74
[2022-06-01 12:54:52,675]     INFO Processing #40/74
[2022-06-01 12:54:53,988]     INFO Processing #44/74
[2022-06-01 12:54:55,742]     INFO Processing #48/74
[2022-06-01 12:54:57,635]     INFO Processing #52/74
[2022-06-01 12:54:58,857]     INFO Processing #56/74
[2022-06-01 12:55:00,749]     INFO Processing #60/74
[2022-06-01 12:55:01,953]     INFO Processing #64/74
[2022-06-01 12:55:03,938]     INFO Processing #68/74
[2022-06-01 12:55:04,887]     INFO Processing #72/74
[2022-06-01 12:55:08,704]     INFO Processing #4/74
[2022-06-01 12:55:08,960]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 12:55:08,960]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 12:55:10,059]     INFO Processing #8/74
[2022-06-01 12:55:15,399]     INFO Processing #12/74
[2022-06-01 12:55:16,648]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 12:55:16,648]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 12:55:21,800]     INFO Processing #16/74
[2022-06-01 12:55:23,996]     INFO Processing #20/74
[2022-06-01 12:55:26,078]     INFO Processing #24/74
[2022-06-01 12:55:36,178]     INFO Processing #28/74
[2022-06-01 12:55:39,540]     INFO Processing #32/74
[2022-06-01 12:55:39,855]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22policy%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 12:55:44,832]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22policy%22&i=stripbooks&s=daterank&page=35&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 12:55:45,903]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22policy%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 12:55:45,904]     INFO HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22policy%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))) raised and ignored while processing item
[2022-06-01 12:55:45,904]     INFO 'tuple' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 12:55:47,326]     INFO Processing #36/74
[2022-06-01 12:55:49,098]     INFO Processing #40/74
[2022-06-01 12:55:50,451]     INFO Processing #44/74
[2022-06-01 12:55:52,750]     INFO Processing #48/74
[2022-06-01 12:55:54,471]     INFO Processing #52/74
[2022-06-01 12:55:55,864]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22policy%22&i=stripbooks&s=daterank&page=58&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 12:55:56,080]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 12:55:56,080]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 12:55:56,170]     INFO Processing #56/74
[2022-06-01 12:55:58,120]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 12:55:58,121]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 12:56:01,030]     INFO Processing #60/74
[2022-06-01 12:56:04,688]     INFO Processing #64/74
[2022-06-01 12:56:06,995]     INFO Processing #68/74
[2022-06-01 12:56:10,363]     INFO Processing #72/74
[2022-06-01 13:00:33,022]     ERROR No further results available - stopping execution
[2022-06-01 13:00:33,023]     DEBUG See traceback
NoneType: None
[2022-06-01 13:00:33,226]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:00:33,226]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:00:38,159]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:00:46,114]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:00:47,365]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:00:47,365]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:00:47,382]     ERROR No further results available - stopping execution
[2022-06-01 13:00:47,383]     DEBUG See traceback
NoneType: None
[2022-06-01 13:00:47,836]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:00:47,836]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:00:52,257]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:00:52,257]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:00:52,566]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22professor+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:00:54,269]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22professor+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:00:54,719]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:00:54,719]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:00:54,971]     INFO Processing #4/5
[2022-06-01 13:00:59,422]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22professor+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:01:11,706]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:01:11,706]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:01:11,737]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:01:11,737]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:01:14,218]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:01:14,218]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:01:16,678]     INFO Processing #4/5
[2022-06-01 13:02:32,119]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:32,119]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:32,124]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:32,124]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:32,269]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:32,270]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:33,292]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:33,292]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:33,293]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:33,293]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:33,293]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:33,293]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:33,429]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:33,429]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:33,736]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:33,737]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:33,737]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:33,737]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:33,737]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:33,737]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:35,062]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:35,062]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:35,062]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:35,470]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:35,470]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:35,470]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:36,140]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:36,141]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:36,141]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:36,142]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:36,288]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:36,289]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:37,310]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:37,311]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:37,311]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:37,311]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:37,311]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:37,312]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:37,449]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:37,449]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:37,610]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:37,611]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:37,613]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:37,613]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:37,614]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:37,614]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:38,776]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:38,776]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:38,776]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:38,795]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:38,795]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:38,795]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:38,923]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:38,923]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:39,084]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:39,085]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:39,087]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:39,088]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:39,088]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:39,088]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:40,257]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:40,258]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:40,259]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:40,258]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:40,259]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:40,259]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:40,263]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:40,263]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:40,440]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:40,441]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:40,441]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:40,441]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:40,588]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:40,589]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:41,634]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:41,634]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:41,634]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:41,635]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:41,636]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:41,636]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:41,761]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:41,761]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:41,917]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:41,918]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:41,934]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:41,934]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:41,939]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:41,939]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:43,078]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:43,079]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:43,079]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:43,096]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:43,097]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:43,097]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:43,324]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:43,324]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:43,484]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:43,486]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:43,486]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:43,486]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:43,488]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:43,488]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:44,662]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:44,662]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:44,662]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:44,665]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:44,665]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:44,665]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:44,884]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:44,884]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:45,047]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:45,048]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:45,048]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:45,050]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:45,056]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:45,057]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:46,310]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:46,311]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:46,311]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:46,313]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:46,313]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:46,313]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:46,314]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:46,314]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:46,481]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:46,483]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:46,483]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:46,485]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:46,485]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:46,485]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:47,657]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:47,657]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:47,657]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:47,660]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:47,661]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:02:47,661]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:02:47,885]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:02:47,885]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:03:24,474]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:03:24,475]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:03:27,704]     ERROR No further results available - stopping execution
[2022-06-01 13:03:27,705]     DEBUG See traceback
NoneType: None
[2022-06-01 13:03:27,908]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:03:27,908]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:03:32,745]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:03:35,507]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:03:35,507]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:03:41,117]     ERROR No further results available - stopping execution
[2022-06-01 13:03:41,117]     DEBUG See traceback
NoneType: None
[2022-06-01 13:03:41,371]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:03:41,371]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:03:42,935]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:03:42,935]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:03:43,226]     DEBUG Rotating host ('Requester' object has no attribute '_solve_captcha')
[2022-06-01 13:03:44,113]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:03:44,113]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:03:44,113]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:03:45,358]     INFO Processing #4/5
[2022-06-01 13:03:51,763]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:03:51,763]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:03:51,765]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:03:51,765]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:03:55,215]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:03:55,215]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:03:58,183]     INFO Processing #4/5
[2022-06-01 13:03:59,251]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:03:59,251]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:04:03,194]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:04:03,195]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:04:04,372]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:04:04,373]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:04:04,373]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:04:05,391]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:04:05,391]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:04:10,997]     INFO Processing #4/5
[2022-06-01 13:04:14,566]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:04:14,566]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:04:14,585]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:04:14,585]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:04:17,148]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:04:17,148]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:04:20,113]     INFO Processing #4/5
[2022-06-01 13:04:25,137]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:04:25,265]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:04:25,266]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:04:26,436]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:04:26,437]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:04:26,437]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:04:28,018]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:04:28,019]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:04:31,992]     INFO Processing #4/5
[2022-06-01 13:04:39,408]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:04:39,409]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:04:39,556]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:04:39,557]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:04:41,386]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:04:41,387]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:04:44,240]     INFO Processing #4/5
[2022-06-01 13:04:54,284]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:04:54,284]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:04:57,430]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:04:57,431]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:04:58,593]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:04:58,593]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:04:58,593]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:04:59,331]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:04:59,331]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:05:04,196]     INFO Processing #4/5
[2022-06-01 13:05:06,996]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:05:06,997]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:05:07,005]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:05:07,006]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:05:08,709]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:05:08,712]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:05:08,877]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:05:08,877]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:05:11,685]     INFO Processing #4/5
[2022-06-01 13:05:14,819]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22policy%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:05:42,627]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:05:42,628]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:05:45,511]     ERROR No further results available - stopping execution
[2022-06-01 13:05:45,512]     DEBUG See traceback
NoneType: None
[2022-06-01 13:05:45,696]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:05:45,697]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:05:46,198]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:05:46,198]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:05:49,393]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:05:49,393]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:05:51,973]     ERROR No further results available - stopping execution
[2022-06-01 13:05:51,974]     DEBUG See traceback
NoneType: None
[2022-06-01 13:05:52,204]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:05:52,204]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:05:53,775]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:05:53,775]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:05:55,466]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:05:55,466]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:05:55,467]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:05:56,271]     INFO Processing #4/19
[2022-06-01 13:05:56,455]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:05:56,455]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:05:59,620]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:05:59,620]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:00,690]     INFO Processing #8/19
[2022-06-01 13:06:00,858]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:00,858]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:02,021]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:02,021]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:02,021]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:06:02,560]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:02,560]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:04,769]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:04,770]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:04,839]     INFO Processing #12/19
[2022-06-01 13:06:05,403]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:05,403]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:07,082]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:07,082]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:08,664]     INFO Processing #16/19
[2022-06-01 13:06:08,834]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:08,834]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:14,466]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:14,573]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:14,573]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:14,595]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:14,596]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:16,830]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:16,931]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:16,932]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:17,673]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:17,782]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:17,783]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:18,944]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:18,945]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:18,945]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:06:19,837]     INFO Processing #4/74
[2022-06-01 13:06:19,901]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:20,563]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:20,564]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:20,568]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:21,732]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:21,732]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:21,733]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:06:22,619]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:22,820]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:23,049]     INFO Processing #8/74
[2022-06-01 13:06:23,118]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:23,223]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:23,223]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:23,308]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:23,334]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:23,542]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:23,866]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:23,866]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:23,874]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:23,874]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:24,274]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:24,274]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:24,447]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:24,447]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:24,447]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:06:24,553]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:24,554]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:24,613]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:24,621]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:24,740]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:24,740]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:24,790]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:24,790]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:24,847]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:24,851]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:25,673]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:25,673]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:25,786]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:25,787]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:25,787]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:25,787]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:06:25,787]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:25,788]     DEBUG 'tuple' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 13:06:25,788]     INFO Processing #12/74
[2022-06-01 13:06:25,904]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:25,904]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:26,026]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:26,026]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:26,027]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:06:26,033]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:26,044]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:26,145]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:26,337]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:26,665]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:26,775]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:26,775]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:26,844]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:27,079]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:27,079]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:27,288]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:27,288]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:27,580]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:27,580]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:27,721]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:27,721]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:27,938]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:27,938]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:27,938]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:06:28,562]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:28,564]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:29,130]     INFO Processing #16/74
[2022-06-01 13:06:29,189]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:29,202]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:29,455]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:29,455]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:29,589]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:29,616]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:29,616]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:29,768]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:29,768]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:29,768]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:06:30,195]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:30,405]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:30,405]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:30,499]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:30,676]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:30,676]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:30,934]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:30,934]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:30,934]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:06:31,555]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:31,555]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:31,575]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:31,576]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:32,144]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:32,144]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:32,221]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:32,370]     INFO Processing #20/74
[2022-06-01 13:06:32,463]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:32,631]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:32,731]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:32,828]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:32,828]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:32,924]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:33,195]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:33,195]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:33,464]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:33,537]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:33,537]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:33,569]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:33,670]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:33,670]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:33,684]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:33,684]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:33,749]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:33,893]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:33,893]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:34,166]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:34,167]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:34,343]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:34,359]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:34,462]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:34,463]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:34,757]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:34,760]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:34,817]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:34,817]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:34,997]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:34,998]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:34,998]     INFO Processing #24/74
[2022-06-01 13:06:35,058]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:35,062]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:35,171]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:35,171]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:35,437]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:35,437]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:35,589]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:35,589]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:35,710]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:35,710]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:35,746]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:35,786]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:35,961]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:35,966]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:36,008]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:36,009]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:36,116]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:36,117]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:36,217]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:36,217]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:36,227]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:36,228]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:36,228]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:06:36,325]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:36,488]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:36,805]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:36,805]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:36,948]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:36,949]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:36,949]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:06:37,087]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:37,087]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:37,210]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:37,211]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:37,379]     INFO Processing #28/74
[2022-06-01 13:06:37,442]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:37,445]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:37,552]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:37,553]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:37,567]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:37,567]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:37,731]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:37,732]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:38,383]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:38,495]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:38,496]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:38,603]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:38,603]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:38,603]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:06:39,455]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:39,455]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:40,441]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:40,442]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:40,823]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=35&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:40,865]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=35&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:42,028]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=35&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:42,028]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=35&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:42,028]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=35&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:06:43,092]     INFO Processing #32/74
[2022-06-01 13:06:43,166]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:43,400]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:43,400]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:43,441]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=38&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))))
[2022-06-01 13:06:43,452]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=38&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:44,413]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:44,414]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:44,460]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:44,462]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:44,604]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=38&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:44,604]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=38&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:44,604]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=38&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:06:45,333]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=39&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:46,066]     INFO Processing #36/74
[2022-06-01 13:06:46,238]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=40&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:46,238]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=40&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:46,934]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=40&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:46,934]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=40&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:47,300]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=40&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:47,300]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=40&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:06:47,738]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=41&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:47,739]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=41&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:48,356]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=42&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:49,524]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=42&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:49,524]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=42&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:49,524]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=42&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:06:50,465]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=43&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:50,664]     INFO Processing #40/74
[2022-06-01 13:06:51,238]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=44&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:51,239]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=44&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:54,474]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=46&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:54,474]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=46&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:55,183]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=46&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:55,184]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=46&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:55,392]     INFO Processing #44/74
[2022-06-01 13:06:55,587]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=48&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:55,588]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=48&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:55,720]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:55,721]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:56,200]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:56,200]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:56,918]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:56,918]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:56,918]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:06:57,258]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=46&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:57,258]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=46&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:58,224]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:58,310]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=46&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:58,397]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:58,523]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:58,523]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:58,591]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:06:59,776]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:06:59,777]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:06:59,777]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:07:01,009]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:01,009]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:01,703]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=51&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:04,094]     INFO Processing #48/74
[2022-06-01 13:07:04,276]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=52&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:04,276]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=52&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:05,457]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=52&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:05,457]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=52&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:05,457]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=52&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:07:06,499]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=54&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:09,611]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=55&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:09,762]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=55&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:09,762]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=55&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:10,533]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=52&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 13:07:10,884]     INFO Processing #52/74
[2022-06-01 13:07:11,096]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=56&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:11,096]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=56&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:14,242]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=58&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:14,242]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=58&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:15,421]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=58&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:15,421]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=58&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:15,421]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=58&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:07:15,616]     INFO Processing #56/74
[2022-06-01 13:07:15,680]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=60&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:16,923]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=60&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:16,923]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=60&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:07:17,159]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:17,160]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:17,305]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:17,305]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:18,211]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:18,211]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:07:18,342]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:18,342]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:18,342]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:07:18,351]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:18,352]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:07:18,610]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=63&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:18,613]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=63&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:19,139]     INFO Processing #60/74
[2022-06-01 13:07:19,200]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:19,352]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:19,353]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:19,696]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:19,832]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:19,832]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:19,859]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=63&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:19,860]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=63&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:07:19,888]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:20,596]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:20,597]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:07:20,945]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:20,946]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:07:21,075]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:21,075]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:07:21,231]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:21,361]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:21,362]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:22,093]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=67&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:22,276]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=67&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:22,410]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:22,410]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:22,410]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:07:22,414]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:22,414]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:07:22,685]     INFO Processing #64/74
[2022-06-01 13:07:22,941]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=68&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:22,945]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=68&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:23,273]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:23,477]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:23,477]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:23,477]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:24,134]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=68&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:24,134]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=68&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:07:24,497]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:24,498]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:24,499]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:07:24,575]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:24,575]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:07:24,772]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:24,773]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:07:25,033]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=70&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:25,073]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=71&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:25,205]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=71&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:25,205]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=71&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:25,274]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=71&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:26,058]     INFO Processing #68/74
[2022-06-01 13:07:26,126]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=71&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:26,126]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=71&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:07:26,146]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:26,315]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:26,316]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:26,364]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=71&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:26,364]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=71&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:07:27,624]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:27,747]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:27,747]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:28,221]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:28,815]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:28,815]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:28,815]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:07:29,279]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:29,279]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:07:29,294]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:29,454]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:29,464]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:30,161]     INFO Processing #72/74
[2022-06-01 13:07:30,475]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:30,476]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:30,476]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:07:30,504]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:30,504]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:07:33,781]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:07:33,886]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:35,125]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:35,125]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:35,125]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:07:36,200]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:36,200]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:36,294]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:36,294]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:37,476]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:37,476]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:37,476]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:07:38,395]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:39,082]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:39,082]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:40,390]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:40,390]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:40,390]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:07:41,907]     INFO Processing #4/74
[2022-06-01 13:07:42,377]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:42,377]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:42,559]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:42,560]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:42,709]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:42,710]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:44,625]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:44,625]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:44,993]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:44,993]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:45,884]     INFO Processing #8/74
[2022-06-01 13:07:46,104]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:46,105]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:46,421]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:46,421]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:46,505]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:46,505]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:46,505]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:07:47,269]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:47,818]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:07:47,818]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:07:47,912]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:48,512]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:48,512]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:07:48,973]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:07:48,973]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:07:49,353]     INFO Processing #12/74
[2022-06-01 13:13:33,798]     ERROR No further results available - stopping execution
[2022-06-01 13:13:33,799]     DEBUG See traceback
NoneType: None
[2022-06-01 13:13:34,227]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:13:34,227]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:13:40,780]     ERROR No further results available - stopping execution
[2022-06-01 13:13:40,781]     DEBUG See traceback
NoneType: None
[2022-06-01 13:13:40,951]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:13:40,951]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:13:45,179]     INFO Processing #2/19
[2022-06-01 13:13:45,363]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:13:45,363]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:13:48,871]     DEBUG  raised and ignored while processing item
[2022-06-01 13:13:49,070]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:13:49,070]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:13:50,067]     INFO Processing #4/19
[2022-06-01 13:14:34,091]     ERROR No further results available - stopping execution
[2022-06-01 13:14:34,092]     DEBUG See traceback
NoneType: None
[2022-06-01 13:14:34,284]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:14:34,285]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:14:38,702]     ERROR No further results available - stopping execution
[2022-06-01 13:14:38,703]     DEBUG See traceback
NoneType: None
[2022-06-01 13:14:38,911]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:14:38,911]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:14:43,353]     INFO Processing #2/19
[2022-06-01 13:14:43,568]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:14:43,568]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:14:48,392]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22professor+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:14:51,521]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:14:51,521]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:14:54,602]     INFO Processing #4/19
[2022-06-01 13:14:57,464]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:14:57,464]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:15:01,522]     INFO Processing #6/19
[2022-06-01 13:15:01,850]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:15:01,850]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:15:11,563]     DEBUG  raised and ignored while processing item
[2022-06-01 13:15:13,077]     INFO Processing #8/19
[2022-06-01 13:15:44,791]     ERROR No further results available - stopping execution
[2022-06-01 13:15:44,792]     DEBUG See traceback
NoneType: None
[2022-06-01 13:15:44,975]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:15:44,976]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:15:53,066]     ERROR No further results available - stopping execution
[2022-06-01 13:15:53,067]     DEBUG See traceback
NoneType: None
[2022-06-01 13:15:53,275]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:15:53,276]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:15:53,277]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:15:53,277]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:15:55,982]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:15:55,982]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:15:59,040]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:15:59,040]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:16:00,141]     INFO Processing #4/19
[2022-06-01 13:16:02,125]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:16:02,126]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:16:03,296]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:16:03,296]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:16:03,297]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:16:59,782]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:16:59,782]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:17:02,694]     ERROR No further results available - stopping execution
[2022-06-01 13:17:02,695]     DEBUG See traceback
NoneType: None
[2022-06-01 13:17:02,920]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:17:02,920]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:17:08,384]     ERROR No further results available - stopping execution
[2022-06-01 13:17:08,385]     DEBUG See traceback
NoneType: None
[2022-06-01 13:17:08,563]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:17:08,564]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:17:12,057]     DEBUG  raised and ignored while processing item
[2022-06-01 13:17:12,229]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:17:12,229]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:17:13,806]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:17:13,806]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:17:13,806]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:17:14,114]     INFO Processing #2/19
[2022-06-01 13:18:31,431]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:18:31,431]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:18:37,563]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:18:37,581]     ERROR No further results available - stopping execution
[2022-06-01 13:18:37,582]     DEBUG See traceback
NoneType: None
[2022-06-01 13:18:37,991]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:18:37,991]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:18:39,828]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:18:39,828]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:18:47,575]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:19:04,659]     ERROR No further results available - stopping execution
[2022-06-01 13:19:04,660]     DEBUG See traceback
NoneType: None
[2022-06-01 13:19:04,844]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:19:04,844]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:20:07,757]     ERROR No further results available - stopping execution
[2022-06-01 13:20:07,757]     DEBUG See traceback
NoneType: None
[2022-06-01 13:20:46,814]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:20:52,943]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:20:52,962]     ERROR No further results available - stopping execution
[2022-06-01 13:20:52,962]     DEBUG See traceback
NoneType: None
[2022-06-01 13:20:53,313]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:20:53,313]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:22:28,066]     ERROR No further results available - stopping execution
[2022-06-01 13:22:28,067]     DEBUG See traceback
NoneType: None
[2022-06-01 13:22:32,999]     DEBUG Rotating host ()
[2022-06-01 13:25:11,127]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 13:25:17,310]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:25:17,330]     ERROR No further results available - stopping execution
[2022-06-01 13:25:17,330]     DEBUG See traceback
NoneType: None
[2022-06-01 13:25:17,747]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:25:17,747]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:25:28,922]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:25:30,127]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:25:30,127]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:25:30,144]     ERROR No further results available - stopping execution
[2022-06-01 13:25:30,144]     DEBUG See traceback
NoneType: None
[2022-06-01 13:30:21,230]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:30:21,230]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:30:24,056]     ERROR No further results available - stopping execution
[2022-06-01 13:30:24,056]     DEBUG See traceback
NoneType: None
[2022-06-01 13:30:24,249]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:30:24,249]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:30:29,921]     ERROR No further results available - stopping execution
[2022-06-01 13:30:29,922]     DEBUG See traceback
NoneType: None
[2022-06-01 13:30:30,112]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:30:30,112]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:30:46,025]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:30:46,025]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:30:48,881]     ERROR No further results available - stopping execution
[2022-06-01 13:30:48,881]     DEBUG See traceback
NoneType: None
[2022-06-01 13:30:49,103]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:30:49,103]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:30:49,303]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:30:49,303]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:31:15,958]     ERROR No further results available - stopping execution
[2022-06-01 13:31:15,959]     DEBUG See traceback
NoneType: None
[2022-06-01 13:31:16,220]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:31:16,220]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:31:21,099]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:31:34,089]     ERROR No further results available - stopping execution
[2022-06-01 13:31:34,090]     DEBUG See traceback
NoneType: None
[2022-06-01 13:31:34,505]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:31:34,505]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:31:36,333]     DEBUG Rotating host ('Requester' object has no attribute '_solve_captcha')
[2022-06-01 13:31:40,907]     ERROR No further results available - stopping execution
[2022-06-01 13:31:40,908]     DEBUG See traceback
NoneType: None
[2022-06-01 13:31:41,110]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:31:41,110]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:31:45,178]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:31:45,179]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:31:45,467]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:31:45,468]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:31:46,293]     INFO Processing #4/19
[2022-06-01 13:31:46,336]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:31:46,336]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:31:46,336]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:31:48,281]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:31:48,281]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:31:49,601]     INFO Processing #8/19
[2022-06-01 13:31:49,636]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:31:49,636]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:31:51,032]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:31:51,032]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:31:51,602]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:31:51,602]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:31:53,004]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22professor+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:31:53,535]     INFO Processing #12/19
[2022-06-01 13:31:53,873]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:31:53,874]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:31:55,036]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:31:55,036]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:31:55,036]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:31:57,482]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:31:57,482]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:31:57,710]     INFO Processing #16/19
[2022-06-01 13:32:00,414]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:00,414]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:03,650]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:03,650]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:04,823]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:04,823]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:04,823]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:32:05,625]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:05,939]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:05,939]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:06,677]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:06,678]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:08,896]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 13:32:11,097]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:11,097]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:12,143]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:12,143]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:12,479]     INFO Processing #4/74
[2022-06-01 13:32:12,669]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:12,784]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:12,784]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:14,182]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:14,182]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:14,183]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:32:14,646]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:14,820]     INFO Processing #8/74
[2022-06-01 13:32:15,042]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:15,079]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:15,225]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:15,225]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:15,893]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:15,893]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:16,097]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:16,097]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:16,272]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:16,272]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:16,392]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:16,393]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:16,393]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:32:16,964]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:17,006]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:17,009]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:17,030]     INFO Processing #12/74
[2022-06-01 13:32:17,120]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:17,122]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:17,122]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:17,285]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:18,020]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:18,021]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:18,061]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:18,062]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:18,195]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:18,195]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:18,328]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:18,328]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:18,328]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:32:18,388]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:18,404]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:18,502]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:18,502]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:18,531]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:18,531]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:18,895]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:19,075]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:19,455]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:19,455]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:19,796]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:19,796]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:19,796]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:32:19,905]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:19,907]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:19,908]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:32:19,983]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:19,998]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:20,043]     INFO Processing #16/74
[2022-06-01 13:32:20,097]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:20,144]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:20,145]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:20,146]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:20,146]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:20,164]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:20,300]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:21,024]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:21,024]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:21,105]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:21,106]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:21,158]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:21,158]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:21,241]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:21,241]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:21,353]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:21,353]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:21,411]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:21,411]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:21,580]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:21,580]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:21,617]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:21,623]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:21,669]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:21,802]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:22,495]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:22,495]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:22,495]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:32:22,643]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:22,643]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:22,709]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:22,709]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:22,864]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:22,864]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:22,864]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:22,865]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:22,865]     INFO Processing #20/74
[2022-06-01 13:32:22,916]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:22,916]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:22,921]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:23,046]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:23,046]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:23,126]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:23,143]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:23,319]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:24,125]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:24,126]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:24,310]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:24,310]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:24,312]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:24,313]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:24,313]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:32:24,488]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:24,489]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:24,562]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:24,566]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:24,849]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:24,849]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:25,714]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:25,714]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:25,821]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:25,821]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:26,067]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:32:26,099]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:26,099]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:26,157]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:26,170]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:26,268]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:26,268]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:27,317]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:27,334]     INFO Processing #24/74
[2022-06-01 13:32:27,385]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:27,595]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:27,734]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:27,734]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:28,449]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:28,449]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:28,840]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:28,840]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:29,494]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:32:29,580]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:29,775]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:29,910]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:29,911]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:30,742]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:30,742]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:30,742]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:32:31,158]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 13:32:31,158]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))) raised and ignored while processing item
[2022-06-01 13:32:32,299]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:32:35,069]     INFO Processing #28/74
[2022-06-01 13:32:35,245]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:35,245]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:35,375]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:32:37,453]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:32:39,962]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:39,962]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:41,142]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:41,142]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:41,142]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:32:41,503]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:32:41,812]     INFO Processing #32/74
[2022-06-01 13:32:42,004]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:42,004]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:46,074]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:32:46,951]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:32:48,163]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:48,164]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:48,571]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:32:49,280]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=39&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:49,280]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=39&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:50,134]     INFO Processing #36/74
[2022-06-01 13:32:53,521]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=41&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:53,521]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=41&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:54,231]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=39&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:32:55,277]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=40&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:32:57,551]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=42&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:57,551]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=42&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:57,753]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=42&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:57,753]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=42&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:58,720]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=42&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:32:58,721]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=42&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:32:58,721]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=42&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:33:00,363]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=39&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:00,377]     INFO Processing #40/74
[2022-06-01 13:33:02,591]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=43&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:03,789]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=42&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:03,988]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=45&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:33:03,988]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=45&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:33:05,382]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=45&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:33:05,382]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=45&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:33:05,382]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=45&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:33:05,523]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=44&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:08,391]     INFO Processing #44/74
[2022-06-01 13:33:08,814]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=48&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:33:08,814]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=48&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:33:10,003]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=46&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:12,753]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:33:12,754]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:33:12,823]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:13,435]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=48&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:17,722]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:20,875]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:21,878]     INFO Processing #48/74
[2022-06-01 13:33:22,064]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=52&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:33:22,064]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=52&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:33:23,704]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=53&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:33:23,704]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=53&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:33:23,851]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:25,442]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=55&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:33:25,443]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=55&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:33:26,208]     INFO Processing #52/74
[2022-06-01 13:33:28,394]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=53&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:29,364]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=57&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:33:29,364]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=57&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:33:29,931]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=53&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:29,931]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=53&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))) raised and ignored while processing item
[2022-06-01 13:33:31,355]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=56&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:32,055]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=58&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:33:32,055]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=58&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:33:34,941]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:33:34,941]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:33:35,495]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=57&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:35,519]     INFO Processing #56/74
[2022-06-01 13:33:37,767]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=56&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 13:33:37,971]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:33:37,971]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:33:39,875]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:41,071]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:41,072]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))) raised and ignored while processing item
[2022-06-01 13:33:41,075]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:33:41,075]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:33:42,372]     INFO Processing #60/74
[2022-06-01 13:33:42,578]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:33:42,578]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:33:45,807]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=62&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:47,503]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:49,265]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:33:49,265]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:33:52,931]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Read timed out.)
[2022-06-01 13:33:54,159]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:55,279]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=67&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:33:55,279]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=67&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:33:55,397]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:33:55,398]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))) raised and ignored while processing item
[2022-06-01 13:33:55,979]     INFO Processing #64/74
[2022-06-01 13:33:56,176]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=68&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:33:56,176]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=68&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:33:57,814]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=70&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:33:57,814]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=70&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:34:01,123]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=68&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:34:01,747]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:34:01,831]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=71&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:34:01,831]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=71&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:34:06,767]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=71&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:34:06,809]     INFO Processing #68/74
[2022-06-01 13:34:07,041]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:34:07,041]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:34:08,159]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 13:34:11,958]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:34:13,142]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:34:13,142]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:34:13,323]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:34:13,824]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:34:13,824]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:34:16,712]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:34:16,712]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:34:19,255]     INFO Processing #72/74
[2022-06-01 13:34:19,455]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:34:21,188]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Read timed out. (read timeout=5))
[2022-06-01 13:34:21,417]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:34:21,417]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:34:26,335]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:34:29,965]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:34:29,965]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:34:31,134]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:34:31,135]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:34:31,135]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:34:32,017]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:34:32,017]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:34:34,759]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:34:34,771]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:34:34,865]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:34:34,866]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:36:09,616]     ERROR No further results available - stopping execution
[2022-06-01 13:36:09,617]     DEBUG See traceback
NoneType: None
[2022-06-01 13:36:13,855]     ERROR No further results available - stopping execution
[2022-06-01 13:36:13,856]     DEBUG See traceback
NoneType: None
[2022-06-01 13:36:44,674]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22professor+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:36:46,715]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:36:46,716]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:36:50,689]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:36:50,689]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:36:50,690]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:36:59,468]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22professor+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:37:01,427]     INFO Processing #4/5
[2022-06-01 13:37:01,597]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:37:01,597]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:48:16,718]     ERROR No further results available - stopping execution
[2022-06-01 13:48:16,719]     DEBUG See traceback
NoneType: None
[2022-06-01 13:48:31,131]     ERROR No further results available - stopping execution
[2022-06-01 13:48:31,133]     DEBUG See traceback
NoneType: None
[2022-06-01 13:48:40,103]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:48:40,103]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:48:52,153]     INFO Processing #4/19
[2022-06-01 13:49:54,256]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:49:54,256]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:50:12,127]     ERROR No further results available - stopping execution
[2022-06-01 13:50:12,129]     DEBUG See traceback
NoneType: None
[2022-06-01 13:50:27,275]     ERROR No further results available - stopping execution
[2022-06-01 13:50:27,276]     DEBUG See traceback
NoneType: None
[2022-06-01 13:51:32,899]     DEBUG  raised and ignored while processing item
[2022-06-01 13:51:33,222]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:51:33,222]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:54:51,777]     ERROR No further results available - stopping execution
[2022-06-01 13:54:51,778]     DEBUG See traceback
NoneType: None
[2022-06-01 13:55:02,784]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 13:55:18,638]     ERROR No further results available - stopping execution
[2022-06-01 13:55:18,639]     DEBUG See traceback
NoneType: None
[2022-06-01 13:55:25,963]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:55:25,965]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:56:44,740]     ERROR No further results available - stopping execution
[2022-06-01 13:56:44,743]     DEBUG See traceback
NoneType: None
[2022-06-01 13:57:17,093]     ERROR No further results available - stopping execution
[2022-06-01 13:57:17,096]     DEBUG See traceback
NoneType: None
[2022-06-01 13:57:29,440]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:57:29,441]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:57:32,495]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:57:32,496]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:57:32,497]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 13:57:37,913]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 13:58:50,210]     DEBUG  raised and ignored while processing item
[2022-06-01 13:59:42,366]     DEBUG Rotating host ()
[2022-06-01 13:59:59,261]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:59:59,261]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 13:59:59,284]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 13:59:59,284]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:00:02,750]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:00:02,750]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:00:02,896]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:00:02,896]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:00:04,142]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:00:04,143]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:00:04,143]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:00:04,708]     INFO Processing #4/10
[2022-06-01 14:00:04,981]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:00:04,982]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:00:08,261]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:00:08,261]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:00:08,867]     INFO Processing #8/10
[2022-06-01 14:00:35,086]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:00:35,086]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:00:35,313]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:00:35,313]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:00:40,034]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:00:40,061]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:00:41,348]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:00:41,348]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:00:41,899]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:00:44,566]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:00:44,567]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:00:46,087]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:00:46,118]     INFO Processing #4/10
[2022-06-01 14:00:46,292]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:00:46,292]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:00:46,519]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:02:18,390]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:03:31,937]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:07:54,268]     INFO Processing #4/10
[2022-06-01 14:07:54,467]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:07:54,468]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:08:03,207]     INFO Processing #8/10
[2022-06-01 14:08:05,031]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:08:05,032]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:08:31,469]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:08:31,469]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:08:31,473]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:08:31,473]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:08:34,131]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:08:34,131]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:08:34,625]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:08:34,625]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:08:35,793]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:08:35,793]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:08:35,794]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:08:35,894]     INFO Processing #4/10
[2022-06-01 14:08:36,300]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:08:36,300]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:08:36,802]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:08:36,802]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:08:39,589]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:08:39,589]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:08:39,882]     INFO Processing #8/10
[2022-06-01 14:09:12,845]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:09:12,845]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:09:12,995]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:09:12,995]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:09:16,486]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:09:16,486]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:09:16,909]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:09:16,909]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:09:34,948]     INFO Processing #4/10
[2022-06-01 14:09:35,130]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:09:35,130]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:09:37,176]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:09:37,176]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:09:38,262]     INFO Processing #8/10
[2022-06-01 14:10:37,939]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:10:37,939]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:10:39,641]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:10:39,642]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:10:39,874]     INFO Processing #4/10
[2022-06-01 14:10:42,294]     INFO Processing #8/10
[2022-06-01 14:11:08,328]     INFO Processing #4/10
[2022-06-01 14:11:52,566]     INFO Processing #4/10
[2022-06-01 14:11:56,558]     INFO Processing #8/10
[2022-06-01 14:12:45,447]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:12:48,597]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))))
[2022-06-01 14:12:53,674]     INFO Processing #4/10
[2022-06-01 14:12:58,039]     INFO Processing #8/10
[2022-06-01 14:13:55,222]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:13:58,032]     ERROR No further results available - stopping execution
[2022-06-01 14:13:58,033]     DEBUG See traceback
NoneType: None
[2022-06-01 14:15:24,616]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:15:24,617]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:15:27,370]     ERROR No further results available - stopping execution
[2022-06-01 14:15:27,371]     DEBUG See traceback
NoneType: None
[2022-06-01 14:15:30,952]     ERROR No further results available - stopping execution
[2022-06-01 14:15:30,953]     DEBUG See traceback
NoneType: None
[2022-06-01 14:15:35,997]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:15:39,594]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:15:39,594]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:15:43,518]     INFO Processing #4/10
[2022-06-01 14:15:49,846]     INFO Processing #8/10
[2022-06-01 14:15:59,058]     INFO Processing #4/10
[2022-06-01 14:16:01,555]     INFO Processing #8/10
[2022-06-01 14:16:17,046]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:16:17,046]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:17:36,042]     ERROR No further results available - stopping execution
[2022-06-01 14:17:36,042]     DEBUG See traceback
NoneType: None
[2022-06-01 14:17:41,179]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:17:49,107]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:17:54,446]     ERROR No further results available - stopping execution
[2022-06-01 14:17:54,447]     DEBUG See traceback
NoneType: None
[2022-06-01 14:17:59,591]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:18:07,295]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:18:07,315]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:18:14,449]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Read timed out. (read timeout=5))
[2022-06-01 14:18:14,953]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:18:17,787]     INFO Processing #4/74
[2022-06-01 14:18:19,354]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:18:45,997]     ERROR No further results available - stopping execution
[2022-06-01 14:18:45,998]     DEBUG See traceback
NoneType: None
[2022-06-01 14:18:51,140]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:18:58,989]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:19:05,019]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:19:05,038]     ERROR No further results available - stopping execution
[2022-06-01 14:19:05,038]     DEBUG See traceback
NoneType: None
[2022-06-01 14:19:10,172]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:19:18,187]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:19:18,188]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:19:21,684]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:19:22,891]     INFO Processing #4/74
[2022-06-01 14:19:24,327]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:19:24,848]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:19:24,848]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:19:28,036]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:19:30,011]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:19:31,207]     INFO Processing #8/74
[2022-06-01 14:19:34,170]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:19:37,678]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:19:38,622]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:19:38,622]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:19:39,354]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:19:40,431]     INFO Processing #12/74
[2022-06-01 14:19:44,751]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:19:47,287]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:19:49,923]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:19:50,155]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 14:19:53,262]     INFO Processing #16/74
[2022-06-01 14:19:56,074]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:19:58,766]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:19:59,954]     INFO Processing #20/74
[2022-06-01 14:20:00,663]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:05,095]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:07,071]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:10,541]     INFO Processing #24/74
[2022-06-01 14:20:12,787]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:15,683]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:17,837]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:18,144]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 14:20:20,428]     INFO Processing #28/74
[2022-06-01 14:20:21,815]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:24,875]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:25,468]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:25,887]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 14:20:26,433]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:20:26,433]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:20:26,979]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:30,309]     INFO Processing #32/74
[2022-06-01 14:20:31,603]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:35,257]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=35&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:35,747]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 14:20:37,739]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:40,606]     INFO Processing #36/74
[2022-06-01 14:20:42,808]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:43,334]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=39&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:48,939]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:50,120]     INFO Processing #40/74
[2022-06-01 14:20:50,931]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=42&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:51,029]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=42&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:54,319]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=43&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:57,159]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=42&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:20:57,177]     INFO Processing #44/74
[2022-06-01 14:20:57,770]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=48&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:20:57,770]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=48&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:21:00,490]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 14:21:02,016]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=46&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:02,237]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:05,571]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:08,371]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:09,691]     INFO Processing #48/74
[2022-06-01 14:21:13,523]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=51&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:14,836]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=52&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:17,920]     INFO Processing #52/74
[2022-06-01 14:21:19,707]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=54&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:21,737]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=55&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:22,963]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=56&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:25,869]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=54&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:29,423]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=57&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:29,598]     INFO Processing #56/74
[2022-06-01 14:21:33,120]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:35,559]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=57&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:40,611]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=62&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:40,715]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=63&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:40,954]     INFO Processing #60/74
[2022-06-01 14:21:45,731]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:21:45,732]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:21:46,843]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=63&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:49,510]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:51,972]     INFO Processing #64/74
[2022-06-01 14:21:52,007]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=67&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:21:57,531]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:00,516]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=70&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:01,290]     INFO Processing #68/74
[2022-06-01 14:22:03,667]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:08,119]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:08,615]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:08,760]     INFO Processing #72/74
[2022-06-01 14:22:14,747]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:22,493]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:22,493]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:24,883]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:27,739]     INFO Processing #4/74
[2022-06-01 14:22:28,635]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:28,978]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 14:22:32,875]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:33,804]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:36,407]     INFO Processing #8/74
[2022-06-01 14:22:36,796]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:41,563]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:44,170]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:44,893]     INFO Processing #12/74
[2022-06-01 14:22:47,435]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:22:47,435]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:22:47,691]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:50,047]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:52,599]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:52,671]     INFO Processing #16/74
[2022-06-01 14:22:55,387]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:22:57,815]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:01,476]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 14:23:01,517]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:01,537]     INFO Processing #20/74
[2022-06-01 14:23:06,575]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:06,687]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:06,984]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 14:23:08,623]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 14:23:12,703]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:12,717]     INFO Processing #24/74
[2022-06-01 14:23:17,259]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:17,856]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:22,614]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:24,991]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:25,079]     INFO Processing #28/74
[2022-06-01 14:23:25,525]     DEBUG Rotating host ('Requester' object has no attribute '_solve_captcha')
[2022-06-01 14:23:30,220]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:33,271]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:34,076]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:36,844]     INFO Processing #32/74
[2022-06-01 14:23:38,250]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=35&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 14:23:39,405]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:44,382]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=35&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:44,405]     INFO Processing #36/74
[2022-06-01 14:23:45,503]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=38&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:49,543]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=40&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:52,639]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=41&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:54,854]     INFO Processing #40/74
[2022-06-01 14:23:54,914]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=44&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 14:23:55,677]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=40&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:23:55,756]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=46&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 14:23:59,995]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=44&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:00,631]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=45&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:01,891]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=46&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:02,662]     INFO Processing #44/74
[2022-06-01 14:24:07,058]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:08,079]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=48&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 14:24:08,483]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:12,012]     INFO Processing #48/74
[2022-06-01 14:24:14,568]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:24:14,568]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:24:15,966]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:24:15,966]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:24:15,966]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:24:16,161]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:16,322]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=51&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:19,335]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=53&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:19,837]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=54&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:24:19,838]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=54&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:24:21,837]     INFO Processing #52/74
[2022-06-01 14:24:24,175]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=54&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:24,405]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=55&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:26,982]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=56&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:32,669]     INFO Processing #56/74
[2022-06-01 14:24:34,274]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=57&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:37,164]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:37,815]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=60&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:38,090]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=60&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 14:24:39,655]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=60&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:24:39,655]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=60&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:24:39,655]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=60&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:24:42,861]     INFO Processing #60/74
[2022-06-01 14:24:43,300]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:45,727]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=62&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:46,025]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 14:24:48,007]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:51,087]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:51,174]     INFO Processing #64/74
[2022-06-01 14:24:54,136]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:56,301]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=70&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 14:24:56,319]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=68&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:24:59,299]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:25:01,200]     INFO Processing #68/74
[2022-06-01 14:25:02,447]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=68&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:25:03,753]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:25:03,753]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:25:06,339]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:25:07,863]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:25:11,023]     INFO Processing #72/74
[2022-06-01 14:25:12,471]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:25:24,495]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:25:38,055]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22history%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:25:38,087]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22history%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:25:42,466]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22history%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:25:46,104]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22history%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:25:47,418]     INFO Processing #4/74
[2022-06-01 14:25:52,239]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22history%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:25:55,373]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22history%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:25:55,442]     INFO Processing #8/74
[2022-06-01 14:25:57,602]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22history%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:27:23,984]     ERROR No further results available - stopping execution
[2022-06-01 14:27:23,985]     DEBUG See traceback
NoneType: None
[2022-06-01 14:27:26,076]     ERROR No further results available - stopping execution
[2022-06-01 14:27:26,076]     DEBUG See traceback
NoneType: None
[2022-06-01 14:27:29,814]     INFO Processing #4/74
[2022-06-01 14:27:32,093]     INFO Processing #8/74
[2022-06-01 14:27:33,607]     INFO Processing #12/74
[2022-06-01 14:27:36,039]     INFO Processing #16/74
[2022-06-01 14:27:37,878]     INFO Processing #20/74
[2022-06-01 14:27:57,846]     ERROR No further results available - stopping execution
[2022-06-01 14:27:57,846]     DEBUG See traceback
NoneType: None
[2022-06-01 14:28:00,253]     ERROR No further results available - stopping execution
[2022-06-01 14:28:00,253]     DEBUG See traceback
NoneType: None
[2022-06-01 14:28:03,650]     INFO Processing #4/74
[2022-06-01 14:28:04,917]     INFO Processing #8/74
[2022-06-01 14:28:06,151]     INFO Processing #12/74
[2022-06-01 14:28:08,106]     INFO Processing #16/74
[2022-06-01 14:28:09,399]     INFO Processing #20/74
[2022-06-01 14:28:10,795]     INFO Processing #24/74
[2022-06-01 14:28:12,748]     INFO Processing #28/74
[2022-06-01 14:28:14,412]     INFO Processing #32/74
[2022-06-01 14:28:15,668]     INFO Processing #36/74
[2022-06-01 14:28:17,758]     INFO Processing #40/74
[2022-06-01 14:28:19,294]     INFO Processing #44/74
[2022-06-01 14:28:20,962]     INFO Processing #48/74
[2022-06-01 14:28:22,639]     INFO Processing #52/74
[2022-06-01 14:28:24,509]     INFO Processing #56/74
[2022-06-01 14:28:25,740]     INFO Processing #60/74
[2022-06-01 14:28:27,246]     INFO Processing #64/74
[2022-06-01 14:28:29,342]     INFO Processing #68/74
[2022-06-01 14:28:30,633]     INFO Processing #72/74
[2022-06-01 14:28:36,253]     INFO Processing #4/74
[2022-06-01 14:28:37,636]     INFO Processing #8/74
[2022-06-01 14:28:39,516]     INFO Processing #12/74
[2022-06-01 14:28:42,138]     INFO Processing #16/74
[2022-06-01 14:28:43,439]     INFO Processing #20/74
[2022-06-01 14:28:45,440]     INFO Processing #24/74
[2022-06-01 14:28:47,108]     INFO Processing #28/74
[2022-06-01 14:28:49,152]     INFO Processing #32/74
[2022-06-01 14:28:50,951]     INFO Processing #36/74
[2022-06-01 14:28:52,510]     INFO Processing #40/74
[2022-06-01 14:28:55,119]     INFO Processing #44/74
[2022-06-01 14:28:56,789]     INFO Processing #48/74
[2022-06-01 14:28:58,325]     INFO Processing #52/74
[2022-06-01 14:29:00,734]     INFO Processing #56/74
[2022-06-01 14:29:02,141]     INFO Processing #60/74
[2022-06-01 14:29:03,800]     INFO Processing #64/74
[2022-06-01 14:29:05,995]     INFO Processing #68/74
[2022-06-01 14:29:07,450]     INFO Processing #72/74
[2022-06-01 14:29:14,916]     INFO Processing #4/74
[2022-06-01 14:29:17,076]     INFO Processing #8/74
[2022-06-01 14:29:18,822]     INFO Processing #12/74
[2022-06-01 14:29:21,308]     INFO Processing #16/74
[2022-06-01 14:29:23,862]     INFO Processing #20/74
[2022-06-01 14:29:25,860]     INFO Processing #24/74
[2022-06-01 14:29:28,520]     INFO Processing #28/74
[2022-06-01 14:29:30,580]     INFO Processing #32/74
[2022-06-01 14:29:32,488]     INFO Processing #36/74
[2022-06-01 14:29:35,598]     INFO Processing #40/74
[2022-06-01 14:29:37,702]     INFO Processing #44/74
[2022-06-01 14:29:40,618]     INFO Processing #48/74
[2022-06-01 14:29:43,987]     INFO Processing #52/74
[2022-06-01 14:29:45,789]     INFO Processing #56/74
[2022-06-01 14:29:46,210]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=60&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:29:46,211]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=60&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:29:48,956]     INFO Processing #60/74
[2022-06-01 14:29:50,870]     INFO Processing #64/74
[2022-06-01 14:29:53,866]     INFO Processing #68/74
[2022-06-01 14:29:54,829]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:29:54,829]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:29:55,869]     INFO Processing #72/74
[2022-06-01 14:29:55,965]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:29:55,965]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:29:58,950]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:29:58,950]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:01,572]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:01,572]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:01,795]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:01,795]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:03,138]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:03,138]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:03,139]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:04,429]     INFO Processing #4/74
[2022-06-01 14:30:04,610]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:04,610]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:06,711]     INFO Processing #8/74
[2022-06-01 14:30:06,902]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:06,903]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:07,049]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:07,049]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:07,061]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:07,061]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:08,224]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:08,224]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:08,225]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:09,081]     INFO Processing #12/74
[2022-06-01 14:30:09,481]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:09,481]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:10,621]     INFO Processing #16/74
[2022-06-01 14:30:11,473]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:11,474]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:12,803]     INFO Processing #20/74
[2022-06-01 14:30:12,970]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:12,970]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:13,789]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:13,789]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:14,359]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:14,360]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:14,360]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:14,360]     INFO Processing #24/74
[2022-06-01 14:30:14,545]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:14,546]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:14,584]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:14,584]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:15,748]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:15,748]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:15,748]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:16,146]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:16,146]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:17,019]     INFO Processing #28/74
[2022-06-01 14:30:17,309]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:17,309]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:17,310]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:17,504]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:17,505]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:18,668]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:18,668]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:18,668]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:18,669]     INFO Processing #32/74
[2022-06-01 14:30:18,832]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:18,832]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:19,763]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:19,763]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:19,783]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=38&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:19,783]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=38&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:21,156]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:21,156]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:21,156]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:21,156]     INFO Processing #36/74
[2022-06-01 14:30:21,274]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=39&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:21,274]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=39&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:22,436]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=39&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:22,436]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=39&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:22,436]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=39&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:22,549]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=41&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:22,549]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=41&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:23,505]     INFO Processing #40/74
[2022-06-01 14:30:23,952]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=44&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:23,952]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=44&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:24,908]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=46&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:24,909]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=46&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:24,954]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:24,954]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:25,293]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=44&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:25,293]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=44&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:25,293]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=44&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:25,293]     INFO Processing #44/74
[2022-06-01 14:30:26,080]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=46&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:26,080]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=46&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:26,081]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=46&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:26,134]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:26,134]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:26,135]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:26,337]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:26,337]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:27,257]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/technology-Books/s?k=%22technology%22&rh=n%3A283155&page=49
[2022-06-01 14:30:27,257]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/technology-Books/s?k=%22technology%22&rh=n%3A283155&page=49)
[2022-06-01 14:30:27,734]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:27,734]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:27,735]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:27,735]     INFO Processing #48/74
[2022-06-01 14:30:28,110]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=52&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:28,110]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=52&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:28,425]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:28,425]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:28,426]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:28,585]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=53&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:28,585]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=53&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:28,706]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=54&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:28,706]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=54&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:29,281]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=52&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:29,281]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=52&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:29,282]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=52&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:29,449]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=55&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:29,449]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=55&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:29,868]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=54&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:29,869]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=54&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:29,869]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=54&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:29,869]     INFO Processing #52/74
[2022-06-01 14:30:30,027]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=56&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:30,028]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=56&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:31,295]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=57&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:31,295]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=57&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:31,864]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=58&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:31,864]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=58&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:32,473]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=57&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:32,473]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=57&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:32,473]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=57&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:32,769]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:32,769]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:33,161]     INFO Processing #56/74
[2022-06-01 14:30:33,184]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=58&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:33,185]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=58&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:33,185]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=58&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:33,573]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:33,573]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:34,166]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:34,167]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:34,167]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=59&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:34,555]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=62&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:34,555]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=62&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:34,575]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=63&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:34,575]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=63&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:34,743]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:34,743]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:34,744]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:34,744]     INFO Processing #60/74
[2022-06-01 14:30:34,902]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:34,903]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:35,716]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=62&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:35,716]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=62&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:35,717]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=62&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:35,880]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:35,881]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:35,889]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=63&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:35,889]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=63&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:35,890]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=63&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:36,051]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:36,051]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:36,051]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:36,213]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=67&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:36,213]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=67&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:36,275]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:36,275]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:37,200]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:37,200]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:37,201]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=65&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:37,201]     INFO Processing #64/74
[2022-06-01 14:30:37,360]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=67&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:37,360]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=67&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:37,360]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=67&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:37,361]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=68&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:37,362]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=68&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:37,445]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:37,445]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:37,445]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:37,602]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=70&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:37,602]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=70&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:37,751]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:37,751]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:38,764]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=68&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:38,765]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=68&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:38,765]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=70&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:38,765]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=68&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:38,765]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=70&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:38,766]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=70&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:38,771]     INFO Processing #68/74
[2022-06-01 14:30:38,926]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=71&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:38,927]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=71&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:38,927]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:38,927]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:38,928]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:38,955]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:38,956]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:39,087]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:39,087]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:40,124]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:40,125]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:40,127]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:40,289]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:40,289]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:40,317]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=71&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:40,317]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=71&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:40,318]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=71&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:40,706]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:40,706]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:41,145]     INFO Processing #72/74
[2022-06-01 14:30:41,618]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:41,618]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:41,618]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:30:43,523]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:43,523]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:44,691]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:44,692]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:45,085]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:45,085]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:46,249]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:46,249]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:46,565]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:46,565]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:30:47,735]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:30:47,735]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:03,726]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:03,726]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:05,036]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:05,036]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:05,420]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:05,420]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:06,590]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:06,590]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:06,977]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:06,977]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:08,294]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:08,294]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:08,743]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:08,743]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:10,177]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:10,177]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:10,588]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:10,588]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:11,977]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:11,977]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:12,368]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:12,368]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:13,534]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:13,534]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:13,693]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:13,693]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:14,928]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:14,928]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:15,318]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:15,318]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:16,710]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:16,710]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:17,017]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:17,017]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:18,200]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:18,200]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:18,593]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:18,593]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:21,236]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:21,236]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:21,268]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:21,268]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:21,269]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:21,269]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:22,711]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:22,712]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:22,713]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:22,713]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:22,714]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:22,716]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:22,804]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:22,805]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:22,805]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:23,070]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:23,071]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:23,071]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:23,072]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:23,098]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:23,098]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:24,252]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:24,253]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:24,254]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:24,255]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:24,255]     INFO Processing #4/74
[2022-06-01 14:31:24,255]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:24,257]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:24,418]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:24,419]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:24,419]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:24,419]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:24,493]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:24,493]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:24,494]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:24,649]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:24,649]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:25,583]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:25,584]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:25,584]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:25,595]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:25,595]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:25,595]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:25,595]     INFO Processing #8/74
[2022-06-01 14:31:25,742]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:25,743]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:25,805]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:25,805]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:25,806]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:25,965]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:25,966]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:25,970]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:25,970]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:26,902]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:26,902]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:26,902]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:27,057]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:27,057]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:27,137]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:27,137]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:27,138]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:27,147]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:27,147]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:27,147]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:27,148]     INFO Processing #12/74
[2022-06-01 14:31:27,482]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:27,482]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:28,224]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:28,224]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:28,224]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:28,255]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:28,255]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:28,618]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:28,618]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:28,652]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:28,652]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:28,652]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:28,811]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:28,812]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:29,414]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:29,414]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:29,414]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:29,414]     INFO Processing #16/74
[2022-06-01 14:31:29,580]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:29,580]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:29,784]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:29,784]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:29,784]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:29,939]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:29,939]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:29,968]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:29,968]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:29,969]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:30,125]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:30,125]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:30,771]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:30,771]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:30,771]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:30,953]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:30,953]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:31,098]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:31,098]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:31,098]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:31,098]     INFO Processing #20/74
[2022-06-01 14:31:31,257]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:31,257]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:31,300]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:31,300]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:31,300]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:32,130]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:32,131]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:31:32,131]     DEBUG 503 raised requesting https://www.amazon.com/s?k=%22policy%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 14:31:59,197]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:31:59,198]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:32:00,369]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:32:00,369]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:32:09,574]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:32:09,574]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:32:10,799]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:32:10,799]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:33:41,012]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:33:41,013]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:33:42,448]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:33:42,448]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:33:48,995]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:33:48,995]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:35:16,347]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:35:16,348]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:35:17,537]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:35:17,538]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:37:31,732]     ERROR No further results available - stopping execution
[2022-06-01 14:37:31,732]     DEBUG See traceback
NoneType: None
[2022-06-01 14:37:34,977]     ERROR No further results available - stopping execution
[2022-06-01 14:37:34,977]     DEBUG See traceback
NoneType: None
[2022-06-01 14:37:40,145]     INFO Processing #4/74
[2022-06-01 14:37:43,016]     INFO Processing #8/74
[2022-06-01 14:37:44,932]     INFO Processing #12/74
[2022-06-01 14:37:47,754]     INFO Processing #16/74
[2022-06-01 14:37:50,434]     INFO Processing #20/74
[2022-06-01 14:37:53,253]     INFO Processing #24/74
[2022-06-01 14:37:56,047]     INFO Processing #28/74
[2022-06-01 14:37:59,400]     INFO Processing #32/74
[2022-06-01 14:38:01,338]     INFO Processing #36/74
[2022-06-01 14:38:02,004]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=39&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:38:02,004]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=39&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:38:02,970]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=41&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:38:02,971]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=41&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:38:06,036]     INFO Processing #40/74
[2022-06-01 14:38:08,860]     INFO Processing #44/74
[2022-06-01 14:38:10,989]     INFO Processing #48/74
[2022-06-01 14:38:14,985]     INFO Processing #52/74
[2022-06-01 14:38:17,344]     INFO Processing #56/74
[2022-06-01 14:38:20,019]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=56&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:38:21,313]     INFO Processing #60/74
[2022-06-01 14:38:23,930]     INFO Processing #64/74
[2022-06-01 14:38:41,120]     ERROR No further results available - stopping execution
[2022-06-01 14:38:41,120]     DEBUG See traceback
NoneType: None
[2022-06-01 14:38:44,781]     ERROR No further results available - stopping execution
[2022-06-01 14:38:44,782]     DEBUG See traceback
NoneType: None
[2022-06-01 14:38:49,615]     INFO Processing #4/74
[2022-06-01 14:38:52,132]     INFO Processing #8/74
[2022-06-01 14:38:55,304]     INFO Processing #12/74
[2022-06-01 14:38:57,288]     INFO Processing #16/74
[2022-06-01 14:39:05,829]     ERROR No further results available - stopping execution
[2022-06-01 14:39:05,829]     DEBUG See traceback
NoneType: None
[2022-06-01 14:39:09,361]     ERROR No further results available - stopping execution
[2022-06-01 14:39:09,363]     DEBUG See traceback
NoneType: None
[2022-06-01 14:39:18,655]     INFO Processing #4/74
[2022-06-01 14:39:34,058]     INFO Processing #8/74
[2022-06-01 14:39:43,266]     INFO Processing #12/74
[2022-06-01 14:39:50,321]     INFO Processing #16/74
[2022-06-01 14:39:55,352]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:39:55,352]     DEBUG HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))) raised and ignored while processing item
[2022-06-01 14:40:01,369]     INFO Processing #20/74
[2022-06-01 14:40:09,060]     INFO Processing #24/74
[2022-06-01 14:40:55,253]     INFO No further results available - stopping execution
[2022-06-01 14:40:59,833]     INFO No further results available - stopping execution
[2022-06-01 14:41:02,372]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:41:02,372]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:41:05,622]     INFO Processing #4/74
[2022-06-01 14:41:09,242]     INFO Processing #8/74
[2022-06-01 14:41:11,552]     INFO Processing #12/74
[2022-06-01 14:41:12,988]     INFO Processing #16/74
[2022-06-01 14:41:16,247]     INFO Processing #20/74
[2022-06-01 14:41:19,143]     INFO Processing #24/74
[2022-06-01 14:41:22,101]     INFO Processing #28/74
[2022-06-01 14:41:25,399]     INFO Processing #32/74
[2022-06-01 14:41:28,567]     INFO Processing #36/74
[2022-06-01 14:41:32,012]     INFO Processing #40/74
[2022-06-01 14:41:35,185]     INFO Processing #44/74
[2022-06-01 14:41:38,052]     INFO Processing #48/74
[2022-06-01 14:41:41,227]     INFO Processing #52/74
[2022-06-01 14:41:42,724]     INFO Processing #56/74
[2022-06-01 14:41:45,558]     INFO Processing #60/74
[2022-06-01 14:41:47,898]     INFO Processing #64/74
[2022-06-01 14:41:50,004]     INFO Processing #68/74
[2022-06-01 14:41:53,149]     INFO Processing #72/74
[2022-06-01 14:41:59,082]     INFO Processing #4/74
[2022-06-01 14:42:02,568]     INFO Processing #8/74
[2022-06-01 14:42:05,588]     INFO Processing #12/74
[2022-06-01 14:42:08,669]     INFO Processing #16/74
[2022-06-01 14:42:11,299]     INFO Processing #20/74
[2022-06-01 14:42:15,019]     INFO Processing #24/74
[2022-06-01 14:42:19,984]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Read timed out. (read timeout=5))
[2022-06-01 14:42:20,197]     INFO Processing #28/74
[2022-06-01 14:42:23,900]     INFO Processing #32/74
[2022-06-01 14:42:27,506]     INFO Processing #36/74
[2022-06-01 14:43:03,364]     INFO No further results available - stopping execution
[2022-06-01 14:43:06,619]     INFO No further results available - stopping execution
[2022-06-01 14:43:12,569]     INFO Processing #4/74
[2022-06-01 14:43:16,563]     INFO Processing #8/74
[2022-06-01 14:43:18,196]     INFO Processing #12/74
[2022-06-01 14:44:07,100]     INFO No further results available - stopping execution
[2022-06-01 14:44:10,779]     INFO No further results available - stopping execution
[2022-06-01 14:44:17,833]     INFO Processing #4/67
[2022-06-01 14:44:21,104]     INFO Processing #8/67
[2022-06-01 14:44:24,650]     INFO Processing #12/67
[2022-06-01 14:44:27,379]     INFO Processing #16/67
[2022-06-01 14:44:30,350]     INFO Processing #20/67
[2022-06-01 14:44:32,964]     INFO Processing #24/67
[2022-06-01 14:59:10,856]     INFO Processing #4/74
[2022-06-01 14:59:14,557]     INFO Processing #8/74
[2022-06-01 14:59:18,922]     INFO Processing #12/74
[2022-06-01 14:59:19,191]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university+of%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 14:59:19,278]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:59:19,279]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:59:22,418]     INFO Processing #16/74
[2022-06-01 14:59:24,812]     INFO Processing #20/74
[2022-06-01 14:59:26,286]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 14:59:26,287]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 14:59:27,693]     INFO Processing #24/74
[2022-06-01 14:59:30,998]     INFO Processing #28/74
[2022-06-01 14:59:33,809]     INFO Processing #32/74
[2022-06-01 14:59:38,426]     INFO Processing #36/74
[2022-06-01 14:59:41,446]     INFO Processing #40/74
[2022-06-01 14:59:44,172]     INFO Processing #44/74
[2022-06-01 14:59:46,663]     INFO Processing #48/74
[2022-06-01 14:59:48,625]     INFO Processing #52/74
[2022-06-01 14:59:51,449]     INFO Processing #56/74
[2022-06-01 14:59:54,522]     INFO Processing #60/74
[2022-06-01 14:59:58,046]     INFO Processing #64/74
[2022-06-01 15:00:01,021]     INFO Processing #68/74
[2022-06-01 15:00:04,201]     INFO Processing #72/74
[2022-06-01 15:00:13,929]     INFO Processing #4/74
[2022-06-01 15:00:17,240]     INFO Processing #8/74
[2022-06-01 15:00:19,589]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:00:19,589]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:00:21,603]     INFO Processing #12/74
[2022-06-01 15:00:25,490]     INFO Processing #16/74
[2022-06-01 15:00:25,721]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:00:29,835]     INFO Processing #20/74
[2022-06-01 15:00:31,880]     INFO Processing #24/74
[2022-06-01 15:00:34,678]     INFO Processing #28/74
[2022-06-01 15:00:38,427]     INFO Processing #32/74
[2022-06-01 15:00:40,770]     INFO Processing #36/74
[2022-06-01 15:00:44,814]     INFO Processing #40/74
[2022-06-01 15:00:46,980]     INFO Processing #44/74
[2022-06-01 15:00:50,756]     INFO Processing #48/74
[2022-06-01 15:00:51,688]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22economic%22&i=stripbooks&s=daterank&page=46&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:00:55,105]     INFO Processing #52/74
[2022-06-01 15:00:55,607]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=55&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:00:55,607]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=55&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:00:56,053]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=56&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:00:56,053]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=56&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:00:57,427]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=56&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:00:57,427]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=56&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:00:57,512]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=55&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:00:57,512]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=55&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:01:00,933]     INFO Processing #56/74
[2022-06-01 15:01:05,078]     INFO Processing #60/74
[2022-06-01 15:01:10,851]     INFO Processing #64/74
[2022-06-01 15:01:14,236]     INFO Processing #68/74
[2022-06-01 15:01:16,472]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Read timed out. (read timeout=5))
[2022-06-01 15:01:18,573]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:01:18,573]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:01:19,245]     INFO Processing #72/74
[2022-06-01 15:01:29,301]     INFO Processing #4/74
[2022-06-01 15:01:29,955]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22history%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:01:33,977]     INFO Processing #8/74
[2022-06-01 15:01:34,168]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:01:34,168]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:01:38,823]     INFO Processing #12/74
[2022-06-01 15:01:41,370]     INFO Processing #16/74
[2022-06-01 15:01:45,277]     INFO Processing #20/74
[2022-06-01 15:01:48,537]     INFO Processing #24/74
[2022-06-01 15:01:50,991]     INFO Processing #28/74
[2022-06-01 15:01:53,715]     INFO Processing #32/74
[2022-06-01 15:01:56,281]     INFO Processing #36/74
[2022-06-01 15:01:59,592]     INFO Processing #40/74
[2022-06-01 15:02:03,034]     INFO Processing #44/74
[2022-06-01 15:02:06,001]     INFO Processing #48/74
[2022-06-01 15:02:09,862]     INFO Processing #52/74
[2022-06-01 15:02:14,282]     INFO Processing #56/74
[2022-06-01 15:02:17,422]     INFO Processing #60/74
[2022-06-01 15:02:21,367]     INFO Processing #64/74
[2022-06-01 15:02:24,155]     INFO Processing #68/74
[2022-06-01 15:02:28,199]     INFO Processing #72/74
[2022-06-01 15:02:29,904]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:02:29,904]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&page=72&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:02:42,666]     INFO Processing #4/74
[2022-06-01 15:02:44,151]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:02:47,719]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:02:48,950]     INFO Processing #8/74
[2022-06-01 15:02:53,759]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:02:57,915]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22technology%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:02:58,515]     INFO Processing #12/74
[2022-06-01 15:03:02,067]     INFO Processing #16/74
[2022-06-01 15:03:04,138]     INFO Processing #20/74
[2022-06-01 15:03:07,683]     INFO Processing #24/74
[2022-06-01 15:03:10,035]     INFO Processing #28/74
[2022-06-01 15:03:13,028]     INFO Processing #32/74
[2022-06-01 15:03:15,882]     INFO Processing #36/74
[2022-06-01 15:03:17,980]     INFO Processing #40/74
[2022-06-01 15:03:20,542]     INFO Processing #44/74
[2022-06-01 15:03:24,444]     INFO Processing #48/74
[2022-06-01 15:03:27,681]     INFO Processing #52/74
[2022-06-01 15:03:35,187]     INFO Processing #56/74
[2022-06-01 15:03:36,183]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Read timed out. (read timeout=5))
[2022-06-01 15:03:38,132]     INFO Processing #60/74
[2022-06-01 15:03:40,739]     INFO Processing #64/74
[2022-06-01 15:03:42,921]     INFO Processing #68/74
[2022-06-01 15:03:46,023]     INFO Processing #72/74
[2022-06-01 15:03:51,364]     INFO Processing #4/71
[2022-06-01 15:03:55,195]     INFO Processing #8/71
[2022-06-01 15:03:59,079]     INFO Processing #12/71
[2022-06-01 15:04:00,059]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22law%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:04:03,220]     INFO Processing #16/71
[2022-06-01 15:04:06,849]     INFO Processing #20/71
[2022-06-01 15:04:12,298]     INFO Processing #24/71
[2022-06-01 15:04:14,275]     INFO Processing #28/71
[2022-06-01 15:04:17,964]     INFO Processing #32/71
[2022-06-01 15:04:20,815]     INFO Processing #36/71
[2022-06-01 15:04:24,410]     INFO Processing #40/71
[2022-06-01 15:04:27,512]     INFO Processing #44/71
[2022-06-01 15:04:30,424]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22law%22&i=stripbooks&s=daterank&page=45&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:04:31,610]     INFO Processing #48/71
[2022-06-01 15:04:34,223]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22law%22&i=stripbooks&s=daterank&page=50&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:04:37,083]     INFO Processing #52/71
[2022-06-01 15:04:38,988]     INFO Processing #56/71
[2022-06-01 15:04:42,349]     INFO Processing #60/71
[2022-06-01 15:04:44,860]     INFO Processing #64/71
[2022-06-01 15:04:48,572]     INFO Processing #68/71
[2022-06-01 15:04:57,264]     INFO Processing #4/60
[2022-06-01 15:04:59,081]     INFO Processing #8/60
[2022-06-01 15:05:00,999]     INFO Processing #12/60
[2022-06-01 15:05:03,867]     INFO Processing #16/60
[2022-06-01 15:05:07,512]     INFO Processing #20/60
[2022-06-01 15:05:10,499]     INFO Processing #24/60
[2022-06-01 15:05:12,876]     INFO Processing #28/60
[2022-06-01 15:05:15,977]     INFO Processing #32/60
[2022-06-01 15:05:18,086]     INFO Processing #36/60
[2022-06-01 15:05:19,857]     INFO Processing #40/60
[2022-06-01 15:05:22,588]     INFO Processing #44/60
[2022-06-01 15:05:25,909]     INFO Processing #48/60
[2022-06-01 15:05:28,747]     INFO Processing #52/60
[2022-06-01 15:05:30,809]     INFO Processing #56/60
[2022-06-01 15:05:35,986]     INFO Processing #60/60
[2022-06-01 15:05:41,178]     INFO Processing #4/45
[2022-06-01 15:05:43,043]     INFO Processing #8/45
[2022-06-01 15:05:46,379]     INFO Processing #12/45
[2022-06-01 15:05:50,167]     INFO Processing #16/45
[2022-06-01 15:05:52,843]     INFO Processing #20/45
[2022-06-01 15:05:55,506]     INFO Processing #24/45
[2022-06-01 15:05:57,495]     INFO Processing #28/45
[2022-06-01 15:06:01,005]     INFO Processing #32/45
[2022-06-01 15:06:01,343]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22policy%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:06:04,932]     INFO Processing #36/45
[2022-06-01 15:06:07,889]     INFO Processing #40/45
[2022-06-01 15:06:10,325]     INFO Processing #44/45
[2022-06-01 15:06:17,276]     INFO Processing #4/62
[2022-06-01 15:06:19,218]     INFO Processing #8/62
[2022-06-01 15:06:22,578]     INFO Processing #12/62
[2022-06-01 15:06:25,364]     INFO Processing #16/62
[2022-06-01 15:06:28,452]     INFO Processing #20/62
[2022-06-01 15:06:31,200]     INFO Processing #24/62
[2022-06-01 15:06:33,196]     INFO Processing #28/62
[2022-06-01 15:06:36,601]     INFO Processing #32/62
[2022-06-01 15:06:38,231]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22architecture%22+%7C+%22design%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:06:40,485]     INFO Processing #36/62
[2022-06-01 15:06:43,483]     INFO Processing #40/62
[2022-06-01 15:06:45,364]     INFO Processing #44/62
[2022-06-01 15:06:47,601]     INFO Processing #48/62
[2022-06-01 15:06:49,732]     INFO Processing #52/62
[2022-06-01 15:06:52,505]     INFO Processing #56/62
[2022-06-01 15:06:55,790]     INFO Processing #60/62
[2022-06-01 15:06:59,555]     INFO No further results available - stopping execution
[2022-06-01 15:07:05,120]     INFO Processing #4/51
[2022-06-01 15:07:07,907]     INFO Processing #8/51
[2022-06-01 15:07:10,774]     INFO Processing #12/51
[2022-06-01 15:07:12,945]     INFO Processing #16/51
[2022-06-01 15:07:15,555]     INFO Processing #20/51
[2022-06-01 15:07:18,394]     INFO Processing #24/51
[2022-06-01 15:07:21,728]     INFO Processing #28/51
[2022-06-01 15:07:22,039]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22poetry%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:07:25,275]     INFO Processing #32/51
[2022-06-01 15:07:27,855]     INFO Processing #36/51
[2022-06-01 15:07:30,925]     INFO Processing #40/51
[2022-06-01 15:07:34,895]     INFO Processing #44/51
[2022-06-01 15:07:37,973]     INFO Processing #48/51
[2022-06-01 15:07:44,911]     INFO Processing #4/59
[2022-06-01 15:07:48,244]     INFO Processing #8/59
[2022-06-01 15:07:50,112]     INFO Processing #12/59
[2022-06-01 15:07:53,224]     INFO Processing #16/59
[2022-06-01 15:07:56,842]     INFO Processing #20/59
[2022-06-01 15:07:58,646]     INFO Processing #24/59
[2022-06-01 15:08:01,834]     INFO Processing #28/59
[2022-06-01 15:08:03,895]     INFO Processing #32/59
[2022-06-01 15:08:05,766]     DEBUG Rotating host ('Requester' object has no attribute '_solve_captcha')
[2022-06-01 15:08:07,310]     INFO Processing #36/59
[2022-06-01 15:08:10,447]     INFO Processing #40/59
[2022-06-01 15:08:13,643]     INFO Processing #44/59
[2022-06-01 15:08:17,111]     INFO Processing #48/59
[2022-06-01 15:08:19,693]     INFO Processing #52/59
[2022-06-01 15:08:21,694]     INFO Processing #56/59
[2022-06-01 15:08:21,969]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22film%22+%7C+%22cinema%22+%7C+%22movie%22+%7C+%22television%22&i=stripbooks&s=daterank&page=58&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:08:21,969]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22film%22+%7C+%22cinema%22+%7C+%22movie%22+%7C+%22television%22&i=stripbooks&s=daterank&page=58&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:08:32,971]     INFO Processing #4/74
[2022-06-01 15:08:35,861]     INFO Processing #8/74
[2022-06-01 15:08:38,104]     INFO Processing #12/74
[2022-06-01 15:08:40,779]     INFO Processing #16/74
[2022-06-01 15:08:43,921]     INFO Processing #20/74
[2022-06-01 15:08:47,295]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22art%22+%7C+%22intellectual%22+%7C+%22linguistics%22+%7C+%22humanities%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:08:47,860]     INFO Processing #24/74
[2022-06-01 15:08:50,124]     INFO Processing #28/74
[2022-06-01 15:08:52,638]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22art%22+%7C+%22intellectual%22+%7C+%22linguistics%22+%7C+%22humanities%22&i=stripbooks&s=daterank&page=35&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))))
[2022-06-01 15:08:53,332]     INFO Processing #32/74
[2022-06-01 15:08:55,811]     INFO Processing #36/74
[2022-06-01 15:08:58,661]     INFO Processing #40/74
[2022-06-01 15:09:01,274]     INFO Processing #44/74
[2022-06-01 15:09:04,430]     INFO Processing #48/74
[2022-06-01 15:09:07,069]     INFO Processing #52/74
[2022-06-01 15:09:10,143]     INFO Processing #56/74
[2022-06-01 15:09:13,038]     INFO Processing #60/74
[2022-06-01 15:09:15,526]     INFO Processing #64/74
[2022-06-01 15:09:17,859]     INFO Processing #68/74
[2022-06-01 15:09:20,096]     INFO Processing #72/74
[2022-06-01 15:09:27,476]     INFO Processing #4/11
[2022-06-01 15:09:30,306]     INFO Processing #8/11
[2022-06-01 15:09:33,583]     INFO No further results available - stopping execution
[2022-06-01 15:09:42,475]     INFO Processing #4/74
[2022-06-01 15:09:44,919]     INFO Processing #8/74
[2022-06-01 15:09:49,018]     INFO Processing #12/74
[2022-06-01 15:09:52,105]     INFO Processing #16/74
[2022-06-01 15:09:52,464]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Psychology%22+%7C+%22anthropology%22+%7C+%22cognitive+sciences%22+%7C+%22cybernetics%22+%7C+%22psychoanalysis%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:09:52,464]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Psychology%22+%7C+%22anthropology%22+%7C+%22cognitive+sciences%22+%7C+%22cybernetics%22+%7C+%22psychoanalysis%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:09:55,671]     INFO Processing #20/74
[2022-06-01 15:09:57,667]     DEBUG Rotating host ('Requester' object has no attribute '_solve_captcha')
[2022-06-01 15:09:58,873]     INFO Processing #24/74
[2022-06-01 15:10:01,842]     INFO Processing #28/74
[2022-06-01 15:10:03,680]     INFO Processing #32/74
[2022-06-01 15:10:06,513]     INFO Processing #36/74
[2022-06-01 15:10:09,174]     INFO Processing #40/74
[2022-06-01 15:10:12,011]     INFO Processing #44/74
[2022-06-01 15:10:13,769]     INFO Processing #48/74
[2022-06-01 15:10:15,437]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Psychology%22+%7C+%22anthropology%22+%7C+%22cognitive+sciences%22+%7C+%22cybernetics%22+%7C+%22psychoanalysis%22&i=stripbooks&s=daterank&page=54&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:10:15,437]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Psychology%22+%7C+%22anthropology%22+%7C+%22cognitive+sciences%22+%7C+%22cybernetics%22+%7C+%22psychoanalysis%22&i=stripbooks&s=daterank&page=54&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:10:15,982]     INFO Processing #52/74
[2022-06-01 15:10:18,904]     INFO Processing #56/74
[2022-06-01 15:10:22,410]     INFO Processing #60/74
[2022-06-01 15:10:25,103]     INFO Processing #64/74
[2022-06-01 15:10:28,132]     INFO Processing #68/74
[2022-06-01 15:10:30,525]     INFO Processing #72/74
[2022-06-01 15:10:34,737]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22Psychology%22+%7C+%22anthropology%22+%7C+%22cognitive+sciences%22+%7C+%22cybernetics%22+%7C+%22psychoanalysis%22&i=stripbooks&s=daterank&page=74&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 15:10:39,710]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22citizen%22+%7C+%22civil+society%22+%7C+%22civil+rights%22+%7C+%22nationality%22+%7C+%22law+&+norms%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:10:39,710]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22citizen%22+%7C+%22civil+society%22+%7C+%22civil+rights%22+%7C+%22nationality%22+%7C+%22law+&+norms%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:10:42,340]     INFO Processing #4/74
[2022-06-01 15:10:44,369]     INFO Processing #8/74
[2022-06-01 15:10:44,613]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22citizen%22+%7C+%22civil+society%22+%7C+%22civil+rights%22+%7C+%22nationality%22+%7C+%22law+&+norms%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 15:10:48,417]     INFO Processing #12/74
[2022-06-01 15:10:50,569]     INFO Processing #16/74
[2022-06-01 15:10:53,104]     INFO Processing #20/74
[2022-06-01 15:10:55,766]     INFO Processing #24/74
[2022-06-01 15:10:57,828]     INFO Processing #28/74
[2022-06-01 15:11:00,836]     INFO Processing #32/74
[2022-06-01 15:11:02,788]     INFO Processing #36/74
[2022-06-01 15:11:05,096]     INFO Processing #40/74
[2022-06-01 15:11:06,658]     INFO Processing #44/74
[2022-06-01 15:11:09,121]     INFO Processing #48/74
[2022-06-01 15:11:11,383]     INFO Processing #52/74
[2022-06-01 15:11:13,626]     INFO Processing #56/74
[2022-06-01 15:11:15,938]     INFO Processing #60/74
[2022-06-01 15:11:19,159]     INFO Processing #64/74
[2022-06-01 15:11:21,075]     INFO Processing #68/74
[2022-06-01 15:11:24,025]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22citizen%22+%7C+%22civil+society%22+%7C+%22civil+rights%22+%7C+%22nationality%22+%7C+%22law+&+norms%22&i=stripbooks&s=daterank&page=75&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 15:11:24,454]     INFO Processing #72/74
[2022-06-01 15:11:30,805]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22citizen%22+%7C+%22civil+society%22+%7C+%22civil+rights%22+%7C+%22nationality%22+%7C+%22law+&+norms%22&i=stripbooks&s=daterank&page=70&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:11:30,805]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22citizen%22+%7C+%22civil+society%22+%7C+%22civil+rights%22+%7C+%22nationality%22+%7C+%22law+&+norms%22&i=stripbooks&s=daterank&page=70&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:11:39,580]     INFO Processing #4/8
[2022-06-01 15:11:41,856]     INFO Processing #8/8
[2022-06-01 15:11:46,890]     INFO Processing #4/74
[2022-06-01 15:11:48,665]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22development%22+%7C+%22subaltern%22+%7C+%22colonial%22+%7C+%22aid%22+%7C+%22dependency%22+%7C+%22developing%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:11:48,665]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22development%22+%7C+%22subaltern%22+%7C+%22colonial%22+%7C+%22aid%22+%7C+%22dependency%22+%7C+%22developing%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:11:50,324]     INFO Processing #8/74
[2022-06-01 15:11:52,208]     INFO Processing #12/74
[2022-06-01 15:11:54,457]     INFO Processing #16/74
[2022-06-01 15:11:57,541]     INFO Processing #20/74
[2022-06-01 15:12:00,839]     INFO Processing #24/74
[2022-06-01 15:12:03,326]     INFO Processing #28/74
[2022-06-01 15:12:05,314]     DEBUG Rotating host ('Requester' object has no attribute '_solve_captcha')
[2022-06-01 15:12:05,872]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22development%22+%7C+%22subaltern%22+%7C+%22colonial%22+%7C+%22aid%22+%7C+%22dependency%22+%7C+%22developing%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:12:07,809]     INFO Processing #32/74
[2022-06-01 15:12:09,960]     INFO Processing #36/74
[2022-06-01 15:12:11,528]     INFO Processing #40/74
[2022-06-01 15:12:14,290]     INFO Processing #44/74
[2022-06-01 15:12:16,255]     INFO Processing #48/74
[2022-06-01 15:12:18,251]     INFO Processing #52/74
[2022-06-01 15:12:20,679]     INFO Processing #56/74
[2022-06-01 15:12:23,527]     INFO Processing #60/74
[2022-06-01 15:12:25,081]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22development%22+%7C+%22subaltern%22+%7C+%22colonial%22+%7C+%22aid%22+%7C+%22dependency%22+%7C+%22developing%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 15:12:25,669]     INFO Processing #64/74
[2022-06-01 15:12:27,353]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22development%22+%7C+%22subaltern%22+%7C+%22colonial%22+%7C+%22aid%22+%7C+%22dependency%22+%7C+%22developing%22&i=stripbooks&s=daterank&page=70&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))))
[2022-06-01 15:12:28,454]     INFO Processing #68/74
[2022-06-01 15:12:31,151]     INFO Processing #72/74
[2022-06-01 15:12:38,023]     INFO Processing #4/74
[2022-06-01 15:12:40,838]     INFO Processing #8/74
[2022-06-01 15:12:42,852]     INFO Processing #12/74
[2022-06-01 15:12:46,253]     INFO Processing #16/74
[2022-06-01 15:12:46,966]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22education%22+%7C+%22university%22+%7C+%22public+school%22+%7C+%22curriculum%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:12:50,815]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22education%22+%7C+%22university%22+%7C+%22public+school%22+%7C+%22curriculum%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:12:51,042]     INFO Processing #20/74
[2022-06-01 15:12:53,962]     INFO Processing #24/74
[2022-06-01 15:12:57,478]     INFO Processing #28/74
[2022-06-01 15:12:59,560]     INFO Processing #32/74
[2022-06-01 15:13:02,514]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22education%22+%7C+%22university%22+%7C+%22public+school%22+%7C+%22curriculum%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:13:04,449]     INFO Processing #36/74
[2022-06-01 15:13:07,249]     INFO Processing #40/74
[2022-06-01 15:13:09,322]     INFO Processing #44/74
[2022-06-01 15:13:12,870]     INFO Processing #48/74
[2022-06-01 15:13:16,048]     INFO Processing #52/74
[2022-06-01 15:13:19,493]     INFO Processing #56/74
[2022-06-01 15:13:22,657]     INFO Processing #60/74
[2022-06-01 15:13:23,775]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22education%22+%7C+%22university%22+%7C+%22public+school%22+%7C+%22curriculum%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:13:23,775]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22education%22+%7C+%22university%22+%7C+%22public+school%22+%7C+%22curriculum%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:13:25,404]     INFO Processing #64/74
[2022-06-01 15:13:27,557]     INFO Processing #68/74
[2022-06-01 15:13:30,981]     INFO Processing #72/74
[2022-06-01 15:13:37,360]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22energy%22+%7C+%22environment%22+%7C+%22oil%22+%7C+%22gas%22+%7C+%22nuclear%22+%7C+%22solar+energy%22+%7C+%22wind+energy%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('_ssl.c:1114: The handshake operation timed out'))))
[2022-06-01 15:13:45,588]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Read timed out. (read timeout=5))
[2022-06-01 15:13:45,871]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22energy%22+%7C+%22environment%22+%7C+%22oil%22+%7C+%22gas%22+%7C+%22nuclear%22+%7C+%22solar+energy%22+%7C+%22wind+energy%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:13:45,871]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22energy%22+%7C+%22environment%22+%7C+%22oil%22+%7C+%22gas%22+%7C+%22nuclear%22+%7C+%22solar+energy%22+%7C+%22wind+energy%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:13:46,780]     INFO Processing #4/57
[2022-06-01 15:13:47,189]     DEBUG Rotating host ('Requester' object has no attribute '_solve_captcha')
[2022-06-01 15:13:49,906]     INFO Processing #8/57
[2022-06-01 15:13:51,650]     INFO Processing #12/57
[2022-06-01 15:13:54,039]     INFO Processing #16/57
[2022-06-01 15:13:55,746]     INFO Processing #20/57
[2022-06-01 15:13:57,644]     INFO Processing #24/57
[2022-06-01 15:14:00,234]     INFO Processing #28/57
[2022-06-01 15:14:01,999]     INFO Processing #32/57
[2022-06-01 15:14:04,383]     INFO Processing #36/57
[2022-06-01 15:14:06,991]     INFO Processing #40/57
[2022-06-01 15:14:09,792]     INFO Processing #44/57
[2022-06-01 15:14:12,602]     INFO Processing #48/57
[2022-06-01 15:14:15,730]     INFO Processing #52/57
[2022-06-01 15:14:18,177]     INFO Processing #56/57
[2022-06-01 15:14:23,113]     INFO Processing #4/54
[2022-06-01 15:14:23,968]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22justice%22+%7C+%22imperialism%22+%7C+%22nationalism%22+%7C+%22nation%22+%7C+%22empire%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:14:23,968]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22justice%22+%7C+%22imperialism%22+%7C+%22nationalism%22+%7C+%22nation%22+%7C+%22empire%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:14:25,472]     INFO Processing #8/54
[2022-06-01 15:14:28,320]     INFO Processing #12/54
[2022-06-01 15:14:29,091]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22justice%22+%7C+%22imperialism%22+%7C+%22nationalism%22+%7C+%22nation%22+%7C+%22empire%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', ConnectionResetError(104, 'Connection reset by peer'))))
[2022-06-01 15:14:31,785]     INFO Processing #16/54
[2022-06-01 15:14:34,117]     INFO Processing #20/54
[2022-06-01 15:14:36,883]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22justice%22+%7C+%22imperialism%22+%7C+%22nationalism%22+%7C+%22nation%22+%7C+%22empire%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:14:37,716]     INFO Processing #24/54
[2022-06-01 15:14:40,086]     INFO Processing #28/54
[2022-06-01 15:14:42,692]     INFO Processing #32/54
[2022-06-01 15:14:44,592]     INFO Processing #36/54
[2022-06-01 15:14:47,225]     INFO Processing #40/54
[2022-06-01 15:14:52,467]     INFO Processing #44/54
[2022-06-01 15:14:59,063]     INFO Processing #48/54
[2022-06-01 15:15:01,673]     INFO Processing #52/54
[2022-06-01 15:15:03,984]     DEBUG Rotating host ('Requester' object has no attribute '_solve_captcha')
[2022-06-01 15:15:08,292]     INFO No further results available - stopping execution
[2022-06-01 15:15:15,234]     INFO Processing #4/13
[2022-06-01 15:15:18,099]     INFO Processing #8/13
[2022-06-01 15:15:20,522]     INFO Processing #12/13
[2022-06-01 15:15:27,583]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22incaceration%22+%7C+%22prison%22+%7C+%22police%22+%7C+%22penalty%22+%7C+%22punishment%22+%7C+%22violence%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:15:27,583]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22incaceration%22+%7C+%22prison%22+%7C+%22police%22+%7C+%22penalty%22+%7C+%22punishment%22+%7C+%22violence%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:15:27,864]     INFO Processing #4/51
[2022-06-01 15:15:30,426]     INFO Processing #8/51
[2022-06-01 15:15:32,550]     INFO Processing #12/51
[2022-06-01 15:15:34,858]     INFO Processing #16/51
[2022-06-01 15:15:37,272]     INFO Processing #20/51
[2022-06-01 15:15:39,521]     INFO Processing #24/51
[2022-06-01 15:15:41,771]     INFO Processing #28/51
[2022-06-01 15:15:45,431]     INFO Processing #32/51
[2022-06-01 15:15:47,743]     INFO Processing #36/51
[2022-06-01 15:15:51,276]     INFO Processing #40/51
[2022-06-01 15:15:53,720]     INFO Processing #44/51
[2022-06-01 15:15:57,091]     INFO Processing #48/51
[2022-06-01 15:16:03,908]     INFO Processing #4/17
[2022-06-01 15:16:05,899]     INFO Processing #8/17
[2022-06-01 15:16:07,793]     INFO Processing #12/17
[2022-06-01 15:16:10,718]     INFO Processing #16/17
[2022-06-01 15:16:18,232]     INFO Processing #4/74
[2022-06-01 15:16:20,672]     INFO Processing #8/74
[2022-06-01 15:16:23,824]     INFO Processing #12/74
[2022-06-01 15:16:26,183]     INFO Processing #16/74
[2022-06-01 15:16:30,006]     INFO Processing #20/74
[2022-06-01 15:16:31,747]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22university%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:16:34,205]     INFO Processing #24/74
[2022-06-01 15:16:38,108]     INFO Processing #28/74
[2022-06-01 15:16:42,279]     INFO Processing #32/74
[2022-06-01 15:16:46,186]     INFO Processing #36/74
[2022-06-01 15:16:48,469]     INFO Processing #40/74
[2022-06-01 15:16:51,870]     INFO Processing #44/74
[2022-06-01 15:16:54,393]     INFO Processing #48/74
[2022-06-01 15:16:57,749]     INFO Processing #52/74
[2022-06-01 15:17:01,521]     INFO Processing #56/74
[2022-06-01 15:17:05,058]     INFO Processing #60/74
[2022-06-01 15:17:07,361]     INFO Processing #64/74
[2022-06-01 15:17:10,347]     INFO Processing #68/74
[2022-06-01 15:17:12,231]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 15:17:12,231]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 15:17:13,411]     INFO Processing #72/74
[2022-06-01 15:17:23,177]     INFO Processing #4/15
[2022-06-01 15:17:26,243]     INFO Processing #8/15
[2022-06-01 15:17:29,222]     INFO Processing #12/15
[2022-06-01 15:17:35,010]     INFO Processing #4/58
[2022-06-01 15:17:37,514]     INFO Processing #8/58
[2022-06-01 15:17:39,042]     INFO Processing #12/58
[2022-06-01 15:17:41,623]     INFO Processing #16/58
[2022-06-01 15:17:44,908]     INFO Processing #20/58
[2022-06-01 15:17:45,435]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22sociology%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:17:49,465]     INFO Processing #24/58
[2022-06-01 15:17:52,998]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Read timed out. (read timeout=5))
[2022-06-01 15:17:53,707]     INFO Processing #28/58
[2022-06-01 15:17:57,818]     INFO Processing #32/58
[2022-06-01 15:17:59,460]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22sociology%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:18:02,628]     INFO Processing #36/58
[2022-06-01 15:18:03,226]     DEBUG Rotating host ('Requester' object has no attribute '_solve_captcha')
[2022-06-01 15:18:05,923]     INFO Processing #40/58
[2022-06-01 15:18:08,158]     INFO Processing #44/58
[2022-06-01 15:18:11,331]     INFO Processing #48/58
[2022-06-01 15:18:13,743]     DEBUG Rotating host (HTTPSConnectionPool(host='www.amazon.com', port=443): Max retries exceeded with url: /s?k=%22sociology%22&i=stripbooks&s=daterank&page=49&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b (Caused by ProxyError('Cannot connect to proxy.', timeout('timed out'))))
[2022-06-01 15:18:15,137]     INFO Processing #52/58
[2022-06-01 15:18:18,683]     INFO Processing #56/58
[2022-06-01 15:18:27,322]     INFO Processing #4/69
[2022-06-01 15:18:29,383]     INFO Processing #8/69
[2022-06-01 15:18:32,425]     INFO Processing #12/69
[2022-06-01 15:18:35,188]     INFO Processing #16/69
[2022-06-01 15:18:38,656]     INFO Processing #20/69
[2022-06-01 15:18:40,419]     INFO Processing #24/69
[2022-06-01 15:18:43,425]     INFO Processing #28/69
[2022-06-01 15:18:45,369]     INFO Processing #32/69
[2022-06-01 15:18:48,874]     INFO Processing #36/69
[2022-06-01 15:18:52,489]     INFO Processing #40/69
[2022-06-01 16:27:48,792]     INFO 
Traceback (most recent call last):
  File "test.py", line 46, in <module>
    driver_sess = Session(sources=[WileyArticlePageRequester])
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 43, in __init__
    self.sources = [x() for x in sources]
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 43, in <listcomp>
    self.sources = [x() for x in sources]
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 198, in __init__
    self._settings.update(  # These are required to hold a session open
AttributeError: 'WileyArticlePageRequester' object has no attribute '_settings'
[2022-06-01 16:28:20,682]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised and ignored while processing item
[2022-06-01 16:28:22,035]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised and ignored while processing item
[2022-06-01 16:28:22,035]     INFO Processing #2/1526
[2022-06-01 16:28:23,217]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised and ignored while processing item
[2022-06-01 16:28:24,399]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised and ignored while processing item
[2022-06-01 16:28:24,400]     INFO Processing #4/1526
[2022-06-01 16:28:25,611]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised and ignored while processing item
[2022-06-01 16:28:26,769]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised and ignored while processing item
[2022-06-01 16:28:26,770]     INFO Processing #6/1526
[2022-06-01 16:28:27,929]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised and ignored while processing item
[2022-06-01 16:28:28,694]     INFO Processing #8/1526
[2022-06-01 16:29:09,769]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised and ignored while processing item
[2022-06-01 16:29:10,973]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised and ignored while processing item
[2022-06-01 16:29:10,974]     INFO Processing #2/1526
[2022-06-01 16:29:12,145]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised and ignored while processing item
[2022-06-01 16:29:13,363]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version. raised and ignored while processing item
[2022-06-01 16:29:13,364]     INFO Processing #4/1526
[2022-06-01 16:30:26,313]     INFO Processing #2/1526
[2022-06-01 16:30:28,693]     INFO Processing #4/1526
[2022-06-01 16:30:30,359]     INFO Processing #6/1526
[2022-06-01 16:32:26,892]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.
[2022-06-01 16:32:28,145]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.
[2022-06-01 16:32:28,146]     INFO Processing #2/1526
[2022-06-01 16:32:29,461]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.
[2022-06-01 16:32:30,637]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.
[2022-06-01 16:32:30,638]     INFO Processing #4/1526
[2022-06-01 16:32:31,809]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.
[2022-06-01 16:32:32,978]     INFO Detected a Cloudflare version 2 challenge, This feature is not available in the opensource (free) version.
[2022-06-01 16:32:32,979]     INFO Processing #6/1526
[2022-06-01 16:56:34,133]     INFO Configuring defensive HTML source session
[2022-06-01 16:56:37,598]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:56:37,604]     DEBUG See traceback
NoneType: None
[2022-06-01 16:56:37,605]     INFO _parse_response() missing 1 required positional argument: 'ad_fields' raised and ignored while processing item
[2022-06-01 16:56:37,605]     INFO Configuring defensive HTML source session
[2022-06-01 16:56:37,605]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:56:37,605]     DEBUG See traceback
NoneType: None
[2022-06-01 16:56:37,605]     INFO _parse_response() missing 1 required positional argument: 'ad_fields' raised and ignored while processing item
[2022-06-01 16:56:37,605]     INFO Processing #2/5
[2022-06-01 16:56:37,605]     INFO Configuring defensive HTML source session
[2022-06-01 16:56:37,606]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:56:37,606]     DEBUG See traceback
NoneType: None
[2022-06-01 16:56:37,606]     INFO _parse_response() missing 1 required positional argument: 'ad_fields' raised and ignored while processing item
[2022-06-01 16:56:37,606]     INFO Configuring defensive HTML source session
[2022-06-01 16:56:37,606]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:56:37,606]     DEBUG See traceback
NoneType: None
[2022-06-01 16:56:37,606]     INFO _parse_response() missing 1 required positional argument: 'ad_fields' raised and ignored while processing item
[2022-06-01 16:56:37,607]     INFO Processing #4/5
[2022-06-01 16:56:37,607]     INFO Configuring defensive HTML source session
[2022-06-01 16:56:37,607]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:56:37,607]     DEBUG See traceback
NoneType: None
[2022-06-01 16:56:37,607]     INFO _parse_response() missing 1 required positional argument: 'ad_fields' raised and ignored while processing item
[2022-06-01 16:58:02,340]     INFO Configuring defensive HTML source session
[2022-06-01 16:58:04,609]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:58:04,610]     DEBUG See traceback
NoneType: None
[2022-06-01 16:58:04,610]     INFO 'NoneType' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 16:58:04,610]     INFO Configuring defensive HTML source session
[2022-06-01 16:58:04,610]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:58:04,611]     DEBUG See traceback
NoneType: None
[2022-06-01 16:58:04,611]     INFO 'NoneType' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 16:58:04,611]     INFO Processing #2/5
[2022-06-01 16:58:04,611]     INFO Configuring defensive HTML source session
[2022-06-01 16:58:04,611]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:58:04,611]     DEBUG See traceback
NoneType: None
[2022-06-01 16:58:04,611]     INFO 'NoneType' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 16:58:04,612]     INFO Configuring defensive HTML source session
[2022-06-01 16:58:04,612]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:58:04,612]     DEBUG See traceback
NoneType: None
[2022-06-01 16:58:04,612]     INFO 'NoneType' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 16:58:04,612]     INFO Processing #4/5
[2022-06-01 16:58:04,612]     INFO Configuring defensive HTML source session
[2022-06-01 16:58:04,613]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:58:04,613]     DEBUG See traceback
NoneType: None
[2022-06-01 16:58:04,613]     INFO 'NoneType' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 16:58:33,714]     INFO Configuring defensive HTML source session
[2022-06-01 16:58:35,436]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:58:35,437]     DEBUG See traceback
NoneType: None
[2022-06-01 16:58:35,437]     INFO 'NoneType' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 16:58:35,437]     INFO Configuring defensive HTML source session
[2022-06-01 16:58:35,437]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:58:35,438]     DEBUG See traceback
NoneType: None
[2022-06-01 16:58:35,438]     INFO 'NoneType' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 16:58:35,438]     INFO Processing #2/5
[2022-06-01 16:58:35,438]     INFO Configuring defensive HTML source session
[2022-06-01 16:58:35,438]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:58:35,438]     DEBUG See traceback
NoneType: None
[2022-06-01 16:58:35,439]     INFO 'NoneType' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 16:58:35,439]     INFO Configuring defensive HTML source session
[2022-06-01 16:58:35,439]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:58:35,439]     DEBUG See traceback
NoneType: None
[2022-06-01 16:58:35,439]     INFO 'NoneType' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 16:58:35,439]     INFO Processing #4/5
[2022-06-01 16:58:35,439]     INFO Configuring defensive HTML source session
[2022-06-01 16:58:35,440]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:58:35,440]     DEBUG See traceback
NoneType: None
[2022-06-01 16:58:35,440]     INFO 'NoneType' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 16:59:11,514]     INFO Configuring defensive HTML source session
[2022-06-01 16:59:14,761]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:59:14,762]     DEBUG See traceback
NoneType: None
[2022-06-01 16:59:14,762]     INFO 'NoneType' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 16:59:14,762]     DEBUG 
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 254, in _configure_session
    return self._parse_response(resp, {})
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 91, in _parse_response
    values[field.name] = field.extract(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/field.py", line 31, in extract
    data = self._get_data(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/field.py", line 60, in _get_data
    return resp.dom
AttributeError: 'NoneType' object has no attribute 'dom'
[2022-06-01 16:59:14,763]     INFO Configuring defensive HTML source session
[2022-06-01 16:59:14,763]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:59:14,764]     DEBUG See traceback
NoneType: None
[2022-06-01 16:59:14,764]     INFO 'NoneType' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 16:59:14,764]     DEBUG 
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 254, in _configure_session
    return self._parse_response(resp, {})
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 91, in _parse_response
    values[field.name] = field.extract(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/field.py", line 31, in extract
    data = self._get_data(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/field.py", line 60, in _get_data
    return resp.dom
AttributeError: 'NoneType' object has no attribute 'dom'
[2022-06-01 16:59:14,764]     INFO Processing #2/5
[2022-06-01 16:59:14,765]     INFO Configuring defensive HTML source session
[2022-06-01 16:59:14,765]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:59:14,765]     DEBUG See traceback
NoneType: None
[2022-06-01 16:59:14,765]     INFO 'NoneType' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 16:59:14,766]     DEBUG 
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 254, in _configure_session
    return self._parse_response(resp, {})
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 91, in _parse_response
    values[field.name] = field.extract(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/field.py", line 31, in extract
    data = self._get_data(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/field.py", line 60, in _get_data
    return resp.dom
AttributeError: 'NoneType' object has no attribute 'dom'
[2022-06-01 16:59:14,766]     INFO Configuring defensive HTML source session
[2022-06-01 16:59:14,766]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:59:14,766]     DEBUG See traceback
NoneType: None
[2022-06-01 16:59:14,766]     INFO 'NoneType' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 16:59:14,767]     DEBUG 
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 254, in _configure_session
    return self._parse_response(resp, {})
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 91, in _parse_response
    values[field.name] = field.extract(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/field.py", line 31, in extract
    data = self._get_data(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/field.py", line 60, in _get_data
    return resp.dom
AttributeError: 'NoneType' object has no attribute 'dom'
[2022-06-01 16:59:14,767]     INFO Processing #4/5
[2022-06-01 16:59:14,767]     INFO Configuring defensive HTML source session
[2022-06-01 16:59:14,767]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 16:59:14,768]     DEBUG See traceback
NoneType: None
[2022-06-01 16:59:14,768]     INFO 'NoneType' object has no attribute 'dom' raised and ignored while processing item
[2022-06-01 16:59:14,768]     DEBUG 
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 254, in _configure_session
    return self._parse_response(resp, {})
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 91, in _parse_response
    values[field.name] = field.extract(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/field.py", line 31, in extract
    data = self._get_data(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/models/field.py", line 60, in _get_data
    return resp.dom
AttributeError: 'NoneType' object has no attribute 'dom'
[2022-06-01 17:01:20,149]     INFO Configuring defensive HTML source session
[2022-06-01 17:01:22,912]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 17:01:22,913]     DEBUG See traceback
NoneType: None
[2022-06-01 17:01:22,914]     INFO Configuring defensive HTML source session
[2022-06-01 17:01:22,915]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 17:01:22,916]     DEBUG See traceback
NoneType: None
[2022-06-01 17:01:22,917]     INFO Processing #2/5
[2022-06-01 17:01:22,918]     INFO Configuring defensive HTML source session
[2022-06-01 17:01:22,919]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 17:01:22,920]     DEBUG See traceback
NoneType: None
[2022-06-01 17:01:22,921]     INFO Configuring defensive HTML source session
[2022-06-01 17:01:22,923]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 17:01:22,927]     DEBUG See traceback
NoneType: None
[2022-06-01 17:01:22,930]     INFO Processing #4/5
[2022-06-01 17:01:22,933]     INFO Configuring defensive HTML source session
[2022-06-01 17:01:22,935]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 17:01:22,937]     DEBUG See traceback
NoneType: None
[2022-06-01 17:01:58,851]     INFO Configuring defensive HTML source session
[2022-06-01 17:02:42,546]     INFO Configuring defensive HTML source session
[2022-06-01 17:02:42,546]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 17:02:42,546]     DEBUG See traceback
NoneType: None
[2022-06-01 17:02:42,546]     INFO Processing #2/5
[2022-06-01 17:02:42,547]     INFO Configuring defensive HTML source session
[2022-06-01 17:02:42,547]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 17:02:42,547]     DEBUG See traceback
NoneType: None
[2022-06-01 17:02:42,547]     INFO Configuring defensive HTML source session
[2022-06-01 17:02:42,547]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 17:02:42,547]     DEBUG See traceback
NoneType: None
[2022-06-01 17:02:42,548]     INFO Processing #4/5
[2022-06-01 17:02:42,548]     INFO Configuring defensive HTML source session
[2022-06-01 17:02:42,548]     ERROR Cannot start mismatched Driver instance... CRITICAL - QUITTING
[2022-06-01 17:02:42,548]     DEBUG See traceback
NoneType: None
[2022-06-01 17:03:31,965]     INFO Configuring defensive HTML source session
[2022-06-01 17:03:43,308]     INFO Configuring defensive HTML source session
[2022-06-01 17:03:53,647]     INFO Processing #2/5
[2022-06-01 17:03:53,648]     INFO Configuring defensive HTML source session
[2022-06-01 17:03:57,441]     DEBUG Rotating host ()
[2022-06-01 17:03:58,463]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=47243): Max retries exceeded with url: /session/9664f0e271527e05bc9d039cf0e19265/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc3764ae550>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 17:03:58,541]     INFO Configuring defensive HTML source session
[2022-06-01 17:03:59,332]     INFO Processing #4/5
[2022-06-01 17:03:59,332]     INFO Configuring defensive HTML source session
[2022-06-01 17:13:13,710]     INFO Configuring defensive HTML source session
[2022-06-01 17:13:16,269]     INFO Configuring defensive HTML source session
[2022-06-01 17:13:17,678]     INFO Processing #2/5
[2022-06-01 17:13:17,679]     INFO Configuring defensive HTML source session
[2022-06-01 17:13:19,044]     INFO Configuring defensive HTML source session
[2022-06-01 17:13:19,568]     INFO Processing #4/5
[2022-06-01 17:13:19,568]     INFO Configuring defensive HTML source session
[2022-06-01 17:14:41,205]     INFO Configuring defensive HTML source session
[2022-06-01 17:14:58,811]     ERROR Driver initialisation failed - 'Chrome' object has no attribute '_host'
[2022-06-01 17:15:12,622]     INFO Configuring defensive HTML source session
[2022-06-01 17:15:13,869]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 17:15:13,869]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 236, in _configure_session
    driver = Driver.get_or_create(
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 77, in get_or_create
    _instances.append(cls(**settings))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 65, in __init__
    self._chrome = Chrome(**self._settings, host=next(self._hosts))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 54, in __init__
    self._init_driver()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 60, in _init_driver
    chrome_cls.__init__(self, **self._configure_init_kwargs())
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/undetected_chromedriver/webdriver.py", line 61, in __init__
    super().__init__(*args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 233, in __init__
    patcher.auto()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 131, in auto
    return self.patch()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 134, in patch
    self.patch_exe()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 236, in patch_exe
    for line in iter(lambda: fh.readline(), b""):
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 222, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 253, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 17:15:13,871]     INFO Processing #2/5
[2022-06-01 17:15:13,871]     INFO Configuring defensive HTML source session
[2022-06-01 17:15:14,423]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 17:15:14,423]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 236, in _configure_session
    driver = Driver.get_or_create(
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 77, in get_or_create
    _instances.append(cls(**settings))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 65, in __init__
    self._chrome = Chrome(**self._settings, host=next(self._hosts))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 54, in __init__
    self._init_driver()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 60, in _init_driver
    chrome_cls.__init__(self, **self._configure_init_kwargs())
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/undetected_chromedriver/webdriver.py", line 61, in __init__
    super().__init__(*args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 233, in __init__
    patcher.auto()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 130, in auto
    self.unzip_package(self.fetch_package())
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 166, in fetch_package
    return urlretrieve(u)[0]
  File "/usr/local/lib/python3.8/urllib/request.py", line 276, in urlretrieve
    block = fp.read(bs)
  File "/usr/local/lib/python3.8/http/client.py", line 459, in read
    n = self.readinto(b)
  File "/usr/local/lib/python3.8/http/client.py", line 503, in readinto
    n = self.fp.readinto(b)
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/local/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 222, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 253, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 17:15:14,430]     INFO Configuring defensive HTML source session
[2022-06-01 17:15:14,678]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 17:15:14,679]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 236, in _configure_session
    driver = Driver.get_or_create(
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 77, in get_or_create
    _instances.append(cls(**settings))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 65, in __init__
    self._chrome = Chrome(**self._settings, host=next(self._hosts))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 54, in __init__
    self._init_driver()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 60, in _init_driver
    chrome_cls.__init__(self, **self._configure_init_kwargs())
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/undetected_chromedriver/webdriver.py", line 61, in __init__
    super().__init__(*args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 233, in __init__
    patcher.auto()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 130, in auto
    self.unzip_package(self.fetch_package())
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 166, in fetch_package
    return urlretrieve(u)[0]
  File "/usr/local/lib/python3.8/urllib/request.py", line 247, in urlretrieve
    with contextlib.closing(urlopen(url, data)) as fp:
  File "/usr/local/lib/python3.8/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/usr/local/lib/python3.8/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/usr/local/lib/python3.8/urllib/request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "/usr/local/lib/python3.8/urllib/request.py", line 502, in _call_chain
    result = func(*args)
  File "/usr/local/lib/python3.8/urllib/request.py", line 1397, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "/usr/local/lib/python3.8/urllib/request.py", line 1358, in do_open
    r = h.getresponse()
  File "/usr/local/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
  File "/usr/local/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/usr/local/lib/python3.8/http/client.py", line 277, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/local/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 222, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 253, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 17:15:14,680]     INFO Processing #4/5
[2022-06-01 17:15:14,859]     INFO Configuring defensive HTML source session
[2022-06-01 17:15:15,023]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 17:15:15,023]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 236, in _configure_session
    driver = Driver.get_or_create(
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 77, in get_or_create
    _instances.append(cls(**settings))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 65, in __init__
    self._chrome = Chrome(**self._settings, host=next(self._hosts))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 54, in __init__
    self._init_driver()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 60, in _init_driver
    chrome_cls.__init__(self, **self._configure_init_kwargs())
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/seleniumwire/undetected_chromedriver/webdriver.py", line 61, in __init__
    super().__init__(*args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 233, in __init__
    patcher.auto()
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 130, in auto
    self.unzip_package(self.fetch_package())
  File "/home/gravy/.local/share/virtualenvs/tsutils-4-WR4Vja/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 166, in fetch_package
    return urlretrieve(u)[0]
  File "/usr/local/lib/python3.8/urllib/request.py", line 247, in urlretrieve
    with contextlib.closing(urlopen(url, data)) as fp:
  File "/usr/local/lib/python3.8/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/usr/local/lib/python3.8/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/usr/local/lib/python3.8/urllib/request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "/usr/local/lib/python3.8/urllib/request.py", line 502, in _call_chain
    result = func(*args)
  File "/usr/local/lib/python3.8/urllib/request.py", line 1397, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "/usr/local/lib/python3.8/urllib/request.py", line 1358, in do_open
    r = h.getresponse()
  File "/usr/local/lib/python3.8/http/client.py", line 1348, in getresponse
    response.begin()
  File "/usr/local/lib/python3.8/http/client.py", line 316, in begin
    version, status, reason = self._read_status()
  File "/usr/local/lib/python3.8/http/client.py", line 277, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/local/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 222, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 253, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 17:16:29,633]     INFO Configuring defensive HTML source session
[2022-06-01 17:19:58,692]     INFO Configuring defensive HTML source session
[2022-06-01 17:21:23,185]     INFO Processing #2/5
[2022-06-01 17:21:51,730]     INFO Processing #4/5
[2022-06-01 17:22:08,102]     INFO Configuring defensive HTML source session
[2022-06-01 17:22:15,953]     INFO Processing #2/5
[2022-06-01 17:22:17,099]     INFO Processing #4/5
[2022-06-01 17:26:38,235]     INFO Configuring defensive HTML source session
[2022-06-01 17:26:47,118]     INFO Processing #2/200
[2022-06-01 17:26:48,733]     INFO Processing #4/200
[2022-06-01 17:26:50,353]     INFO Processing #6/200
[2022-06-01 17:26:51,717]     INFO Processing #8/200
[2022-06-01 17:26:53,335]     INFO Processing #10/200
[2022-06-01 17:26:54,688]     INFO Processing #12/200
[2022-06-01 17:26:56,207]     INFO Processing #14/200
[2022-06-01 17:26:57,600]     INFO Processing #16/200
[2022-06-01 17:26:59,370]     INFO Processing #18/200
[2022-06-01 17:27:01,620]     INFO Processing #20/200
[2022-06-01 17:27:03,611]     INFO Processing #22/200
[2022-06-01 17:27:05,186]     INFO Processing #24/200
[2022-06-01 17:27:06,919]     INFO Processing #26/200
[2022-06-01 17:27:08,453]     INFO Processing #28/200
[2022-06-01 17:27:10,887]     INFO Processing #30/200
[2022-06-01 17:27:12,587]     INFO Processing #32/200
[2022-06-01 17:27:14,606]     INFO Processing #34/200
[2022-06-01 17:27:16,783]     INFO Processing #36/200
[2022-06-01 17:27:18,473]     INFO Processing #38/200
[2022-06-01 17:27:19,698]     INFO Processing #40/200
[2022-06-01 17:27:21,427]     INFO Processing #42/200
[2022-06-01 17:27:24,547]     INFO Processing #44/200
[2022-06-01 17:27:27,009]     INFO Processing #46/200
[2022-06-01 17:27:30,711]     INFO Processing #48/200
[2022-06-01 17:27:32,634]     INFO Processing #50/200
[2022-06-01 17:27:34,364]     INFO Processing #52/200
[2022-06-01 17:27:35,805]     INFO Processing #54/200
[2022-06-01 17:27:37,372]     INFO Processing #56/200
[2022-06-01 17:27:39,112]     INFO Processing #58/200
[2022-06-01 17:27:40,350]     INFO Processing #60/200
[2022-06-01 17:27:42,189]     INFO Processing #62/200
[2022-06-01 17:27:43,708]     INFO Processing #64/200
[2022-06-01 17:27:45,683]     INFO Processing #66/200
[2022-06-01 17:27:47,043]     INFO Processing #68/200
[2022-06-01 17:27:48,645]     INFO Processing #70/200
[2022-06-01 17:27:50,102]     INFO Processing #72/200
[2022-06-01 17:27:51,424]     INFO Processing #74/200
[2022-06-01 17:27:54,119]     INFO Processing #76/200
[2022-06-01 17:27:55,594]     INFO Processing #78/200
[2022-06-01 17:27:58,753]     INFO Processing #80/200
[2022-06-01 17:28:01,907]     INFO Processing #82/200
[2022-06-01 17:28:04,662]     INFO Processing #84/200
[2022-06-01 17:28:07,404]     INFO Processing #86/200
[2022-06-01 17:28:09,937]     INFO Processing #88/200
[2022-06-01 17:28:11,981]     INFO Processing #90/200
[2022-06-01 17:28:15,129]     INFO Processing #92/200
[2022-06-01 17:28:17,777]     INFO Processing #94/200
[2022-06-01 17:28:19,318]     INFO Processing #96/200
[2022-06-01 17:28:22,409]     INFO Processing #98/200
[2022-06-01 17:28:24,132]     INFO Processing #100/200
[2022-06-01 17:28:25,751]     INFO Processing #102/200
[2022-06-01 17:28:27,564]     INFO Processing #104/200
[2022-06-01 17:28:29,016]     INFO Processing #106/200
[2022-06-01 17:28:30,511]     INFO Processing #108/200
[2022-06-01 17:28:31,931]     INFO Processing #110/200
[2022-06-01 17:28:33,632]     INFO Processing #112/200
[2022-06-01 17:28:36,317]     INFO Processing #114/200
[2022-06-01 17:28:38,009]     INFO Processing #116/200
[2022-06-01 17:28:40,110]     INFO Processing #118/200
[2022-06-01 17:28:41,768]     INFO Processing #120/200
[2022-06-01 17:28:43,265]     INFO Processing #122/200
[2022-06-01 17:28:45,592]     INFO Processing #124/200
[2022-06-01 17:28:47,240]     INFO Processing #126/200
[2022-06-01 17:28:49,018]     INFO Processing #128/200
[2022-06-01 17:28:50,563]     INFO Processing #130/200
[2022-06-01 17:28:52,663]     INFO Processing #132/200
[2022-06-01 17:28:56,852]     INFO Processing #134/200
[2022-06-01 17:28:58,375]     INFO Processing #136/200
[2022-06-01 17:29:06,967]     INFO Processing #138/200
[2022-06-01 17:29:10,808]     INFO Processing #140/200
[2022-06-01 17:29:13,761]     INFO Processing #142/200
[2022-06-01 17:29:15,409]     INFO Processing #144/200
[2022-06-01 17:29:17,852]     INFO Processing #146/200
[2022-06-01 17:29:19,525]     INFO Processing #148/200
[2022-06-01 17:29:21,752]     INFO Processing #150/200
[2022-06-01 17:29:23,116]     INFO Processing #152/200
[2022-06-01 17:29:24,265]     INFO Processing #154/200
[2022-06-01 17:29:26,364]     INFO Processing #156/200
[2022-06-01 17:29:27,746]     INFO Processing #158/200
[2022-06-01 17:29:29,568]     INFO Processing #160/200
[2022-06-01 17:29:31,117]     INFO Processing #162/200
[2022-06-01 17:29:32,965]     INFO Processing #164/200
[2022-06-01 17:29:34,725]     INFO Processing #166/200
[2022-06-01 17:29:36,387]     INFO Processing #168/200
[2022-06-01 17:29:38,298]     INFO Processing #170/200
[2022-06-01 17:29:39,924]     INFO Processing #172/200
[2022-06-01 17:29:41,601]     INFO Processing #174/200
[2022-06-01 17:29:43,656]     INFO Processing #176/200
[2022-06-01 17:29:46,111]     INFO Processing #178/200
[2022-06-01 17:29:47,720]     INFO Processing #180/200
[2022-06-01 17:29:49,633]     INFO Processing #182/200
[2022-06-01 17:29:51,909]     INFO Processing #184/200
[2022-06-01 17:29:53,342]     INFO Processing #186/200
[2022-06-01 17:29:54,933]     INFO Processing #188/200
[2022-06-01 17:29:56,432]     INFO Processing #190/200
[2022-06-01 17:29:58,508]     INFO Processing #192/200
[2022-06-01 17:29:59,521]     INFO Processing #194/200
[2022-06-01 17:30:01,384]     INFO Processing #196/200
[2022-06-01 17:30:03,545]     INFO Processing #198/200
[2022-06-01 17:30:05,339]     INFO Processing #200/200
[2022-06-01 18:33:41,855]     INFO No further results available - stopping execution
[2022-06-01 18:33:44,569]     INFO No further results available - stopping execution
[2022-06-01 18:33:48,199]     INFO Processing #4/74
[2022-06-01 18:33:49,580]     INFO Processing #8/74
[2022-06-01 18:33:50,554]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/university-Books/s?k=%22university+of%22&rh=n%3A283155&page=12
[2022-06-01 18:33:50,554]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/university-Books/s?k=%22university+of%22&rh=n%3A283155&page=12)
[2022-06-01 18:33:52,309]     INFO Processing #12/74
[2022-06-01 18:33:53,504]     INFO Processing #16/74
[2022-06-01 18:33:55,553]     INFO Processing #20/74
[2022-06-01 18:33:57,809]     INFO Processing #24/74
[2022-06-01 18:33:58,131]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:33:58,131]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:33:59,409]     INFO Processing #28/74
[2022-06-01 18:34:01,512]     INFO Processing #32/74
[2022-06-01 18:34:03,040]     INFO Processing #36/74
[2022-06-01 18:34:04,467]     INFO Processing #40/74
[2022-06-01 18:34:06,145]     INFO Processing #44/74
[2022-06-01 18:34:08,678]     INFO Processing #48/74
[2022-06-01 18:34:10,132]     INFO Processing #52/74
[2022-06-01 18:34:11,500]     INFO Processing #56/74
[2022-06-01 18:34:13,890]     INFO Processing #60/74
[2022-06-01 18:34:15,325]     INFO Processing #64/74
[2022-06-01 18:34:16,806]     INFO Processing #68/74
[2022-06-01 18:34:18,720]     INFO Processing #72/74
[2022-06-01 18:34:23,579]     INFO Processing #4/74
[2022-06-01 18:34:25,140]     INFO Processing #8/74
[2022-06-01 18:34:26,452]     INFO Processing #12/74
[2022-06-01 18:34:29,254]     INFO Processing #16/74
[2022-06-01 18:34:30,833]     INFO Processing #20/74
[2022-06-01 18:34:32,548]     INFO Processing #24/74
[2022-06-01 18:34:34,373]     INFO Processing #28/74
[2022-06-01 18:34:35,778]     INFO Processing #32/74
[2022-06-01 18:34:38,751]     INFO Processing #36/74
[2022-06-01 18:34:40,296]     INFO Processing #40/74
[2022-06-01 18:34:42,266]     INFO Processing #44/74
[2022-06-01 18:34:44,225]     INFO Processing #48/74
[2022-06-01 18:34:45,730]     INFO Processing #52/74
[2022-06-01 18:34:47,530]     INFO Processing #56/74
[2022-06-01 18:34:49,721]     INFO Processing #60/74
[2022-06-01 18:34:51,853]     INFO Processing #64/74
[2022-06-01 18:34:54,270]     INFO Processing #68/74
[2022-06-01 18:34:55,953]     INFO Processing #72/74
[2022-06-01 18:35:02,350]     INFO Processing #4/74
[2022-06-01 18:35:04,348]     INFO Processing #8/74
[2022-06-01 18:35:07,133]     INFO Processing #12/74
[2022-06-01 18:35:10,759]     INFO Processing #16/74
[2022-06-01 18:35:13,673]     INFO Processing #20/74
[2022-06-01 18:35:16,430]     INFO Processing #24/74
[2022-06-01 18:35:18,994]     INFO Processing #28/74
[2022-06-01 18:35:20,826]     INFO Processing #32/74
[2022-06-01 18:35:23,227]     INFO Processing #36/74
[2022-06-01 18:35:25,300]     INFO Processing #40/74
[2022-06-01 18:35:27,479]     INFO Processing #44/74
[2022-06-01 18:35:32,049]     INFO Processing #48/74
[2022-06-01 18:35:35,015]     INFO Processing #52/74
[2022-06-01 18:35:38,683]     INFO Processing #56/74
[2022-06-01 18:35:41,157]     INFO Processing #60/74
[2022-06-01 18:35:43,786]     INFO Processing #64/74
[2022-06-01 18:35:45,970]     INFO Processing #68/74
[2022-06-01 18:35:47,950]     INFO Processing #72/74
[2022-06-01 18:35:53,069]     INFO Processing #4/74
[2022-06-01 18:35:54,322]     INFO Processing #8/74
[2022-06-01 18:35:55,731]     INFO Processing #12/74
[2022-06-01 18:35:57,965]     INFO Processing #16/74
[2022-06-01 18:35:59,201]     INFO Processing #20/74
[2022-06-01 18:36:00,756]     INFO Processing #24/74
[2022-06-01 18:36:02,983]     INFO Processing #28/74
[2022-06-01 18:36:04,784]     INFO Processing #32/74
[2022-06-01 18:36:06,470]     INFO Processing #36/74
[2022-06-01 18:36:08,174]     INFO Processing #40/74
[2022-06-01 18:36:10,029]     INFO Processing #44/74
[2022-06-01 18:36:11,482]     INFO Processing #48/74
[2022-06-01 18:36:14,017]     INFO Processing #52/74
[2022-06-01 18:36:15,833]     INFO Processing #56/74
[2022-06-01 18:36:17,068]     INFO Processing #60/74
[2022-06-01 18:36:19,567]     INFO Processing #64/74
[2022-06-01 18:36:20,888]     INFO Processing #68/74
[2022-06-01 18:36:22,370]     INFO Processing #72/74
[2022-06-01 18:36:27,207]     INFO Processing #4/74
[2022-06-01 18:36:29,857]     INFO Processing #8/74
[2022-06-01 18:36:31,323]     INFO Processing #12/74
[2022-06-01 18:36:33,427]     INFO Processing #16/74
[2022-06-01 18:36:35,390]     INFO Processing #20/74
[2022-06-01 18:36:36,786]     INFO Processing #24/74
[2022-06-01 18:36:38,147]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:36:38,147]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:36:38,727]     INFO Processing #28/74
[2022-06-01 18:36:40,587]     INFO Processing #32/74
[2022-06-01 18:36:42,507]     INFO Processing #36/74
[2022-06-01 18:36:43,898]     INFO Processing #40/74
[2022-06-01 18:36:44,098]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=44&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:36:44,098]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=44&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:36:45,312]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:36:45,312]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:36:45,890]     INFO Processing #44/74
[2022-06-01 18:36:46,508]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:36:46,508]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=47&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:36:48,246]     INFO Processing #48/74
[2022-06-01 18:36:49,718]     INFO Processing #52/74
[2022-06-01 18:36:50,193]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=57&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:36:50,194]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=57&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:36:51,392]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=57&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:36:51,392]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=57&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:36:51,777]     INFO Processing #56/74
[2022-06-01 18:36:52,827]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=57&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:36:52,827]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=57&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:36:52,850]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:36:52,851]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=61&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:36:53,198]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=62&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:36:53,198]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=62&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:36:55,130]     INFO Processing #60/74
[2022-06-01 18:36:55,320]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:36:55,321]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:36:56,407]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:36:56,407]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:36:56,503]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:36:56,503]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=64&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:36:57,616]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:36:57,616]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=66&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:36:57,718]     INFO Processing #64/74
[2022-06-01 18:37:03,975]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:03,975]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=69&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:05,536]     INFO Processing #68/74
[2022-06-01 18:37:05,892]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:05,893]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:07,153]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:07,153]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=73&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:07,652]     INFO Processing #72/74
[2022-06-01 18:37:09,694]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:09,695]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:12,818]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:12,818]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:13,892]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:13,892]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:14,383]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:14,383]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:15,150]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:15,150]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:15,198]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:15,198]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:15,641]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:15,642]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:16,440]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:16,440]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:17,564]     INFO Processing #4/74
[2022-06-01 18:37:17,702]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:17,702]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:17,831]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:17,831]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:17,997]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:17,997]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:18,966]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:18,966]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:19,255]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:19,255]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:20,933]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:20,934]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:20,934]     INFO name 'AllRequestsFailedError' is not defined raised and ignored while processing item
[2022-06-01 18:37:20,934]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise AllRequestsFailedError(exc)
NameError: name 'AllRequestsFailedError' is not defined
[2022-06-01 18:37:21,114]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:21,114]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:21,114]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:21,115]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:21,231]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:21,232]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:22,376]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:22,376]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:23,209]     INFO Processing #8/74
[2022-06-01 18:37:23,814]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:23,814]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:23,920]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:23,921]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:24,701]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:24,701]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:25,184]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:25,184]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:25,283]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:25,283]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:26,270]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:26,270]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:26,546]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:26,546]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:27,498]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:27,499]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:27,532]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:27,532]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:27,809]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:27,809]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:28,765]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:28,766]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:29,066]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:29,066]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:29,667]     INFO Processing #12/74
[2022-06-01 18:37:29,929]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:29,929]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:30,027]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:30,027]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:31,244]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:31,244]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:31,346]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:31,346]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:31,372]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:31,372]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:32,505]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:32,505]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:32,642]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:32,642]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:32,913]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:32,914]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:33,763]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:33,763]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:33,905]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:33,905]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:35,019]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:35,019]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:35,165]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:35,167]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:36,282]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:36,284]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:36,285]     INFO name 'AllRequestsFailedError' is not defined raised and ignored while processing item
[2022-06-01 18:37:36,285]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise AllRequestsFailedError(exc)
NameError: name 'AllRequestsFailedError' is not defined
[2022-06-01 18:37:36,285]     INFO Processing #16/74
[2022-06-01 18:37:36,430]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:36,430]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:36,438]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:36,438]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:36,551]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:36,551]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:37,691]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:37,691]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:37,692]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:37,693]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:37,693]     INFO name 'AllRequestsFailedError' is not defined raised and ignored while processing item
[2022-06-01 18:37:37,693]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise AllRequestsFailedError(exc)
NameError: name 'AllRequestsFailedError' is not defined
[2022-06-01 18:37:37,807]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:37,807]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:37,948]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:37,948]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:38,945]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:38,945]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:39,209]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:39,210]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:39,377]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:39,377]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:40,369]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:40,369]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:40,576]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:40,576]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:40,865]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:40,866]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:41,752]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:41,752]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:41,860]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:41,860]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:42,124]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:42,124]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:43,020]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:43,020]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:43,020]     INFO name 'AllRequestsFailedError' is not defined raised and ignored while processing item
[2022-06-01 18:37:43,021]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
NameError: name 'AllRequestsFailedError' is not defined
[2022-06-01 18:37:43,132]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:43,132]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:43,285]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:43,285]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:43,384]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:43,384]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:43,385]     INFO name 'AllRequestsFailedError' is not defined raised and ignored while processing item
[2022-06-01 18:37:43,385]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
NameError: name 'AllRequestsFailedError' is not defined
[2022-06-01 18:37:44,530]     INFO Processing #20/74
[2022-06-01 18:37:44,546]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:44,547]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:44,704]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:44,704]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:44,705]     INFO name 'AllRequestsFailedError' is not defined raised and ignored while processing item
[2022-06-01 18:37:44,706]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
NameError: name 'AllRequestsFailedError' is not defined
[2022-06-01 18:37:44,790]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:44,791]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:45,164]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:45,165]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:45,807]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:45,807]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:46,051]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:46,051]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:46,430]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:46,430]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:47,314]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:47,314]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:47,690]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:47,690]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:48,157]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:48,157]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:48,585]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:48,585]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:48,946]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:48,947]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:49,415]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:49,415]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:49,843]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:49,843]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:50,508]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:50,508]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:50,994]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:50,994]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:51,103]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:51,103]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:51,103]     INFO name 'AllRequestsFailedError' is not defined raised and ignored while processing item
[2022-06-01 18:37:51,104]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
NameError: name 'AllRequestsFailedError' is not defined
[2022-06-01 18:37:51,374]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:51,374]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:51,767]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:51,768]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:51,768]     INFO name 'AllRequestsFailedError' is not defined raised and ignored while processing item
[2022-06-01 18:37:51,768]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
NameError: name 'AllRequestsFailedError' is not defined
[2022-06-01 18:37:51,768]     INFO Processing #24/74
[2022-06-01 18:37:52,028]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:52,028]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:52,259]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:52,259]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:52,634]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:52,634]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:53,592]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:53,592]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:53,819]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:53,819]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:53,892]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:53,892]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:54,856]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:54,856]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:55,162]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:55,163]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:55,308]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:55,308]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:55,308]     INFO name 'AllRequestsFailedError' is not defined raised and ignored while processing item
[2022-06-01 18:37:55,309]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
NameError: name 'AllRequestsFailedError' is not defined
[2022-06-01 18:37:55,567]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:55,567]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:56,416]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:56,416]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:56,616]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:56,617]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:56,747]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:56,747]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:57,585]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:57,585]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:57,910]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:57,911]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:58,015]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:58,015]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:58,015]     INFO name 'AllRequestsFailedError' is not defined raised and ignored while processing item
[2022-06-01 18:37:58,015]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
NameError: name 'AllRequestsFailedError' is not defined
[2022-06-01 18:37:58,190]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:58,190]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:58,750]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:58,750]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:58,751]     INFO name 'AllRequestsFailedError' is not defined raised and ignored while processing item
[2022-06-01 18:37:58,751]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
NameError: name 'AllRequestsFailedError' is not defined
[2022-06-01 18:37:58,937]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:58,937]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:59,077]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:59,077]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:37:59,593]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:37:59,593]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:00,248]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:00,248]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:00,405]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:00,405]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:00,854]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:00,855]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:01,510]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:01,510]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:01,911]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:01,911]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:01,911]     INFO name 'AllRequestsFailedError' is not defined raised and ignored while processing item
[2022-06-01 18:38:01,911]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
NameError: name 'AllRequestsFailedError' is not defined
[2022-06-01 18:38:01,912]     INFO Processing #28/74
[2022-06-01 18:38:02,060]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:02,060]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:02,693]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:02,693]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:06,401]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:06,401]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:07,575]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:07,575]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:08,734]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:08,734]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:09,904]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:09,905]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:11,069]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:11,069]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:12,235]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:12,235]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:12,404]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:12,404]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:13,578]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:13,578]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:14,750]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:14,750]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:15,932]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:15,932]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:17,216]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:17,216]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:18,378]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:18,378]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:18,548]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:18,548]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:19,709]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:19,709]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:21,820]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:21,821]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:22,986]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:22,986]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:24,156]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:24,156]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:25,332]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:25,332]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:26,497]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:26,497]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:27,664]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:27,664]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:27,827]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:27,827]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:28,997]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:28,998]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:30,201]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:30,201]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:31,508]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:31,508]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:32,699]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:32,700]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:33,933]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:33,933]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:34,166]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:34,167]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:35,871]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:35,871]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:37,191]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:37,191]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:38,354]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:38,354]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:39,689]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:39,690]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:40,848]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:40,849]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:44,015]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:44,015]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:45,213]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:45,213]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:46,384]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:46,385]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:47,583]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:47,583]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:48,807]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:48,808]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:50,091]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:50,091]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:52,114]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:52,114]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:54,436]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:54,437]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:55,784]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:55,784]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:56,944]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:56,945]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:58,319]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:58,320]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:38:59,632]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:38:59,632]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:01,022]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:01,022]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:01,331]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:01,331]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:02,645]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:02,645]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:03,829]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:03,829]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:05,002]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:05,002]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:06,167]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:06,167]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:07,329]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:07,329]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:07,488]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:07,488]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:08,651]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:08,651]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:09,814]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:09,814]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:10,982]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:10,982]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:12,389]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:12,389]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:13,794]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:13,795]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:13,957]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:13,957]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:15,123]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:15,123]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:16,350]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:16,350]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:17,578]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:17,579]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:18,739]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:18,740]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:19,935]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:19,936]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:20,109]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:20,109]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:21,270]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:21,271]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:22,700]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:22,700]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:23,868]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:23,868]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:26,340]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:26,340]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:26,340]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:26,341]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:26,342]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:26,342]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=2&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:27,520]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:27,520]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:27,746]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:27,747]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=4&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:28,693]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:28,693]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=3&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:28,777]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:28,777]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:29,955]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:29,955]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:30,277]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:30,277]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:31,110]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:31,111]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:31,115]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:31,116]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:31,445]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:31,445]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:32,426]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:32,427]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:32,427]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:32,427]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:32,655]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:32,655]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:33,757]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:33,758]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:33,758]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:33,758]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:33,943]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:33,944]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:34,925]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:34,926]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:34,926]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:34,926]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:34,927]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:39:34,927]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=5&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:34,928]     INFO Processing #4/74
[2022-06-01 18:39:35,090]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:35,090]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:35,091]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:35,092]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:36,104]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:36,106]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:36,253]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:36,253]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:36,254]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:36,255]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:36,255]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:39:36,255]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=6&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:36,427]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:36,427]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:37,271]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:37,271]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:37,271]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:39:37,271]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=7&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:37,419]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:37,420]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:37,456]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:37,456]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:37,589]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:37,589]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:38,596]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:38,596]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:38,619]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:38,619]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:38,985]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:38,985]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:39,774]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:39,774]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:39,794]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:39,794]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:40,143]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:40,144]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:40,941]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:40,941]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:40,942]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:39:40,942]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=8&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:40,961]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:40,961]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:41,133]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:41,133]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:41,633]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:41,633]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:42,297]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:42,297]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:42,352]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:42,352]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:42,809]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:42,810]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:42,810]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:39:42,810]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=9&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:42,811]     INFO Processing #8/74
[2022-06-01 18:39:42,971]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:42,971]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:43,466]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:43,467]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:43,523]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:43,523]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:43,523]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:39:43,524]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=10&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:43,686]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:43,686]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:44,135]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:44,135]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:44,632]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:44,632]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:44,853]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:44,854]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:45,310]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:45,310]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:45,805]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:45,806]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:46,014]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:46,015]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:46,592]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:46,592]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=12&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:46,973]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:46,973]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:46,975]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:39:46,975]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=11&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:47,140]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:47,140]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:47,408]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:47,409]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:48,405]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:48,405]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:48,680]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:48,681]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:49,325]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:49,325]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:49,572]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:49,572]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:49,844]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:49,844]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:49,844]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:39:49,844]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=13&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:49,845]     INFO Processing #12/74
[2022-06-01 18:39:50,007]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:50,007]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:50,486]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:50,486]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:50,748]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:50,748]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=14&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:51,173]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:51,173]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:51,651]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:51,651]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:52,341]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:52,341]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:52,816]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:52,816]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:53,096]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:53,096]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:53,509]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:53,509]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:54,122]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:54,123]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:54,262]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:54,263]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:54,684]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:54,684]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:55,297]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:55,298]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:55,299]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:39:55,302]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=15&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:55,437]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:55,437]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:55,466]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:55,466]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:55,847]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:55,847]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:55,848]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:39:55,848]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=16&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:56,022]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:56,022]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:56,597]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:56,598]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:56,628]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:56,628]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:57,193]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:57,193]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:57,757]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:57,757]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:57,785]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:57,785]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:58,357]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:58,358]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:58,919]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:58,920]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:58,920]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:39:58,920]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=17&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:58,921]     INFO Processing #16/74
[2022-06-01 18:39:59,085]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:59,085]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:59,173]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:59,173]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:39:59,515]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:39:59,516]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:00,265]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:00,265]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:00,494]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:00,494]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:00,677]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:00,677]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:01,585]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:01,585]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:01,654]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:01,655]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:01,655]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:40:01,655]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=18&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:01,848]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:01,848]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:01,848]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:40:01,848]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=19&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:02,014]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:02,014]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:02,041]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:02,041]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=21&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:02,746]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:02,746]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:03,200]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:03,200]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:03,913]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:03,914]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:04,364]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:04,364]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:04,746]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:04,746]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:05,300]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:05,301]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:05,301]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:40:05,301]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=20&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:05,302]     INFO Processing #20/74
[2022-06-01 18:40:05,475]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:05,475]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:05,534]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:05,534]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:05,911]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:05,912]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:06,694]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:06,694]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:06,781]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:06,782]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:07,080]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:07,081]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:07,857]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:07,857]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:07,857]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:40:07,858]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=22&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:07,959]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:07,959]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:08,157]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:08,157]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:08,794]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:08,794]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:09,414]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:09,414]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:09,448]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:09,448]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:09,993]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:09,994]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:10,577]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:10,577]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:10,608]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:10,608]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:11,313]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:11,313]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:11,313]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:40:11,313]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=23&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:11,475]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:11,475]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:11,739]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:11,739]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:11,739]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:40:11,739]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=24&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:11,901]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:11,902]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:11,916]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:11,916]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:12,642]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:12,642]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:13,076]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:13,076]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:13,079]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:13,080]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:13,805]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:13,805]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:14,243]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:14,243]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:14,243]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:40:14,244]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=25&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:14,244]     INFO Processing #24/74
[2022-06-01 18:40:14,255]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:14,255]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:14,644]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:14,644]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:14,969]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:14,969]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:15,428]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:15,428]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:16,038]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:16,038]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:16,346]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:16,347]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:16,739]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:16,739]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:17,207]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:17,207]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:17,757]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:17,757]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:17,758]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:40:17,758]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=26&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:17,907]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:17,907]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:17,907]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:40:17,908]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=27&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:17,917]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:17,917]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:18,073]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:18,073]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:18,373]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:18,373]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:19,081]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:19,083]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:19,233]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:19,234]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:19,543]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:19,544]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:20,654]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:20,654]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:20,752]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:20,753]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:20,862]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:20,862]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:20,862]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:40:20,862]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=28&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:21,440]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:21,440]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:22,036]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:22,036]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:22,102]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:22,103]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:22,602]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:22,602]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:23,199]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:23,199]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:23,417]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:23,417]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:23,766]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:23,766]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:24,358]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:24,358]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:24,358]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:40:24,359]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=29&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:24,359]     INFO Processing #28/74
[2022-06-01 18:40:24,534]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:24,534]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:24,580]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:24,580]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:24,580]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:40:24,580]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=30&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:24,740]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:24,740]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:25,154]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:25,154]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:25,717]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:25,717]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:25,902]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:25,903]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:26,320]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:26,321]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:26,890]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:26,890]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:27,072]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:27,072]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:27,479]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:27,480]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:27,480]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:40:27,480]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=31&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:27,652]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:27,653]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:28,057]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:28,057]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:28,462]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:28,462]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:28,819]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:28,819]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:29,217]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:29,217]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:29,623]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:29,623]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:29,980]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:29,980]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:30,379]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:30,379]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:30,379]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:40:30,380]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=32&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:30,932]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:30,932]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:30,933]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:40:30,933]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=33&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:30,933]     INFO Processing #32/74
[2022-06-01 18:40:31,143]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:31,144]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:31,246]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:31,246]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:32,001]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:32,001]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:32,636]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:32,636]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:32,637]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:32,637]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:33,248]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:33,248]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:33,994]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:33,994]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:33,994]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:33,995]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:33,995]     INFO 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b raised and ignored while processing item
[2022-06-01 18:40:33,995]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 73, in scrape_url
    resp = self.scraper.get(url, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/requester.py", line 52, in inner
    return pool.execute()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 82, in execute
    return self._do_parallel_execution()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 132, in _do_parallel_execution
    done, futures = self._parse_completing_threads(futures)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 153, in _parse_completing_threads
    raise f.exception()  # Only True if a **stopping* exception
  File "/usr/local/lib/python3.8/concurrent/futures/thread.py", line 57, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 101, in _handle_task
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 47, in inner
    scraper._handle_error(e, iteration)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 84, in _handle_error
    raise ScrapeFailedError(exc)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/exceptions.py", line 5, in __init__
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    return scraper._parse_response(resp)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 74, in _parse_response
    raise RequestFailedError(resp.msg)
tsutils.scrape.exceptions.RequestFailedError: 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=34&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:34,395]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=38&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:34,395]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=38&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:34,639]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:34,639]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:35,152]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:35,152]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=36&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:35,553]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=38&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:35,553]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=38&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:40:35,952]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:40:35,952]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&page=37&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:05,118]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:05,118]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:06,284]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:06,284]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:07,456]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:07,457]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:08,890]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:08,890]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:10,058]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:10,058]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:11,229]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:11,229]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:11,393]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:11,393]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:13,728]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:13,728]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:14,890]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:14,891]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:16,057]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:16,058]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:17,383]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:17,383]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:19,306]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:19,306]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:20,774]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:20,774]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:21,952]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:21,953]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:23,140]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:23,141]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:24,308]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:24,308]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:25,489]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:25,489]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:25,657]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:25,657]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:26,840]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:26,840]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:28,007]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:28,007]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:29,409]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:29,409]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:30,581]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:30,581]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:31,755]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:31,755]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:31,921]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:31,921]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:33,239]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:33,239]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:34,445]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:34,445]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:35,610]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:35,610]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:36,944]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:36,944]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:38,217]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:38,217]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:38,383]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:38,383]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:39,545]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:39,546]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:40,708]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:40,708]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:42,311]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:42,311]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:43,492]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:43,493]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:44,677]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:44,677]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22technology%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:44,840]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:44,840]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:45,999]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:46,000]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:47,164]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:47,165]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:48,328]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:48,328]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:49,549]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:49,549]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:50,712]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:50,713]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22law%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:50,878]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:50,879]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:52,048]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:52,048]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:42:53,289]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:42:53,290]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22digital%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:43:32,242]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:43:32,242]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:43:33,436]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:43:33,437]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:43:34,718]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:43:34,718]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:43:35,923]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:43:35,923]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:43:37,124]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:43:37,124]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:43:38,383]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:43:38,383]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:44:36,849]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:44:36,850]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:44:38,016]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:44:38,017]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:44:39,180]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:44:39,181]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:44:40,344]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:44:40,344]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:44:41,506]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:44:41,507]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:44:42,665]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:44:42,665]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:46:01,634]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:46:01,634]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:46:02,834]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:46:02,834]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:46:04,030]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:46:04,030]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:46:05,212]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:46:05,212]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:46:06,394]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:46:06,394]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:46:07,585]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:46:07,585]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:46:07,765]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:46:07,765]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:46:09,110]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:46:09,111]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:46:10,466]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:46:10,467]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:51:59,916]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:51:59,916]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:01,097]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:01,097]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:02,294]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:02,294]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:03,481]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:03,481]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:04,777]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:04,777]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:05,990]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:05,990]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22The+Indigo+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=6&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:06,189]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:06,189]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:07,380]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:07,381]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:08,669]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:08,669]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:09,864]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:09,864]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22Stanford+University+Press%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:12,065]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:12,065]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:13,248]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:13,248]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:14,431]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:14,431]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:15,612]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:15,612]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:16,801]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:16,801]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:18,014]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:18,014]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22professor+of%22&i=stripbooks&s=daterank&Adv-Srch-Books%5B%E2%80%A6%5Dd-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:18,197]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:18,197]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:19,644]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:19,644]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:20,824]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:20,824]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:22,115]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:22,115]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:23,457]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:23,457]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:24,623]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:24,623]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22university+of%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:24,785]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:24,785]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:26,114]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:26,114]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:27,514]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:27,514]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:28,680]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:28,680]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:29,857]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:29,857]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:31,177]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:31,177]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22economic%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:31,340]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:31,340]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:32,726]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:32,726]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:34,139]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:34,139]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 18:52:35,302]     DEBUG Request failed - 503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b
[2022-06-01 18:52:35,302]     DEBUG Rotating host (503 raised requesting https://www.amazon.com/s?k=%22history%22&i=stripbooks&s=daterank&Adv-Srch-Books-Submit.x=26&Adv-Srch-Books-Submit.y=20&field-datemod=5&field-dateop=During&field-dateyear=2022&unfiltered=1&ref=sr_adv_b)
[2022-06-01 17:53:46,035]     INFO Configuring defensive HTML source session
[2022-06-01 17:53:59,582]     INFO Processing #2/99
[2022-06-01 17:54:00,878]     INFO Processing #4/99
[2022-06-01 17:54:03,325]     INFO Processing #6/99
[2022-06-01 17:54:04,955]     INFO Processing #8/99
[2022-06-01 17:54:06,262]     INFO Processing #10/99
[2022-06-01 17:54:09,669]     INFO Processing #12/99
[2022-06-01 17:54:12,008]     INFO Processing #14/99
[2022-06-01 17:54:14,867]     INFO Processing #16/99
[2022-06-01 17:54:16,254]     INFO Processing #18/99
[2022-06-01 17:54:17,899]     INFO Processing #20/99
[2022-06-01 17:54:21,152]     INFO Processing #22/99
[2022-06-01 17:54:23,044]     INFO Processing #24/99
[2022-06-01 17:54:24,226]     INFO Processing #26/99
[2022-06-01 17:54:25,726]     INFO Processing #28/99
[2022-06-01 17:54:27,706]     INFO Processing #30/99
[2022-06-01 17:54:29,540]     INFO Processing #32/99
[2022-06-01 17:54:32,947]     INFO Processing #34/99
[2022-06-01 17:54:34,726]     INFO Processing #36/99
[2022-06-01 17:54:36,681]     INFO Processing #38/99
[2022-06-01 17:54:38,183]     INFO Processing #40/99
[2022-06-01 17:54:39,866]     INFO Processing #42/99
[2022-06-01 17:54:41,144]     INFO Processing #44/99
[2022-06-01 17:54:43,992]     INFO Processing #46/99
[2022-06-01 17:54:46,235]     INFO Processing #48/99
[2022-06-01 17:54:48,533]     INFO Processing #50/99
[2022-06-01 17:54:50,779]     INFO Processing #52/99
[2022-06-01 17:54:53,342]     INFO Processing #54/99
[2022-06-01 17:54:56,910]     INFO Processing #56/99
[2022-06-01 17:55:00,496]     INFO Processing #58/99
[2022-06-01 17:55:02,353]     INFO Processing #60/99
[2022-06-01 17:55:04,535]     INFO Processing #62/99
[2022-06-01 17:55:06,111]     INFO Processing #64/99
[2022-06-01 17:55:08,541]     INFO Processing #66/99
[2022-06-01 17:55:10,477]     INFO Processing #68/99
[2022-06-01 17:55:12,751]     INFO Processing #70/99
[2022-06-01 17:55:14,267]     INFO Processing #72/99
[2022-06-01 17:55:16,353]     INFO Processing #74/99
[2022-06-01 17:55:18,468]     INFO Processing #76/99
[2022-06-01 17:55:20,017]     INFO Processing #78/99
[2022-06-01 17:55:22,103]     INFO Processing #80/99
[2022-06-01 17:55:25,077]     INFO Processing #82/99
[2022-06-01 17:55:27,689]     INFO Processing #84/99
[2022-06-01 17:55:30,026]     INFO Processing #86/99
[2022-06-01 17:55:31,560]     INFO Processing #88/99
[2022-06-01 17:55:33,267]     INFO Processing #90/99
[2022-06-01 17:55:35,914]     INFO Processing #92/99
[2022-06-01 17:55:38,050]     INFO Processing #94/99
[2022-06-01 17:55:40,107]     INFO Processing #96/99
[2022-06-01 17:55:41,760]     INFO Processing #98/99
[2022-06-01 19:24:41,219]     INFO Configuring defensive HTML source session
[2022-06-01 19:37:32,276]     INFO Configuring defensive HTML source session
[2022-06-01 19:38:41,240]     INFO Configuring defensive HTML source session
[2022-06-01 19:39:53,590]     INFO Configuring defensive HTML source session
[2022-06-01 19:43:16,178]     INFO Configuring defensive HTML source session
[2022-06-01 19:43:52,889]     INFO Configuring defensive HTML source session
[2022-06-01 19:44:03,401]     INFO Configuring defensive HTML source session
[2022-06-01 19:44:06,253]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711
[2022-06-01 19:44:06,254]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711)
[2022-06-01 19:44:09,658]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711
[2022-06-01 19:44:09,658]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711)
[2022-06-01 19:44:12,166]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711
[2022-06-01 19:44:12,166]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711)
[2022-06-01 19:44:12,168]     ERROR Driver initialisation failed
[2022-06-01 19:44:52,636]     INFO Configuring defensive HTML source session
[2022-06-01 19:44:58,903]     INFO Configuring defensive HTML source session
[2022-06-01 19:45:01,002]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711
[2022-06-01 19:45:01,002]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711)
[2022-06-01 19:45:03,717]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711
[2022-06-01 19:45:03,717]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711)
[2022-06-01 19:45:06,631]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711
[2022-06-01 19:45:06,631]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711)
[2022-06-01 19:45:06,633]     ERROR Driver initialisation failed
[2022-06-01 19:45:06,633]     INFO Configuring defensive HTML source session
[2022-06-01 19:45:08,299]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/10.1111/imig.13019
[2022-06-01 19:45:08,299]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/10.1111/imig.13019)
[2022-06-01 19:45:11,142]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/10.1111/imig.13019
[2022-06-01 19:45:11,143]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/10.1111/imig.13019)
[2022-06-01 19:45:13,788]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/10.1111/imig.13019
[2022-06-01 19:45:13,788]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/10.1111/imig.13019)
[2022-06-01 19:45:13,790]     ERROR Driver initialisation failed
[2022-06-01 19:46:10,046]     INFO Configuring defensive HTML source session
[2022-06-01 19:46:28,852]     INFO Configuring defensive HTML source session
[2022-06-01 19:46:39,616]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711
[2022-06-01 19:46:39,616]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711)
[2022-06-01 19:46:51,387]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711
[2022-06-01 19:46:51,387]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/dech.12711)
[2022-06-01 19:46:59,889]     ERROR Driver initialisation failed
[2022-06-01 19:46:59,889]     INFO Configuring defensive HTML source session
[2022-06-01 19:46:59,896]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56795): Max retries exceeded with url: /session/6c9e65ef95a0b00302056e87aefebf1a/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f5298848070>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 19:47:00,566]     ERROR Driver initialisation failed
[2022-06-01 18:47:27,272]     INFO Configuring defensive HTML source session
[2022-06-01 18:47:39,689]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298
[2022-06-01 18:47:39,689]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298)
[2022-06-01 18:47:51,220]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298
[2022-06-01 18:47:51,220]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298)
[2022-06-01 18:48:02,729]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298
[2022-06-01 18:48:02,730]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298)
[2022-06-01 18:48:02,732]     ERROR Driver initialisation failed
[2022-06-01 18:48:02,732]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:06,702]     ERROR Driver initialisation failed
[2022-06-01 18:48:06,703]     INFO Processing #2/99
[2022-06-01 18:48:06,703]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:06,704]     DEBUG Rotating host (('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')))
[2022-06-01 18:48:07,709]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5cea60>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:07,872]     ERROR Driver initialisation failed
[2022-06-01 18:48:07,872]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:07,874]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1ce4bd90>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:08,036]     ERROR Driver initialisation failed
[2022-06-01 18:48:08,037]     INFO Processing #4/99
[2022-06-01 18:48:08,037]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:08,039]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1d690280>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:08,202]     ERROR Driver initialisation failed
[2022-06-01 18:48:08,202]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:08,205]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c57fca0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:08,456]     ERROR Driver initialisation failed
[2022-06-01 18:48:08,457]     INFO Processing #6/99
[2022-06-01 18:48:08,457]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:08,459]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c572e50>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:08,622]     ERROR Driver initialisation failed
[2022-06-01 18:48:08,622]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:08,625]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5ce1c0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:08,801]     ERROR Driver initialisation failed
[2022-06-01 18:48:08,802]     INFO Processing #8/99
[2022-06-01 18:48:08,802]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:08,804]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1ce4bac0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:08,982]     ERROR Driver initialisation failed
[2022-06-01 18:48:08,982]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:08,985]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5ce760>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:09,147]     ERROR Driver initialisation failed
[2022-06-01 18:48:09,147]     INFO Processing #10/99
[2022-06-01 18:48:09,147]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:09,151]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c57fc40>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:09,646]     ERROR Driver initialisation failed
[2022-06-01 18:48:09,646]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:09,649]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5c1e20>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:09,678]     ERROR Driver initialisation failed
[2022-06-01 18:48:09,678]     INFO Processing #12/99
[2022-06-01 18:48:09,678]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:09,681]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c572a30>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:09,707]     ERROR Driver initialisation failed
[2022-06-01 18:48:09,707]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:09,709]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5ce7c0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:09,737]     ERROR Driver initialisation failed
[2022-06-01 18:48:09,738]     INFO Processing #14/99
[2022-06-01 18:48:09,738]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:09,740]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1ce37fa0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:09,767]     ERROR Driver initialisation failed
[2022-06-01 18:48:09,768]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:09,770]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c57fe80>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:09,800]     ERROR Driver initialisation failed
[2022-06-01 18:48:09,800]     INFO Processing #16/99
[2022-06-01 18:48:09,800]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:09,803]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5e73a0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:09,830]     ERROR Driver initialisation failed
[2022-06-01 18:48:09,830]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:09,833]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5cec40>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:09,858]     ERROR Driver initialisation failed
[2022-06-01 18:48:09,859]     INFO Processing #18/99
[2022-06-01 18:48:09,859]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:09,862]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5e79a0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:09,889]     ERROR Driver initialisation failed
[2022-06-01 18:48:09,889]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:09,892]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1ce4b700>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:09,918]     ERROR Driver initialisation failed
[2022-06-01 18:48:09,918]     INFO Processing #20/99
[2022-06-01 18:48:09,919]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:09,921]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5ce760>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:09,950]     ERROR Driver initialisation failed
[2022-06-01 18:48:09,950]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:09,955]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1d6b0670>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:09,980]     ERROR Driver initialisation failed
[2022-06-01 18:48:09,980]     INFO Processing #22/99
[2022-06-01 18:48:09,980]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:09,983]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5e7a30>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,007]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,008]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,010]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c578640>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,038]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,039]     INFO Processing #24/99
[2022-06-01 18:48:10,039]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,041]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c578730>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,069]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,069]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,071]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c57fbb0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,098]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,098]     INFO Processing #26/99
[2022-06-01 18:48:10,099]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,101]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c62e100>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,129]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,130]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,132]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c578220>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,158]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,159]     INFO Processing #28/99
[2022-06-01 18:48:10,159]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,161]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5c1880>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,189]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,189]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,192]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1ce4bac0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,219]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,220]     INFO Processing #30/99
[2022-06-01 18:48:10,220]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,222]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5c1d90>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,250]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,250]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,253]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c612f10>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,285]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,285]     INFO Processing #32/99
[2022-06-01 18:48:10,285]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,288]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5e7ac0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,310]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,311]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,313]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c6125b0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,340]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,340]     INFO Processing #34/99
[2022-06-01 18:48:10,341]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,343]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5f95b0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,370]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,370]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,372]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5d4640>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,400]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,400]     INFO Processing #36/99
[2022-06-01 18:48:10,400]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,403]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5f95b0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,430]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,431]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,433]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5d4700>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,460]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,460]     INFO Processing #38/99
[2022-06-01 18:48:10,460]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,463]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5baf40>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,490]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,491]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,493]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5c1ca0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,525]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,525]     INFO Processing #40/99
[2022-06-01 18:48:10,525]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,527]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c583130>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,551]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,551]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,554]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5d4640>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,580]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,581]     INFO Processing #42/99
[2022-06-01 18:48:10,581]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,583]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c612d00>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,610]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,610]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,613]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c612250>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,640]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,640]     INFO Processing #44/99
[2022-06-01 18:48:10,640]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,642]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5d4be0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,670]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,670]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,673]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5c1790>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,701]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,701]     INFO Processing #46/99
[2022-06-01 18:48:10,701]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,704]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c612910>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,731]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,731]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,733]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c62ea60>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,763]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,763]     INFO Processing #48/99
[2022-06-01 18:48:10,763]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,766]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5c51c0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,791]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,791]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,796]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5d4970>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,821]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,822]     INFO Processing #50/99
[2022-06-01 18:48:10,822]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,824]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1ce4bb20>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,852]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,852]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,855]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5c57c0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,881]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,882]     INFO Processing #52/99
[2022-06-01 18:48:10,882]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,884]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1ce4b700>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,912]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,912]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,915]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c612d00>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,944]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,945]     INFO Processing #54/99
[2022-06-01 18:48:10,945]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,947]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5d49d0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:10,972]     ERROR Driver initialisation failed
[2022-06-01 18:48:10,973]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:10,975]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5ce280>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,002]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,002]     INFO Processing #56/99
[2022-06-01 18:48:11,003]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,005]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c6121f0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,034]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,034]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,036]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5ce190>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,066]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,066]     INFO Processing #58/99
[2022-06-01 18:48:11,066]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,069]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5d4310>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,093]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,094]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,097]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1ce37fd0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,124]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,124]     INFO Processing #60/99
[2022-06-01 18:48:11,124]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,128]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1ce372b0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,153]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,153]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,156]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1ce4b700>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,183]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,183]     INFO Processing #62/99
[2022-06-01 18:48:11,183]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,185]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5c6b80>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,214]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,214]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,216]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1ce37fd0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,245]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,245]     INFO Processing #64/99
[2022-06-01 18:48:11,245]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,247]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5c61f0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,274]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,274]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,276]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1ce37700>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,305]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,305]     INFO Processing #66/99
[2022-06-01 18:48:11,305]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,308]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5cd700>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,335]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,335]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,338]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5cd460>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,366]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,366]     INFO Processing #68/99
[2022-06-01 18:48:11,367]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,369]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5c61f0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,395]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,395]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,397]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5cd160>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,427]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,427]     INFO Processing #70/99
[2022-06-01 18:48:11,427]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,429]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5c68b0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,455]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,456]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,458]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5cea60>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,485]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,486]     INFO Processing #72/99
[2022-06-01 18:48:11,486]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,488]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5cee80>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,516]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,516]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,518]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5c6880>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,546]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,546]     INFO Processing #74/99
[2022-06-01 18:48:11,546]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,549]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1ce4bbe0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,577]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,578]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,580]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5ce4c0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,607]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,608]     INFO Processing #76/99
[2022-06-01 18:48:11,608]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,611]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5c11f0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,637]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,638]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,640]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c578160>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,669]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,669]     INFO Processing #78/99
[2022-06-01 18:48:11,669]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,671]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1ce4bd90>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,699]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,699]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,701]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5f94f0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,728]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,728]     INFO Processing #80/99
[2022-06-01 18:48:11,728]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,731]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5ce940>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,758]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,758]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,760]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5d4190>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,793]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,793]     INFO Processing #82/99
[2022-06-01 18:48:11,794]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,796]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5c6e20>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,821]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,821]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,824]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5cda30>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,851]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,851]     INFO Processing #84/99
[2022-06-01 18:48:11,851]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,854]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5cd070>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,881]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,881]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,883]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c612f10>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,911]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,911]     INFO Processing #86/99
[2022-06-01 18:48:11,912]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,914]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5e2310>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,940]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,940]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,943]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5cd670>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:11,972]     ERROR Driver initialisation failed
[2022-06-01 18:48:11,972]     INFO Processing #88/99
[2022-06-01 18:48:11,972]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:11,975]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c551100>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:12,001]     ERROR Driver initialisation failed
[2022-06-01 18:48:12,001]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:12,005]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5cd970>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:12,033]     ERROR Driver initialisation failed
[2022-06-01 18:48:12,034]     INFO Processing #90/99
[2022-06-01 18:48:12,034]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:12,036]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c5514c0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:12,062]     ERROR Driver initialisation failed
[2022-06-01 18:48:12,062]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:12,064]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c551850>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:12,091]     ERROR Driver initialisation failed
[2022-06-01 18:48:12,091]     INFO Processing #92/99
[2022-06-01 18:48:12,092]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:12,094]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c551040>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:12,122]     ERROR Driver initialisation failed
[2022-06-01 18:48:12,122]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:12,124]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c551b50>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:12,152]     ERROR Driver initialisation failed
[2022-06-01 18:48:12,153]     INFO Processing #94/99
[2022-06-01 18:48:12,153]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:12,155]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c551280>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:12,182]     ERROR Driver initialisation failed
[2022-06-01 18:48:12,182]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:12,184]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c4ff250>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:12,212]     ERROR Driver initialisation failed
[2022-06-01 18:48:12,213]     INFO Processing #96/99
[2022-06-01 18:48:12,213]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:12,215]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c551ee0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:12,242]     ERROR Driver initialisation failed
[2022-06-01 18:48:12,242]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:12,245]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c4ff610>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:12,272]     ERROR Driver initialisation failed
[2022-06-01 18:48:12,273]     INFO Processing #98/99
[2022-06-01 18:48:12,273]     INFO Configuring defensive HTML source session
[2022-06-01 18:48:12,275]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=56355): Max retries exceeded with url: /session/fcf3be3a2d738ea5cc38c60f6494b383/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f4c1c4ffa30>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:48:12,305]     ERROR Driver initialisation failed
[2022-06-01 18:49:29,953]     INFO Configuring defensive HTML source session
[2022-06-01 18:50:37,233]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298
[2022-06-01 18:50:37,233]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298)
[2022-06-01 18:50:48,739]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298
[2022-06-01 18:50:48,739]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298)
[2022-06-01 18:51:00,624]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.1329
[2022-06-01 18:51:00,624]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.1329)
[2022-06-01 18:51:00,626]     ERROR Driver initialisation failed
[2022-06-01 18:51:00,626]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:04,047]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:04,047]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:04,048]     INFO Processing #2/99
[2022-06-01 18:51:04,048]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:04,692]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:04,692]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:04,693]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:05,157]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:05,157]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:05,158]     INFO Processing #4/99
[2022-06-01 18:51:05,158]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:05,518]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:05,519]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:05,520]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:10,812]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:10,813]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:10,813]     INFO Processing #6/99
[2022-06-01 18:51:10,813]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,312]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,313]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,313]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,343]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,343]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,344]     INFO Processing #8/99
[2022-06-01 18:51:11,344]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,374]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,374]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,375]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,402]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,402]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,402]     INFO Processing #10/99
[2022-06-01 18:51:11,402]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,432]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,433]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,433]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,463]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,464]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,464]     INFO Processing #12/99
[2022-06-01 18:51:11,464]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,493]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,493]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,494]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,525]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,525]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,526]     INFO Processing #14/99
[2022-06-01 18:51:11,526]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,557]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,558]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,558]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,584]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,584]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,585]     INFO Processing #16/99
[2022-06-01 18:51:11,585]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,629]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,629]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,629]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,657]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,657]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,658]     INFO Processing #18/99
[2022-06-01 18:51:11,658]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,689]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,690]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,690]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,735]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,736]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,736]     INFO Processing #20/99
[2022-06-01 18:51:11,736]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,750]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,751]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,751]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,785]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,785]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,785]     INFO Processing #22/99
[2022-06-01 18:51:11,786]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,811]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,811]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,811]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,842]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,842]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,842]     INFO Processing #24/99
[2022-06-01 18:51:11,843]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,877]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,877]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,877]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,908]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,909]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,910]     INFO Processing #26/99
[2022-06-01 18:51:11,910]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,930]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,930]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,930]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,958]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,958]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,958]     INFO Processing #28/99
[2022-06-01 18:51:11,959]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:11,988]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:11,989]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:11,989]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,019]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,019]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,020]     INFO Processing #30/99
[2022-06-01 18:51:12,020]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,049]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,049]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,049]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,079]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,079]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,079]     INFO Processing #32/99
[2022-06-01 18:51:12,080]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,126]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,126]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,126]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,155]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,155]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,155]     INFO Processing #34/99
[2022-06-01 18:51:12,156]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,184]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,184]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,185]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,215]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,215]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,215]     INFO Processing #36/99
[2022-06-01 18:51:12,216]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,245]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,245]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,246]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,275]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,275]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,275]     INFO Processing #38/99
[2022-06-01 18:51:12,276]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,308]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,309]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,309]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,335]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,335]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,335]     INFO Processing #40/99
[2022-06-01 18:51:12,335]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,364]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,365]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,365]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,405]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,406]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,406]     INFO Processing #42/99
[2022-06-01 18:51:12,406]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,425]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,425]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,425]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,454]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,454]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,455]     INFO Processing #44/99
[2022-06-01 18:51:12,455]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,485]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,485]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,485]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,515]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,516]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,516]     INFO Processing #46/99
[2022-06-01 18:51:12,516]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,546]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,547]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,547]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,576]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,576]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,576]     INFO Processing #48/99
[2022-06-01 18:51:12,577]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,611]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,612]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,612]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,638]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,638]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,639]     INFO Processing #50/99
[2022-06-01 18:51:12,639]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,668]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,669]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,669]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,701]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,701]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,701]     INFO Processing #52/99
[2022-06-01 18:51:12,702]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,730]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,730]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,730]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,763]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,763]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,764]     INFO Processing #54/99
[2022-06-01 18:51:12,764]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,790]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,791]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,791]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,820]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,821]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,821]     INFO Processing #56/99
[2022-06-01 18:51:12,821]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,850]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,851]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,851]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,881]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,881]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,881]     INFO Processing #58/99
[2022-06-01 18:51:12,881]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,918]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,919]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,920]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,940]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,941]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,941]     INFO Processing #60/99
[2022-06-01 18:51:12,941]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:12,972]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:12,972]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:12,972]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,003]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,003]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,004]     INFO Processing #62/99
[2022-06-01 18:51:13,004]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,034]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,034]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,034]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,064]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,064]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,065]     INFO Processing #64/99
[2022-06-01 18:51:13,065]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,096]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,097]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,097]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,129]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,129]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,130]     INFO Processing #66/99
[2022-06-01 18:51:13,130]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,159]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,159]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,159]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,189]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,189]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,190]     INFO Processing #68/99
[2022-06-01 18:51:13,190]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,220]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,220]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,220]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,249]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,250]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,250]     INFO Processing #70/99
[2022-06-01 18:51:13,250]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,281]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,281]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,281]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,312]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,313]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,313]     INFO Processing #72/99
[2022-06-01 18:51:13,313]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,348]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,348]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,349]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,372]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,372]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,373]     INFO Processing #74/99
[2022-06-01 18:51:13,373]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,405]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,405]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,405]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,437]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,437]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,438]     INFO Processing #76/99
[2022-06-01 18:51:13,438]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,466]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,467]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,467]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,493]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,494]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,494]     INFO Processing #78/99
[2022-06-01 18:51:13,494]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,524]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,526]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,528]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,554]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,554]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,555]     INFO Processing #80/99
[2022-06-01 18:51:13,555]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,586]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,586]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,587]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,628]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,628]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,628]     INFO Processing #82/99
[2022-06-01 18:51:13,628]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,658]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,658]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,658]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,688]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,688]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,688]     INFO Processing #84/99
[2022-06-01 18:51:13,689]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,718]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,718]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,719]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,749]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,749]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,750]     INFO Processing #86/99
[2022-06-01 18:51:13,750]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,779]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,779]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,779]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,808]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,809]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,809]     INFO Processing #88/99
[2022-06-01 18:51:13,809]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,838]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,839]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,839]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,869]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,869]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,869]     INFO Processing #90/99
[2022-06-01 18:51:13,869]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,899]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,899]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,900]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,929]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,929]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,930]     INFO Processing #92/99
[2022-06-01 18:51:13,930]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,959]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,959]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,959]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:13,988]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:13,988]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:13,989]     INFO Processing #94/99
[2022-06-01 18:51:13,989]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:14,018]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:14,018]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:14,018]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:14,048]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:14,048]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:14,049]     INFO Processing #96/99
[2022-06-01 18:51:14,049]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:14,079]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:14,079]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:14,080]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:14,122]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:14,123]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:51:14,123]     INFO Processing #98/99
[2022-06-01 18:51:14,123]     INFO Configuring defensive HTML source session
[2022-06-01 18:51:14,152]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:51:14,152]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 244, in _configure_session
    raise exc
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 260, in driver
    return self._driver
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:54:39,939]     INFO Configuring defensive HTML source session
[2022-06-01 18:54:44,161]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298
[2022-06-01 18:54:44,161]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298)
[2022-06-01 18:54:46,894]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298
[2022-06-01 18:54:46,895]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298)
[2022-06-01 18:54:50,905]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298
[2022-06-01 18:54:50,905]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298)
[2022-06-01 18:54:50,907]     ERROR Driver initialisation failed
[2022-06-01 18:54:50,907]     INFO Configuring defensive HTML source session
[2022-06-01 18:54:52,644]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/10.1002/sd.2327?af=R
[2022-06-01 18:54:52,644]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/10.1002/sd.2327?af=R)
[2022-06-01 18:54:56,623]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:54:56,624]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 45, in inner
    resp = func(scraper, *args, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 56, in inner
    return driver._chrome.compose_response()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 123, in compose_response
    self.get_cookies())
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 1079, in get_cookies
    return self.execute(Command.GET_ALL_COOKIES)['value']
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py", line 428, in execute
    response = self.command_executor.execute(driver_command, params)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 347, in execute
    return self._request(command_info[0], url, body=data)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py", line 395, in _request
    data = utils.load_json(data.strip())
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/selenium/webdriver/remote/utils.py", line 27, in load_json
    return json.loads(s)
  File "/usr/local/lib/python3.8/json/__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.8/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.8/json/decoder.py", line 353, in raw_decode
    obj, end = self.scan_once(s, idx)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:54:56,630]     INFO Processing #2/99
[2022-06-01 18:54:56,630]     INFO Configuring defensive HTML source session
[2022-06-01 18:54:56,632]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b044f280>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:54:57,298]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:54:57,298]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:54:57,298]     INFO Configuring defensive HTML source session
[2022-06-01 18:54:57,300]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b041e400>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:54:58,306]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b044fe20>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:54:59,315]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b044f640>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:54:59,317]     ERROR Driver initialisation failed
[2022-06-01 18:54:59,319]     INFO Processing #4/99
[2022-06-01 18:54:59,320]     INFO Configuring defensive HTML source session
[2022-06-01 18:54:59,325]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b044f490>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:00,330]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d2070>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:00,583]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:00,583]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:00,583]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:00,586]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d9910>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,084]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,084]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,084]     INFO Processing #6/99
[2022-06-01 18:55:01,084]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,087]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b0526160>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,115]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,115]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,115]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,118]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b05c1850>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,144]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,144]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,144]     INFO Processing #8/99
[2022-06-01 18:55:01,145]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,147]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b0556430>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,174]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,175]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,175]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,177]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d2580>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,205]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,205]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,206]     INFO Processing #10/99
[2022-06-01 18:55:01,206]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,208]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b0556e20>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,235]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,235]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,236]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,238]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b044fd90>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,265]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,265]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,265]     INFO Processing #12/99
[2022-06-01 18:55:01,266]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,268]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b044f520>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,295]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,296]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,296]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,298]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b0556eb0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,336]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,336]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,336]     INFO Processing #14/99
[2022-06-01 18:55:01,337]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,341]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04f23a0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,355]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,355]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,356]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,360]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b044f5b0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,385]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,385]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,386]     INFO Processing #16/99
[2022-06-01 18:55:01,386]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,388]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d2070>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,415]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,416]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,416]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,418]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d2070>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,446]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,447]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,447]     INFO Processing #18/99
[2022-06-01 18:55:01,447]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,450]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b05c1580>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,489]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,489]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,489]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,492]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b041c4f0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,518]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,518]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,519]     INFO Processing #20/99
[2022-06-01 18:55:01,519]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,521]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b041cd90>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,548]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,549]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,549]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,551]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d9280>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,580]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,580]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,580]     INFO Processing #22/99
[2022-06-01 18:55:01,580]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,583]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b041c850>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,608]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,609]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,609]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,611]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d9820>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,638]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,638]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,639]     INFO Processing #24/99
[2022-06-01 18:55:01,639]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,641]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b041e400>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,669]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,670]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,670]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,672]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d9670>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,700]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,700]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,700]     INFO Processing #26/99
[2022-06-01 18:55:01,701]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,703]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b041eca0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,732]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,733]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,733]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,735]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d9520>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,760]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,760]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,761]     INFO Processing #28/99
[2022-06-01 18:55:01,761]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,763]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b047c070>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,790]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,791]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,791]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,794]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b0512190>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,820]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,821]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,821]     INFO Processing #30/99
[2022-06-01 18:55:01,821]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,823]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b047ce80>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,851]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,851]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,851]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,853]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04fd0a0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,881]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,882]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,882]     INFO Processing #32/99
[2022-06-01 18:55:01,882]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,884]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d9280>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,912]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,912]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,912]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,915]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04cfee0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,944]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,944]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,945]     INFO Processing #34/99
[2022-06-01 18:55:01,945]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,949]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04cf7c0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:01,985]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:01,986]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:01,986]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:01,989]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b0423af0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,017]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,017]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,017]     INFO Processing #36/99
[2022-06-01 18:55:02,018]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,020]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04236d0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,047]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,047]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,048]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,050]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b0540100>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,077]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,077]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,078]     INFO Processing #38/99
[2022-06-01 18:55:02,078]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,084]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d2cd0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,107]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,108]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,108]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,112]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b0423be0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,137]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,137]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,138]     INFO Processing #40/99
[2022-06-01 18:55:02,138]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,140]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b041ec70>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,169]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,170]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,170]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,172]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d2820>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,198]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,198]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,199]     INFO Processing #42/99
[2022-06-01 18:55:02,199]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,201]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d29a0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,227]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,228]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,228]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,230]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d9820>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,258]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,258]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,259]     INFO Processing #44/99
[2022-06-01 18:55:02,259]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,262]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d9eb0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,290]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,290]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,290]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,292]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b041ec10>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,318]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,318]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,318]     INFO Processing #46/99
[2022-06-01 18:55:02,319]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,321]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04cb910>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,349]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,349]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,349]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,351]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d9490>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,378]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,379]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,380]     INFO Processing #48/99
[2022-06-01 18:55:02,380]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,382]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04f28e0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,410]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,410]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,411]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,414]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b05568b0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,438]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,438]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,438]     INFO Processing #50/99
[2022-06-01 18:55:02,438]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,445]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b05123d0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,485]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,485]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,485]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,489]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b044faf0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,514]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,514]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,514]     INFO Processing #52/99
[2022-06-01 18:55:02,514]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,517]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04c48b0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,543]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,544]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,544]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,546]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b044f910>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,573]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,574]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,574]     INFO Processing #54/99
[2022-06-01 18:55:02,574]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,577]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04c49d0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,603]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,603]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,604]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,606]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b044fee0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,633]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,634]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,634]     INFO Processing #56/99
[2022-06-01 18:55:02,634]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,637]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04232b0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,664]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,664]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,665]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,667]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d9820>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,694]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,695]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,695]     INFO Processing #58/99
[2022-06-01 18:55:02,695]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,697]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b0423850>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,724]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,724]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,725]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,728]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b044f580>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,754]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,754]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,755]     INFO Processing #60/99
[2022-06-01 18:55:02,755]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,757]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b05123a0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,786]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,786]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,786]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,789]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b047cf40>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,816]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,816]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,817]     INFO Processing #62/99
[2022-06-01 18:55:02,817]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,819]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b0526a00>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,845]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,845]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,846]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,849]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b047c610>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,875]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,876]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,877]     INFO Processing #64/99
[2022-06-01 18:55:02,879]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,881]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b047cf10>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,905]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,905]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,906]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,910]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04c5fd0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,935]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,935]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,936]     INFO Processing #66/99
[2022-06-01 18:55:02,936]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,938]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04cfd90>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,968]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,968]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,968]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:02,972]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04c49d0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:02,997]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:02,997]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:02,997]     INFO Processing #68/99
[2022-06-01 18:55:02,998]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,000]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04c5640>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,027]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,027]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,028]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,031]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04cfe50>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,057]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,058]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,058]     INFO Processing #70/99
[2022-06-01 18:55:03,058]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,061]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b047c9a0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,088]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,089]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,089]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,127]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b05d86a0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,148]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,148]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,149]     INFO Processing #72/99
[2022-06-01 18:55:03,149]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,151]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04c5f40>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,178]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,179]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,179]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,182]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b047c070>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,209]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,209]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,210]     INFO Processing #74/99
[2022-06-01 18:55:03,210]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,212]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b05562e0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,238]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,238]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,238]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,241]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b03f23d0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,268]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,268]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,269]     INFO Processing #76/99
[2022-06-01 18:55:03,269]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,271]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b0596220>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,302]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,302]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,302]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,304]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b03f2b80>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,329]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,329]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,329]     INFO Processing #78/99
[2022-06-01 18:55:03,329]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,332]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b03f25e0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,359]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,359]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,359]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,362]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04f2610>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,389]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,389]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,389]     INFO Processing #80/99
[2022-06-01 18:55:03,389]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,391]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b044f790>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,420]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,420]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,421]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,423]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b03f2cd0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,451]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,451]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,452]     INFO Processing #82/99
[2022-06-01 18:55:03,452]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,454]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b044fdf0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,491]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,491]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,491]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,494]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04f2220>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,520]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,521]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,521]     INFO Processing #84/99
[2022-06-01 18:55:03,521]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,523]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04cbaf0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,550]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,550]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,551]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,553]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b041e040>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,581]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,581]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,581]     INFO Processing #86/99
[2022-06-01 18:55:03,582]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,584]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b044f3a0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,612]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,613]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,613]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,615]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b041e730>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,641]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,641]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,641]     INFO Processing #88/99
[2022-06-01 18:55:03,641]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,644]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b03f29a0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,674]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,675]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,675]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,677]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d9f10>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,703]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,703]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,703]     INFO Processing #90/99
[2022-06-01 18:55:03,703]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,706]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b03f29a0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,735]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,735]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,736]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,738]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04d97f0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,762]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,763]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,763]     INFO Processing #92/99
[2022-06-01 18:55:03,763]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,767]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04fdeb0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,793]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,793]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,793]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,797]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b041ed60>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,821]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,822]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,822]     INFO Processing #94/99
[2022-06-01 18:55:03,822]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,825]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b048b640>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,852]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,852]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,852]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,855]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b041ed30>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,884]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,884]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,885]     INFO Processing #96/99
[2022-06-01 18:55:03,885]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,887]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04fde80>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,914]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,914]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,914]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,917]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b05c14c0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,944]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,946]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 18:55:03,946]     INFO Processing #98/99
[2022-06-01 18:55:03,947]     INFO Configuring defensive HTML source session
[2022-06-01 18:55:03,952]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=46521): Max retries exceeded with url: /session/8b996c28f50927c249f5453df5ccf6a1/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f85b04fda90>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 18:55:03,987]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 18:55:03,987]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:01:16,544]     INFO Configuring defensive HTML source session
[2022-06-01 19:01:21,535]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298
[2022-06-01 19:01:21,535]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298)
[2022-06-01 19:01:24,093]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298
[2022-06-01 19:01:24,093]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298)
[2022-06-01 19:01:27,771]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298
[2022-06-01 19:01:27,772]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298)
[2022-06-01 19:01:27,784]     ERROR Driver initialisation failed
[2022-06-01 19:02:37,941]     INFO Configuring defensive HTML source session
[2022-06-01 19:02:49,276]     ERROR Driver initialisation failed
[2022-06-01 19:02:49,276]     INFO Configuring defensive HTML source session
[2022-06-01 19:02:50,820]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:02:50,820]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 254, in driver
    self._driver = Driver.get_or_create(
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 77, in get_or_create
    _instances.append(cls(**settings))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 65, in __init__
    self._chrome = Chrome(**self._settings, host=next(self._hosts))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 54, in __init__
    self._init_driver()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 60, in _init_driver
    chrome_cls.__init__(self, **self._configure_init_kwargs())
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/seleniumwire/undetected_chromedriver/webdriver.py", line 61, in __init__
    super().__init__(*args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 233, in __init__
    patcher.auto()
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 130, in auto
    self.unzip_package(self.fetch_package())
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 166, in fetch_package
    return urlretrieve(u)[0]
  File "/usr/local/lib/python3.8/urllib/request.py", line 276, in urlretrieve
    block = fp.read(bs)
  File "/usr/local/lib/python3.8/http/client.py", line 459, in read
    n = self.readinto(b)
  File "/usr/local/lib/python3.8/http/client.py", line 503, in readinto
    n = self.fp.readinto(b)
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/local/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:02:50,825]     INFO Processing #2/99
[2022-06-01 19:02:50,825]     INFO Configuring defensive HTML source session
[2022-06-01 19:02:51,000]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:02:51,000]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 254, in driver
    self._driver = Driver.get_or_create(
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 77, in get_or_create
    _instances.append(cls(**settings))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 65, in __init__
    self._chrome = Chrome(**self._settings, host=next(self._hosts))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 54, in __init__
    self._init_driver()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 60, in _init_driver
    chrome_cls.__init__(self, **self._configure_init_kwargs())
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/seleniumwire/undetected_chromedriver/webdriver.py", line 61, in __init__
    super().__init__(*args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 233, in __init__
    patcher.auto()
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 127, in auto
    release = self.fetch_release_number()
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 148, in fetch_release_number
    return LooseVersion(urlopen(self.url_repo + path).read().decode())
  File "/usr/local/lib/python3.8/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/usr/local/lib/python3.8/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/usr/local/lib/python3.8/urllib/request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "/usr/local/lib/python3.8/urllib/request.py", line 502, in _call_chain
    result = func(*args)
  File "/usr/local/lib/python3.8/urllib/request.py", line 1397, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "/usr/local/lib/python3.8/urllib/request.py", line 1354, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/usr/local/lib/python3.8/http/client.py", line 1418, in connect
    super().connect()
  File "/usr/local/lib/python3.8/http/client.py", line 922, in connect
    self.sock = self._create_connection(
  File "/usr/local/lib/python3.8/socket.py", line 796, in create_connection
    sock.connect(sa)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:02:51,150]     INFO Configuring defensive HTML source session
[2022-06-01 19:02:51,495]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:02:51,495]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 254, in driver
    self._driver = Driver.get_or_create(
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 77, in get_or_create
    _instances.append(cls(**settings))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 65, in __init__
    self._chrome = Chrome(**self._settings, host=next(self._hosts))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 54, in __init__
    self._init_driver()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 60, in _init_driver
    chrome_cls.__init__(self, **self._configure_init_kwargs())
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/seleniumwire/undetected_chromedriver/webdriver.py", line 61, in __init__
    super().__init__(*args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 233, in __init__
    patcher.auto()
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 127, in auto
    release = self.fetch_release_number()
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 148, in fetch_release_number
    return LooseVersion(urlopen(self.url_repo + path).read().decode())
  File "/usr/local/lib/python3.8/urllib/request.py", line 222, in urlopen
    return opener.open(url, data, timeout)
  File "/usr/local/lib/python3.8/urllib/request.py", line 525, in open
    response = self._open(req, data)
  File "/usr/local/lib/python3.8/urllib/request.py", line 542, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
  File "/usr/local/lib/python3.8/urllib/request.py", line 502, in _call_chain
    result = func(*args)
  File "/usr/local/lib/python3.8/urllib/request.py", line 1397, in https_open
    return self.do_open(http.client.HTTPSConnection, req,
  File "/usr/local/lib/python3.8/urllib/request.py", line 1354, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "/usr/local/lib/python3.8/http/client.py", line 1256, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1302, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1251, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "/usr/local/lib/python3.8/http/client.py", line 1011, in _send_output
    self.send(msg)
  File "/usr/local/lib/python3.8/http/client.py", line 951, in send
    self.connect()
  File "/usr/local/lib/python3.8/http/client.py", line 1418, in connect
    super().connect()
  File "/usr/local/lib/python3.8/http/client.py", line 922, in connect
    self.sock = self._create_connection(
  File "/usr/local/lib/python3.8/socket.py", line 796, in create_connection
    sock.connect(sa)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:02:51,496]     INFO Processing #4/99
[2022-06-01 19:02:51,750]     INFO Configuring defensive HTML source session
[2022-06-01 19:02:52,110]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:02:52,110]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 254, in driver
    self._driver = Driver.get_or_create(
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 77, in get_or_create
    _instances.append(cls(**settings))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 65, in __init__
    self._chrome = Chrome(**self._settings, host=next(self._hosts))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 54, in __init__
    self._init_driver()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 60, in _init_driver
    chrome_cls.__init__(self, **self._configure_init_kwargs())
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/seleniumwire/undetected_chromedriver/webdriver.py", line 61, in __init__
    super().__init__(*args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 233, in __init__
    patcher.auto()
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 130, in auto
    self.unzip_package(self.fetch_package())
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 166, in fetch_package
    return urlretrieve(u)[0]
  File "/usr/local/lib/python3.8/urllib/request.py", line 276, in urlretrieve
    block = fp.read(bs)
  File "/usr/local/lib/python3.8/http/client.py", line 459, in read
    n = self.readinto(b)
  File "/usr/local/lib/python3.8/http/client.py", line 503, in readinto
    n = self.fp.readinto(b)
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/local/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:02:52,501]     INFO Configuring defensive HTML source session
[2022-06-01 19:02:52,935]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:02:52,935]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 254, in driver
    self._driver = Driver.get_or_create(
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 77, in get_or_create
    _instances.append(cls(**settings))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/driver.py", line 65, in __init__
    self._chrome = Chrome(**self._settings, host=next(self._hosts))
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 54, in __init__
    self._init_driver()
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/utils/chrome.py", line 60, in _init_driver
    chrome_cls.__init__(self, **self._configure_init_kwargs())
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/seleniumwire/undetected_chromedriver/webdriver.py", line 61, in __init__
    super().__init__(*args, **kwargs)
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/undetected_chromedriver/__init__.py", line 233, in __init__
    patcher.auto()
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 130, in auto
    self.unzip_package(self.fetch_package())
  File "/home/gravy/.local/share/virtualenvs/backend-gbEKCDLf/lib/python3.8/site-packages/undetected_chromedriver/patcher.py", line 166, in fetch_package
    return urlretrieve(u)[0]
  File "/usr/local/lib/python3.8/urllib/request.py", line 276, in urlretrieve
    block = fp.read(bs)
  File "/usr/local/lib/python3.8/http/client.py", line 459, in read
    n = self.readinto(b)
  File "/usr/local/lib/python3.8/http/client.py", line 503, in readinto
    n = self.fp.readinto(b)
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/usr/local/lib/python3.8/ssl.py", line 1241, in recv_into
    return self.read(nbytes, buffer)
  File "/usr/local/lib/python3.8/ssl.py", line 1099, in read
    return self._sslobj.read(len, buffer)
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:02:52,936]     INFO Processing #6/99
[2022-06-01 19:02:55,943]     INFO Configuring defensive HTML source session
[2022-06-01 19:03:00,184]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/10.1111/ajt.16657?af=R
[2022-06-01 19:03:00,184]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/10.1111/ajt.16657?af=R)
[2022-06-01 19:03:00,273]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:03:00,273]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:03:00,429]     INFO Configuring defensive HTML source session
[2022-06-01 19:03:00,431]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=35537): Max retries exceeded with url: /session/ee8007247bcd7fba7370eddb7e9ede4d/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6e9ff7da90>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 19:03:00,569]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:03:00,569]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:03:00,570]     INFO Processing #8/99
[2022-06-01 19:03:00,570]     INFO Configuring defensive HTML source session
[2022-06-01 19:03:00,575]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=35537): Max retries exceeded with url: /session/ee8007247bcd7fba7370eddb7e9ede4d/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6e9ff31940>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 19:03:00,814]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:03:00,814]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:03:00,814]     INFO Configuring defensive HTML source session
[2022-06-01 19:03:00,817]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=35537): Max retries exceeded with url: /session/ee8007247bcd7fba7370eddb7e9ede4d/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6e9ff31970>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 19:03:00,918]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:03:00,919]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:03:00,920]     INFO Processing #10/99
[2022-06-01 19:03:00,920]     INFO Configuring defensive HTML source session
[2022-06-01 19:03:00,926]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=35537): Max retries exceeded with url: /session/ee8007247bcd7fba7370eddb7e9ede4d/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6e9ff7dbb0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 19:03:01,185]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:03:01,186]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:03:01,186]     INFO Configuring defensive HTML source session
[2022-06-01 19:03:01,188]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=35537): Max retries exceeded with url: /session/ee8007247bcd7fba7370eddb7e9ede4d/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6e9ff16e80>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 19:03:01,580]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:03:01,580]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:03:01,581]     INFO Processing #12/99
[2022-06-01 19:03:01,581]     INFO Configuring defensive HTML source session
[2022-06-01 19:03:01,583]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=35537): Max retries exceeded with url: /session/ee8007247bcd7fba7370eddb7e9ede4d/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6e9ff7da00>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 19:03:01,617]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:03:01,618]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:03:01,618]     INFO Configuring defensive HTML source session
[2022-06-01 19:03:01,621]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=35537): Max retries exceeded with url: /session/ee8007247bcd7fba7370eddb7e9ede4d/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6e9ff7d6a0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 19:03:01,641]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:03:01,641]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:03:01,641]     INFO Processing #14/99
[2022-06-01 19:03:01,642]     INFO Configuring defensive HTML source session
[2022-06-01 19:03:01,644]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=35537): Max retries exceeded with url: /session/ee8007247bcd7fba7370eddb7e9ede4d/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6e9ff16190>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 19:03:01,674]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:03:01,674]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:03:01,675]     INFO Configuring defensive HTML source session
[2022-06-01 19:03:01,677]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=35537): Max retries exceeded with url: /session/ee8007247bcd7fba7370eddb7e9ede4d/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6e9d7944c0>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 19:03:01,701]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:03:01,702]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:03:01,702]     INFO Processing #16/99
[2022-06-01 19:03:01,702]     INFO Configuring defensive HTML source session
[2022-06-01 19:03:01,704]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=35537): Max retries exceeded with url: /session/ee8007247bcd7fba7370eddb7e9ede4d/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6ea4059910>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 19:03:01,733]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:03:01,733]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:03:01,733]     INFO Configuring defensive HTML source session
[2022-06-01 19:03:01,736]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=35537): Max retries exceeded with url: /session/ee8007247bcd7fba7370eddb7e9ede4d/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6e9d794430>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 19:03:01,764]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:03:01,765]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:03:01,765]     INFO Processing #18/99
[2022-06-01 19:03:01,765]     INFO Configuring defensive HTML source session
[2022-06-01 19:03:01,768]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=35537): Max retries exceeded with url: /session/ee8007247bcd7fba7370eddb7e9ede4d/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6ea4059280>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 19:03:01,820]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:03:01,820]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:03:01,820]     INFO Configuring defensive HTML source session
[2022-06-01 19:03:01,823]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=35537): Max retries exceeded with url: /session/ee8007247bcd7fba7370eddb7e9ede4d/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6e9d794c70>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 19:03:01,861]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:03:01,861]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:03:01,862]     INFO Processing #20/99
[2022-06-01 19:03:01,862]     INFO Configuring defensive HTML source session
[2022-06-01 19:03:01,864]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=35537): Max retries exceeded with url: /session/ee8007247bcd7fba7370eddb7e9ede4d/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6e9febfe80>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 19:03:01,985]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:03:01,985]     DEBUG Check traceback
Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 237, in _configure_session
    resp = self.driver.get(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/scrapers/scraper.py", line 49, in inner
    time.sleep(scraper._settings["request_retry_interval"])
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/common/pool.py", line 98, in _handle_task
    return func(*args, **kwargs), None
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/session.py", line 68, in scrape_url
    res = source.scrape_url(url, fields, **kwargs)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 224, in scrape_url
    return self._configure_session(url)
  File "/home/gravy/Dropbox/code/syllabus/tsutils/tsutils/scrape/source.py", line 249, in _configure_session
    return self._parse_response(resp, {})
UnboundLocalError: local variable 'resp' referenced before assignment
[2022-06-01 19:03:01,986]     INFO Configuring defensive HTML source session
[2022-06-01 19:03:01,988]     DEBUG Rotating host (HTTPConnectionPool(host='localhost', port=35537): Max retries exceeded with url: /session/ee8007247bcd7fba7370eddb7e9ede4d/execute/sync (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f6e9d794c10>: Failed to establish a new connection: [Errno 111] Connection refused')))
[2022-06-01 19:03:01,994]     INFO local variable 'resp' referenced before assignment raised and ignored while processing item
[2022-06-01 19:03:01,997]     INFO Processing #22/99
[2022-06-01 19:03:57,682]     INFO Configuring defensive HTML source session
[2022-06-01 19:04:03,846]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298
[2022-06-01 19:04:03,846]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298)
[2022-06-01 19:05:52,968]     INFO Configuring defensive HTML source session
[2022-06-01 19:05:59,361]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298
[2022-06-01 19:05:59,367]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298)
[2022-06-01 19:06:01,894]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298
[2022-06-01 19:06:01,894]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298)
[2022-06-01 19:06:04,394]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298
[2022-06-01 19:06:04,394]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298)
[2022-06-01 19:06:04,396]     ERROR Driver initialisation failed
[2022-06-01 19:06:04,396]     INFO Configuring defensive HTML source session
[2022-06-01 19:06:06,424]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/10.1002/sd.2327?af=R
[2022-06-01 19:06:06,424]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/10.1002/sd.2327?af=R)
[2022-06-01 19:06:09,720]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/10.1002/sd.2327?af=R
[2022-06-01 19:06:09,720]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/10.1002/sd.2327?af=R)
[2022-06-01 19:06:12,283]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/10.1002/sd.2327?af=R
[2022-06-01 19:06:12,283]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/10.1002/sd.2327?af=R)
[2022-06-01 19:06:12,285]     ERROR Driver initialisation failed
[2022-06-01 19:06:12,289]     INFO Processing #2/99
[2022-06-01 19:06:12,290]     INFO Configuring defensive HTML source session
[2022-06-01 19:09:23,920]     INFO Configuring defensive HTML source session
[2022-06-01 19:09:52,824]     DEBUG Request failed - 503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298
[2022-06-01 19:09:52,825]     DEBUG Rotating host (503 raised requesting https://onlinelibrary.wiley.com/doi/abs/10.1111/os.13298)
[2022-06-01 19:11:09,394]     INFO Configuring defensive HTML source session
[2022-06-01 19:11:18,251]     DEBUG Rotating host (Message: invalid selector: Unable to locate an element with the xpath expression //h1[@class="citation__title" because of the following error:
SyntaxError: Failed to execute 'evaluate' on 'Document': The string '//h1[@class="citation__title"' is not a valid XPath expression.
  (Session info: headless chrome=102.0.5005.61)
Stacktrace:
#0 0x55e5760fdf33 <unknown>
#1 0x55e575e48118 <unknown>
#2 0x55e575e4af97 <unknown>
#3 0x55e575e4ae3b <unknown>
#4 0x55e575e4b0fc <unknown>
#5 0x55e575e7e11e <unknown>
#6 0x55e575e7e5c1 <unknown>
#7 0x55e575eb15c4 <unknown>
#8 0x55e575e9bf9d <unknown>
#9 0x55e575eaf2e4 <unknown>
#10 0x55e575e9be63 <unknown>
#11 0x55e575e7182a <unknown>
#12 0x55e575e72985 <unknown>
#13 0x55e5761424cd <unknown>
#14 0x55e5761465ec <unknown>
#15 0x55e57612c71e <unknown>
#16 0x55e576147238 <unknown>
#17 0x55e576121870 <unknown>
#18 0x55e576163608 <unknown>
#19 0x55e576163788 <unknown>
#20 0x55e57617df1d <unknown>
#21 0x7fc229adb947 <unknown>
)
[2022-06-01 19:11:34,622]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:04,327]     ERROR 
[2022-06-01 19:12:04,328]     DEBUG See traceback
NoneType: None
[2022-06-01 19:12:04,328]     DEBUG Rotating host ()
[2022-06-01 19:12:51,241]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,914]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,914]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,914]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,914]     INFO Processing #2/99
[2022-06-01 19:12:52,915]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,921]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,922]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,924]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,924]     INFO Processing #4/99
[2022-06-01 19:12:52,924]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,925]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,925]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,925]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,925]     INFO Processing #6/99
[2022-06-01 19:12:52,925]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,926]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,926]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,927]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,927]     INFO Processing #8/99
[2022-06-01 19:12:52,927]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,927]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,928]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,928]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,928]     INFO Processing #10/99
[2022-06-01 19:12:52,928]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,928]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,928]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,929]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,929]     INFO Processing #12/99
[2022-06-01 19:12:52,929]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,929]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,929]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,929]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,930]     INFO Processing #14/99
[2022-06-01 19:12:52,931]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,932]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,932]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,933]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,933]     INFO Processing #16/99
[2022-06-01 19:12:52,934]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,934]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,935]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,936]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,936]     INFO Processing #18/99
[2022-06-01 19:12:52,936]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,937]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,937]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,938]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,938]     INFO Processing #20/99
[2022-06-01 19:12:52,939]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,939]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,939]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,940]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,941]     INFO Processing #22/99
[2022-06-01 19:12:52,941]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,941]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,942]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,943]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,943]     INFO Processing #24/99
[2022-06-01 19:12:52,945]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,945]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,945]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,946]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,947]     INFO Processing #26/99
[2022-06-01 19:12:52,947]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,948]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,948]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,949]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,949]     INFO Processing #28/99
[2022-06-01 19:12:52,949]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,950]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,950]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,950]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,951]     INFO Processing #30/99
[2022-06-01 19:12:52,951]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,951]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,952]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,952]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,952]     INFO Processing #32/99
[2022-06-01 19:12:52,953]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,953]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,953]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,954]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,954]     INFO Processing #34/99
[2022-06-01 19:12:52,954]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,954]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,955]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,955]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,956]     INFO Processing #36/99
[2022-06-01 19:12:52,957]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,957]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,958]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,958]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,958]     INFO Processing #38/99
[2022-06-01 19:12:52,959]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,959]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,959]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,960]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,961]     INFO Processing #40/99
[2022-06-01 19:12:52,961]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,961]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,962]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,962]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,962]     INFO Processing #42/99
[2022-06-01 19:12:52,963]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,963]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,963]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,964]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,964]     INFO Processing #44/99
[2022-06-01 19:12:52,964]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,964]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,965]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,965]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,965]     INFO Processing #46/99
[2022-06-01 19:12:52,966]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,966]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,966]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,966]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,967]     INFO Processing #48/99
[2022-06-01 19:12:52,967]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,967]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,968]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,968]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,968]     INFO Processing #50/99
[2022-06-01 19:12:52,968]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,969]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,969]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,969]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,970]     INFO Processing #52/99
[2022-06-01 19:12:52,970]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,970]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,971]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,971]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,971]     INFO Processing #54/99
[2022-06-01 19:12:52,972]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,972]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,972]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,973]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,973]     INFO Processing #56/99
[2022-06-01 19:12:52,973]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,973]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,974]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,974]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,974]     INFO Processing #58/99
[2022-06-01 19:12:52,975]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,975]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,975]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,976]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,976]     INFO Processing #60/99
[2022-06-01 19:12:52,976]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,976]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,977]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,977]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,977]     INFO Processing #62/99
[2022-06-01 19:12:52,978]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,978]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,978]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,978]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,979]     INFO Processing #64/99
[2022-06-01 19:12:52,979]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,979]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,980]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,980]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,980]     INFO Processing #66/99
[2022-06-01 19:12:52,981]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,981]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,981]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,982]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,982]     INFO Processing #68/99
[2022-06-01 19:12:52,982]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,983]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,983]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,983]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,983]     INFO Processing #70/99
[2022-06-01 19:12:52,984]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,984]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,984]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,985]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,985]     INFO Processing #72/99
[2022-06-01 19:12:52,985]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,985]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,986]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,986]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,986]     INFO Processing #74/99
[2022-06-01 19:12:52,987]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,987]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,987]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,988]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,988]     INFO Processing #76/99
[2022-06-01 19:12:52,988]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,988]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,989]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,989]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,989]     INFO Processing #78/99
[2022-06-01 19:12:52,990]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,990]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,990]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,991]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,991]     INFO Processing #80/99
[2022-06-01 19:12:52,991]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,992]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,992]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,992]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,992]     INFO Processing #82/99
[2022-06-01 19:12:52,993]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,993]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,993]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,994]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,994]     INFO Processing #84/99
[2022-06-01 19:12:52,994]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,994]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,995]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,995]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,995]     INFO Processing #86/99
[2022-06-01 19:12:52,996]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,996]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,996]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,996]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,997]     INFO Processing #88/99
[2022-06-01 19:12:52,997]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,997]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,998]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,998]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,998]     INFO Processing #90/99
[2022-06-01 19:12:52,999]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,999]     ERROR Driver initialisation failed
[2022-06-01 19:12:52,999]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:52,999]     ERROR Driver initialisation failed
[2022-06-01 19:12:53,000]     INFO Processing #92/99
[2022-06-01 19:12:53,000]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:53,000]     ERROR Driver initialisation failed
[2022-06-01 19:12:53,001]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:53,001]     ERROR Driver initialisation failed
[2022-06-01 19:12:53,001]     INFO Processing #94/99
[2022-06-01 19:12:53,002]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:53,002]     ERROR Driver initialisation failed
[2022-06-01 19:12:53,002]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:53,002]     ERROR Driver initialisation failed
[2022-06-01 19:12:53,003]     INFO Processing #96/99
[2022-06-01 19:12:53,003]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:53,003]     ERROR Driver initialisation failed
[2022-06-01 19:12:53,003]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:53,004]     ERROR Driver initialisation failed
[2022-06-01 19:12:53,004]     INFO Processing #98/99
[2022-06-01 19:12:53,004]     INFO Configuring defensive HTML source session
[2022-06-01 19:12:53,004]     ERROR Driver initialisation failed
[2022-06-01 19:13:11,984]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,789]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,789]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,789]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,790]     INFO Processing #2/99
[2022-06-01 19:13:13,790]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,790]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,791]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,791]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,791]     INFO Processing #4/99
[2022-06-01 19:13:13,791]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,792]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,792]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,792]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,792]     INFO Processing #6/99
[2022-06-01 19:13:13,793]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,793]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,793]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,793]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,794]     INFO Processing #8/99
[2022-06-01 19:13:13,794]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,794]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,795]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,795]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,795]     INFO Processing #10/99
[2022-06-01 19:13:13,795]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,796]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,796]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,797]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,798]     INFO Processing #12/99
[2022-06-01 19:13:13,799]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,799]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,800]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,801]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,802]     INFO Processing #14/99
[2022-06-01 19:13:13,802]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,803]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,804]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,805]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,805]     INFO Processing #16/99
[2022-06-01 19:13:13,806]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,806]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,807]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,807]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,808]     INFO Processing #18/99
[2022-06-01 19:13:13,808]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,809]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,809]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,810]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,811]     INFO Processing #20/99
[2022-06-01 19:13:13,811]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,812]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,812]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,813]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,814]     INFO Processing #22/99
[2022-06-01 19:13:13,814]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,815]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,816]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,817]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,819]     INFO Processing #24/99
[2022-06-01 19:13:13,819]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,820]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,821]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,821]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,822]     INFO Processing #26/99
[2022-06-01 19:13:13,823]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,823]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,824]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,824]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,825]     INFO Processing #28/99
[2022-06-01 19:13:13,825]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,826]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,827]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,827]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,828]     INFO Processing #30/99
[2022-06-01 19:13:13,828]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,829]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,829]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,829]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,830]     INFO Processing #32/99
[2022-06-01 19:13:13,830]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,830]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,831]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,831]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,832]     INFO Processing #34/99
[2022-06-01 19:13:13,832]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,832]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,833]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,833]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,834]     INFO Processing #36/99
[2022-06-01 19:13:13,834]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,834]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,834]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,835]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,835]     INFO Processing #38/99
[2022-06-01 19:13:13,835]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,836]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,836]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,836]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,837]     INFO Processing #40/99
[2022-06-01 19:13:13,837]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,837]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,838]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,838]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,838]     INFO Processing #42/99
[2022-06-01 19:13:13,839]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,839]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,839]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,839]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,840]     INFO Processing #44/99
[2022-06-01 19:13:13,840]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,840]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,840]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,841]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,841]     INFO Processing #46/99
[2022-06-01 19:13:13,841]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,842]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,842]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,842]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,842]     INFO Processing #48/99
[2022-06-01 19:13:13,843]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,843]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,843]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,844]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,844]     INFO Processing #50/99
[2022-06-01 19:13:13,844]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,844]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,845]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,845]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,845]     INFO Processing #52/99
[2022-06-01 19:13:13,845]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,846]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,846]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,846]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,846]     INFO Processing #54/99
[2022-06-01 19:13:13,847]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,847]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,847]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,847]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,848]     INFO Processing #56/99
[2022-06-01 19:13:13,848]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,848]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,848]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,849]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,849]     INFO Processing #58/99
[2022-06-01 19:13:13,849]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,850]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,850]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,850]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,850]     INFO Processing #60/99
[2022-06-01 19:13:13,851]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,851]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,851]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,851]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,852]     INFO Processing #62/99
[2022-06-01 19:13:13,852]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,852]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,852]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,853]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,853]     INFO Processing #64/99
[2022-06-01 19:13:13,853]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,853]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,854]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,854]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,854]     INFO Processing #66/99
[2022-06-01 19:13:13,854]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,855]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,855]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,855]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,855]     INFO Processing #68/99
[2022-06-01 19:13:13,855]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,856]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,856]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,856]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,856]     INFO Processing #70/99
[2022-06-01 19:13:13,857]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,857]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,857]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,857]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,858]     INFO Processing #72/99
[2022-06-01 19:13:13,858]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,858]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,859]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,859]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,859]     INFO Processing #74/99
[2022-06-01 19:13:13,859]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,860]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,860]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,860]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,860]     INFO Processing #76/99
[2022-06-01 19:13:13,861]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,861]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,861]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,861]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,862]     INFO Processing #78/99
[2022-06-01 19:13:13,862]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,862]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,862]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,863]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,863]     INFO Processing #80/99
[2022-06-01 19:13:13,863]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,863]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,864]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,864]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,864]     INFO Processing #82/99
[2022-06-01 19:13:13,864]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,865]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,865]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,865]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,865]     INFO Processing #84/99
[2022-06-01 19:13:13,865]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,866]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,866]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,866]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,866]     INFO Processing #86/99
[2022-06-01 19:13:13,866]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,866]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,867]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,867]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,867]     INFO Processing #88/99
[2022-06-01 19:13:13,867]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,867]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,868]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,868]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,868]     INFO Processing #90/99
[2022-06-01 19:13:13,868]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,868]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,868]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,869]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,869]     INFO Processing #92/99
[2022-06-01 19:13:13,869]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,869]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,869]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,870]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,870]     INFO Processing #94/99
[2022-06-01 19:13:13,870]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,870]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,870]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,870]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,871]     INFO Processing #96/99
[2022-06-01 19:13:13,871]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,871]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,871]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,871]     ERROR Driver initialisation failed
[2022-06-01 19:13:13,872]     INFO Processing #98/99
[2022-06-01 19:13:13,872]     INFO Configuring defensive HTML source session
[2022-06-01 19:13:13,872]     ERROR Driver initialisation failed
[2022-06-01 19:13:21,204]     INFO Configuring defensive HTML source session
[2022-06-01 19:14:19,712]     INFO Configuring defensive HTML source session
[2022-06-01 19:14:33,552]     INFO Configuring defensive HTML source session
[2022-06-01 19:14:41,834]     INFO Configuring defensive HTML source session
[2022-06-01 19:17:17,529]     INFO Configuring defensive HTML source session
[2022-06-01 19:17:20,619]     DEBUG Rotating host (Message: unknown error: net::ERR_TUNNEL_CONNECTION_FAILED
  (Session info: headless chrome=102.0.5005.61)
Stacktrace:
#0 0x557110558f33 <unknown>
#1 0x5571102a3118 <unknown>
#2 0x55711029cf25 <unknown>
#3 0x55711028e7a6 <unknown>
#4 0x55711028f6bb <unknown>
#5 0x55711028ea72 <unknown>
#6 0x55711028df15 <unknown>
#7 0x55711028cc0f <unknown>
#8 0x55711028d042 <unknown>
#9 0x5571102a4b92 <unknown>
#10 0x55711030aa3f <unknown>
#11 0x5571102f6f72 <unknown>
#12 0x55711030a2e4 <unknown>
#13 0x5571102f6e63 <unknown>
#14 0x5571102cc82a <unknown>
#15 0x5571102cd985 <unknown>
#16 0x55711059d4cd <unknown>
#17 0x5571105a15ec <unknown>
#18 0x55711058771e <unknown>
#19 0x5571105a2238 <unknown>
#20 0x55711057c870 <unknown>
#21 0x5571105be608 <unknown>
#22 0x5571105be788 <unknown>
#23 0x5571105d8f1d <unknown>
#24 0x7f41059a7947 <unknown>
)
[2022-06-01 19:17:21,725]     DEBUG Rotating host (Message: unknown error: net::ERR_TUNNEL_CONNECTION_FAILED
  (Session info: headless chrome=102.0.5005.61)
Stacktrace:
#0 0x557110558f33 <unknown>
#1 0x5571102a3118 <unknown>
#2 0x55711029cf25 <unknown>
#3 0x55711028e7a6 <unknown>
#4 0x55711028f6bb <unknown>
#5 0x55711028ea72 <unknown>
#6 0x55711028df15 <unknown>
#7 0x55711028cc0f <unknown>
#8 0x55711028d042 <unknown>
#9 0x5571102a4b92 <unknown>
#10 0x55711030aa3f <unknown>
#11 0x5571102f6f72 <unknown>
#12 0x55711030a2e4 <unknown>
#13 0x5571102f6e63 <unknown>
#14 0x5571102cc82a <unknown>
#15 0x5571102cd985 <unknown>
#16 0x55711059d4cd <unknown>
#17 0x5571105a15ec <unknown>
#18 0x55711058771e <unknown>
#19 0x5571105a2238 <unknown>
#20 0x55711057c870 <unknown>
#21 0x5571105be608 <unknown>
#22 0x5571105be788 <unknown>
#23 0x5571105d8f1d <unknown>
#24 0x7f41059a7947 <unknown>
)
[2022-06-01 19:17:23,003]     DEBUG Rotating host (Message: unknown error: net::ERR_TUNNEL_CONNECTION_FAILED
  (Session info: headless chrome=102.0.5005.61)
Stacktrace:
#0 0x557110558f33 <unknown>
#1 0x5571102a3118 <unknown>
#2 0x55711029cf25 <unknown>
#3 0x55711028e7a6 <unknown>
#4 0x55711028f6bb <unknown>
#5 0x55711028ea72 <unknown>
#6 0x55711028df15 <unknown>
#7 0x55711028cc0f <unknown>
#8 0x55711028d042 <unknown>
#9 0x5571102a4b92 <unknown>
#10 0x55711030aa3f <unknown>
#11 0x5571102f6f72 <unknown>
#12 0x55711030a2e4 <unknown>
#13 0x5571102f6e63 <unknown>
#14 0x5571102cc82a <unknown>
#15 0x5571102cd985 <unknown>
#16 0x55711059d4cd <unknown>
#17 0x5571105a15ec <unknown>
#18 0x55711058771e <unknown>
#19 0x5571105a2238 <unknown>
#20 0x55711057c870 <unknown>
#21 0x5571105be608 <unknown>
#22 0x5571105be788 <unknown>
#23 0x5571105d8f1d <unknown>
#24 0x7f41059a7947 <unknown>
)
[2022-06-01 19:17:23,006]     ERROR Driver initialisation failed
[2022-06-01 19:17:23,006]     INFO Configuring defensive HTML source session
[2022-06-01 19:17:25,081]     DEBUG Rotating host (Message: unknown error: net::ERR_TUNNEL_CONNECTION_FAILED
  (Session info: headless chrome=102.0.5005.61)
Stacktrace:
#0 0x557110558f33 <unknown>
#1 0x5571102a3118 <unknown>
#2 0x55711029cf25 <unknown>
#3 0x55711028e7a6 <unknown>
#4 0x55711028f6bb <unknown>
#5 0x55711028ea72 <unknown>
#6 0x55711028df15 <unknown>
#7 0x55711028cc0f <unknown>
#8 0x55711028d042 <unknown>
#9 0x5571102a4b92 <unknown>
#10 0x55711030aa3f <unknown>
#11 0x5571102f6f72 <unknown>
#12 0x55711030a2e4 <unknown>
#13 0x5571102f6e63 <unknown>
#14 0x5571102cc82a <unknown>
#15 0x5571102cd985 <unknown>
#16 0x55711059d4cd <unknown>
#17 0x5571105a15ec <unknown>
#18 0x55711058771e <unknown>
#19 0x5571105a2238 <unknown>
#20 0x55711057c870 <unknown>
#21 0x5571105be608 <unknown>
#22 0x5571105be788 <unknown>
#23 0x5571105d8f1d <unknown>
#24 0x7f41059a7947 <unknown>
)
[2022-06-01 19:17:26,356]     DEBUG Rotating host (Message: unknown error: net::ERR_TUNNEL_CONNECTION_FAILED
  (Session info: headless chrome=102.0.5005.61)
Stacktrace:
#0 0x557110558f33 <unknown>
#1 0x5571102a3118 <unknown>
#2 0x55711029cf25 <unknown>
#3 0x55711028e7a6 <unknown>
#4 0x55711028f6bb <unknown>
#5 0x55711028ea72 <unknown>
#6 0x55711028df15 <unknown>
#7 0x55711028cc0f <unknown>
#8 0x55711028d042 <unknown>
#9 0x5571102a4b92 <unknown>
#10 0x55711030aa3f <unknown>
#11 0x5571102f6f72 <unknown>
#12 0x55711030a2e4 <unknown>
#13 0x5571102f6e63 <unknown>
#14 0x5571102cc82a <unknown>
#15 0x5571102cd985 <unknown>
#16 0x55711059d4cd <unknown>
#17 0x5571105a15ec <unknown>
#18 0x55711058771e <unknown>
#19 0x5571105a2238 <unknown>
#20 0x55711057c870 <unknown>
#21 0x5571105be608 <unknown>
#22 0x5571105be788 <unknown>
#23 0x5571105d8f1d <unknown>
#24 0x7f41059a7947 <unknown>
)
[2022-06-01 19:17:27,446]     DEBUG Rotating host (Message: unknown error: net::ERR_TUNNEL_CONNECTION_FAILED
  (Session info: headless chrome=102.0.5005.61)
Stacktrace:
#0 0x557110558f33 <unknown>
#1 0x5571102a3118 <unknown>
#2 0x55711029cf25 <unknown>
#3 0x55711028e7a6 <unknown>
#4 0x55711028f6bb <unknown>
#5 0x55711028ea72 <unknown>
#6 0x55711028df15 <unknown>
#7 0x55711028cc0f <unknown>
#8 0x55711028d042 <unknown>
#9 0x5571102a4b92 <unknown>
#10 0x55711030aa3f <unknown>
#11 0x5571102f6f72 <unknown>
#12 0x55711030a2e4 <unknown>
#13 0x5571102f6e63 <unknown>
#14 0x5571102cc82a <unknown>
#15 0x5571102cd985 <unknown>
#16 0x55711059d4cd <unknown>
#17 0x5571105a15ec <unknown>
#18 0x55711058771e <unknown>
#19 0x5571105a2238 <unknown>
#20 0x55711057c870 <unknown>
#21 0x5571105be608 <unknown>
#22 0x5571105be788 <unknown>
#23 0x5571105d8f1d <unknown>
#24 0x7f41059a7947 <unknown>
)
[2022-06-01 19:17:27,448]     ERROR Driver initialisation failed
[2022-06-01 19:17:27,448]     INFO Processing #2/99
[2022-06-01 19:17:27,448]     INFO Configuring defensive HTML source session
[2022-06-01 19:17:42,129]     INFO Configuring defensive HTML source session
[2022-06-01 19:17:49,602]     DEBUG Rotating host (Message: unknown error: net::ERR_TUNNEL_CONNECTION_FAILED
  (Session info: headless chrome=102.0.5005.61)
Stacktrace:
#0 0x558a4044ff33 <unknown>
#1 0x558a4019a118 <unknown>
#2 0x558a40193f25 <unknown>
#3 0x558a401857a6 <unknown>
#4 0x558a401866bb <unknown>
#5 0x558a40185a72 <unknown>
#6 0x558a40184f15 <unknown>
#7 0x558a40183c0f <unknown>
#8 0x558a40184042 <unknown>
#9 0x558a4019bb92 <unknown>
#10 0x558a40201a3f <unknown>
#11 0x558a401edf72 <unknown>
#12 0x558a402012e4 <unknown>
#13 0x558a401ede63 <unknown>
#14 0x558a401c382a <unknown>
#15 0x558a401c4985 <unknown>
#16 0x558a404944cd <unknown>
#17 0x558a404985ec <unknown>
#18 0x558a4047e71e <unknown>
#19 0x558a40499238 <unknown>
#20 0x558a40473870 <unknown>
#21 0x558a404b5608 <unknown>
#22 0x558a404b5788 <unknown>
#23 0x558a404cff1d <unknown>
#24 0x7fe0366ef947 <unknown>
)
[2022-06-01 19:17:50,695]     DEBUG Rotating host (Message: unknown error: net::ERR_TUNNEL_CONNECTION_FAILED
  (Session info: headless chrome=102.0.5005.61)
Stacktrace:
#0 0x558a4044ff33 <unknown>
#1 0x558a4019a118 <unknown>
#2 0x558a40193f25 <unknown>
#3 0x558a401857a6 <unknown>
#4 0x558a401866bb <unknown>
#5 0x558a40185a72 <unknown>
#6 0x558a40184f15 <unknown>
#7 0x558a40183c0f <unknown>
#8 0x558a40184042 <unknown>
#9 0x558a4019bb92 <unknown>
#10 0x558a40201a3f <unknown>
#11 0x558a401edf72 <unknown>
#12 0x558a402012e4 <unknown>
#13 0x558a401ede63 <unknown>
#14 0x558a401c382a <unknown>
#15 0x558a401c4985 <unknown>
#16 0x558a404944cd <unknown>
#17 0x558a404985ec <unknown>
#18 0x558a4047e71e <unknown>
#19 0x558a40499238 <unknown>
#20 0x558a40473870 <unknown>
#21 0x558a404b5608 <unknown>
#22 0x558a404b5788 <unknown>
#23 0x558a404cff1d <unknown>
#24 0x7fe0366ef947 <unknown>
)
[2022-06-01 19:17:51,967]     DEBUG Rotating host (Message: unknown error: net::ERR_TUNNEL_CONNECTION_FAILED
  (Session info: headless chrome=102.0.5005.61)
Stacktrace:
#0 0x558a4044ff33 <unknown>
#1 0x558a4019a118 <unknown>
#2 0x558a40193f25 <unknown>
#3 0x558a401857a6 <unknown>
#4 0x558a401866bb <unknown>
#5 0x558a40185a72 <unknown>
#6 0x558a40184f15 <unknown>
#7 0x558a40183c0f <unknown>
#8 0x558a40184042 <unknown>
#9 0x558a4019bb92 <unknown>
#10 0x558a40201a3f <unknown>
#11 0x558a401edf72 <unknown>
#12 0x558a402012e4 <unknown>
#13 0x558a401ede63 <unknown>
#14 0x558a401c382a <unknown>
#15 0x558a401c4985 <unknown>
#16 0x558a404944cd <unknown>
#17 0x558a404985ec <unknown>
#18 0x558a4047e71e <unknown>
#19 0x558a40499238 <unknown>
#20 0x558a40473870 <unknown>
#21 0x558a404b5608 <unknown>
#22 0x558a404b5788 <unknown>
#23 0x558a404cff1d <unknown>
#24 0x7fe0366ef947 <unknown>
)
[2022-06-01 19:17:51,969]     ERROR Driver initialisation failed
[2022-06-01 19:17:51,969]     INFO Configuring defensive HTML source session
[2022-06-01 19:17:59,238]     INFO Processing #2/99
[2022-06-02 08:30:09,383]     INFO Configuring defensive HTML source session
